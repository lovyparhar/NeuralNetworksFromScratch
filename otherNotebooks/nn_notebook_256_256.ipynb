{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB3aQxfqZsJq"
      },
      "source": [
        "Please read the assignment description document."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWOjK1DweJS",
        "outputId": "96ac7255-4093-463d-cbe0-c71b9e3aa60c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcoKSbpvZsJu"
      },
      "source": [
        "# Imports: No other imports allowed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Oha8pGPvZsJv"
      },
      "outputs": [],
      "source": [
        "import numpy as np #No using automatic differentiation allowed from here!\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noaSPo4WZsJw"
      },
      "source": [
        "## Class template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gPuym061ZsJx"
      },
      "outputs": [],
      "source": [
        "def linearActivate(X):\n",
        "    return X\n",
        "\n",
        "def reluActivate(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "def softmaxActivate(X):\n",
        "    expval = np.exp(X - np.max(X, axis=0, keepdims=True))\n",
        "    return expval / np.sum(expval, axis=0, keepdims=True)\n",
        "\n",
        "def linearActivateGrad(X):\n",
        "    return 1\n",
        "\n",
        "def reluActivateGrad(X):\n",
        "    ar = X\n",
        "    ar[ar >= 0] = 1\n",
        "    ar[ar < 0] = 0\n",
        "    return ar\n",
        "\n",
        "def softmaxActivateGrad(X):\n",
        "    val = softmaxActivate(X)\n",
        "    return val * (1-val)\n",
        "    \n",
        "\n",
        "class NeuralNetworkClassifier: \n",
        "    \n",
        "    def __init__(self, layers): \n",
        "        #### CHANGE THE CODE BELOW  \n",
        "        \n",
        "        # The number of layers, including the input layer\n",
        "        self.num_layers = len(layers)\n",
        "        \n",
        "        # Information about each layer (like the size, activation function etc)\n",
        "        self.linfo = {}\n",
        "        \n",
        "        # For each layers, give the info, following the convention that layer 0 is the input layer\n",
        "        for l in range(0, self.num_layers):\n",
        "            \n",
        "            self.linfo[l] = list(layers[l])\n",
        "            if(self.linfo[l][1] == 'linear'):\n",
        "                self.linfo[l].append(linearActivate)\n",
        "                self.linfo[l].append(linearActivateGrad)\n",
        "                \n",
        "            elif(self.linfo[l][1] == 'relu'):\n",
        "                self.linfo[l].append(reluActivate)\n",
        "                self.linfo[l].append(reluActivateGrad)\n",
        "                \n",
        "            else:\n",
        "                self.linfo[l].append(softmaxActivate)\n",
        "                self.linfo[l].append(softmaxActivateGrad)\n",
        "                \n",
        "            \n",
        "        # Parameters for each layer\n",
        "        self.weights = {}\n",
        "        self.bias = {}\n",
        "        \n",
        "        # Randomly initializing the parameters for the layers (except the input one) \n",
        "        for l in range(1, self.num_layers):\n",
        "            div = self.linfo[l-1][0] + self.linfo[l][0]\n",
        "            self.weights[l] = np.random.randn(self.linfo[l][0], self.linfo[l-1][0])/np.sqrt(div)\n",
        "            self.bias[l] = np.random.randn(self.linfo[l][0], 1)/np.sqrt(div)\n",
        "        \n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n",
        "        \n",
        "    def predict(self, X): \n",
        "        #### CHANGE THE CODE BELOW \n",
        "\n",
        "        Z = {}\n",
        "        A = {}\n",
        "        cura = X.T\n",
        "        \n",
        "        for l in range(1, self.num_layers):\n",
        "            Z[l] = (self.weights[l] @ cura) + self.bias[l]\n",
        "            activation_fun = self.linfo[l][2]\n",
        "            A[l] = activation_fun(Z[l])\n",
        "            cura = A[l]\n",
        "        \n",
        "        return cura.T\n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n",
        "    def fit_once(self, X, y, alpha=0.001): \n",
        "        #### CHANGE THE CODE BELOW\n",
        "        \n",
        "        y_d = np.zeros((len(y), self.linfo[len(self.linfo)-1][0]))\n",
        "        for i in range(len(y)):\n",
        "            y_d[i][y[i]] = 1\n",
        "        y_d = y_d.T\n",
        "          \n",
        "        Z = {}\n",
        "        A = {}\n",
        "        Z[0] = X.T\n",
        "        A[0] = X.T\n",
        "        for l in range(1, self.num_layers):\n",
        "            Z[l] = (self.weights[l] @ A[l-1]) + self.bias[l]\n",
        "            activation_fun = self.linfo[l][2]\n",
        "            A[l] = activation_fun(Z[l])\n",
        "        \n",
        "        dZ = {}\n",
        "        dW = {}\n",
        "        db = {}\n",
        "        m = X.shape[0]\n",
        "        dZ[self.num_layers-1] = A[self.num_layers-1] - y_d\n",
        "        dW[self.num_layers-1] = (1/m) * (dZ[self.num_layers-1] @ A[self.num_layers-2].T)\n",
        "        db[self.num_layers-1] = (1/m) * np.sum(dZ[self.num_layers-1], axis=1, keepdims=True)\n",
        "        \n",
        "        \n",
        "        for l in range(self.num_layers-2, 0, -1):\n",
        "            activationGrad = self.linfo[l][3]\n",
        "            dZ[l] = (self.weights[l+1].T @ dZ[l+1]) * activationGrad(Z[l])\n",
        "            dW[l] = (1/m) * (dZ[l] @ A[l-1].T)\n",
        "            db[l] = (1/m) * np.sum(dZ[l], axis=1, keepdims=True)\n",
        "        \n",
        "        \n",
        "        for l in range(1, self.num_layers):\n",
        "            assert(self.weights[l].shape == dW[l].shape)\n",
        "            self.weights[l] -= alpha*dW[l]\n",
        "            assert(self.bias[l].shape == db[l].shape)\n",
        "            self.bias[l] -= alpha*db[l]\n",
        "        \n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n",
        "        \n",
        "    def categorical_cross_entropy_loss(self, y, yhat):\n",
        "      \n",
        "        #### CHANGE THE CODE BELOW\n",
        "        \n",
        "        sh = (len(y), self.linfo[len(self.linfo)-1][0])\n",
        "        y_d = np.zeros(sh)\n",
        "        for i in range(len(y)):\n",
        "            y_d[i][y[i]] = 1\n",
        "            \n",
        "        yhat = np.clip(yhat, 1e-7, 1-1e-7)\n",
        "        logs = -np.log(np.sum(y_d * yhat, axis=1)) \n",
        "        return logs.mean()\n",
        "    \n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDqiM44ZZsJ1"
      },
      "source": [
        "# Example main code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DSQ1wniFZsJ1"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignment3/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignment3/test.csv')\n",
        "sample_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignment3/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "JBm5GEK9ZsJ1",
        "outputId": "469e605b-cdd1-4e55-c771-b146eee84395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1c64af99-22ba-4906-9554-ddc80350f598\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c64af99-22ba-4906-9554-ddc80350f598')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c64af99-22ba-4906-9554-ddc80350f598 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c64af99-22ba-4906-9554-ddc80350f598');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-B3sZ0kBZsJ3",
        "outputId": "414fc26f-1cd5-45a5-d7e1-3f5cb6596777"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b78186a-17e3-4e32-b517-b1e9948587ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b78186a-17e3-4e32-b517-b1e9948587ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b78186a-17e3-4e32-b517-b1e9948587ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b78186a-17e3-4e32-b517-b1e9948587ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0       0       0       0       0  ...         0         0         0         0\n",
              "1       0       0       0       0  ...         0         0         0         0\n",
              "2       0       0       0       0  ...         0         0         0         0\n",
              "3       0       0       0       0  ...         0         0         0         0\n",
              "4       0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-NUhdfZgZsJ4",
        "outputId": "5699ecf7-b667-4379-c56e-610b58633fcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7f96d036-a24d-48a8-9200-2d3de874597b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f96d036-a24d-48a8-9200-2d3de874597b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f96d036-a24d-48a8-9200-2d3de874597b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f96d036-a24d-48a8-9200-2d3de874597b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      0\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sample_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JGJcgKcnZsJ5"
      },
      "outputs": [],
      "source": [
        "X = train_df.iloc[:, 1:].to_numpy()\n",
        "y = train_df['label'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X/255"
      ],
      "metadata": {
        "id": "ev17sc_jyEVB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T1FZ5nQiZsJ5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.20, random_state=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WP0DNpjwZsJ5"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetworkClassifier([(X_train.shape[1], \"relu\"), (256, \"relu\"), (256, \"relu\"), (10, \"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI6BMMShZsJ6",
        "outputId": "df47491b-7fab-4b91-ba6a-a774ba356e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.12095238095238092\n",
            "0 Train_loss = 2.298612941281724     Test_loss = 2.298608729982354\n",
            "\n",
            "Accuracy : 0.16607142857142854\n",
            "1 Train_loss = 2.281612560365073     Test_loss = 2.2818273844755232\n",
            "\n",
            "Accuracy : 0.21499999999999997\n",
            "2 Train_loss = 2.2646867631846663     Test_loss = 2.2651038610719936\n",
            "\n",
            "Accuracy : 0.27202380952380956\n",
            "3 Train_loss = 2.2476404414864586     Test_loss = 2.2482645996513684\n",
            "\n",
            "Accuracy : 0.3391666666666666\n",
            "4 Train_loss = 2.2302553745421743     Test_loss = 2.2310934273028415\n",
            "\n",
            "Accuracy : 0.39642857142857146\n",
            "5 Train_loss = 2.212380502972697     Test_loss = 2.2134481113452686\n",
            "\n",
            "Accuracy : 0.44666666666666666\n",
            "6 Train_loss = 2.193852108631956     Test_loss = 2.195136823324702\n",
            "\n",
            "Accuracy : 0.4848809523809524\n",
            "7 Train_loss = 2.174536020753785     Test_loss = 2.176029188086015\n",
            "\n",
            "Accuracy : 0.5175000000000001\n",
            "8 Train_loss = 2.154310920423274     Test_loss = 2.1560059951025567\n",
            "\n",
            "Accuracy : 0.5472619047619047\n",
            "9 Train_loss = 2.133062982655517     Test_loss = 2.134953541676623\n",
            "\n",
            "Accuracy : 0.5720238095238095\n",
            "10 Train_loss = 2.110696287623683     Test_loss = 2.1127891606840987\n",
            "\n",
            "Accuracy : 0.5921428571428571\n",
            "11 Train_loss = 2.087107405480806     Test_loss = 2.0893950440898243\n",
            "\n",
            "Accuracy : 0.6126190476190476\n",
            "12 Train_loss = 2.062187876105199     Test_loss = 2.0646751515852357\n",
            "\n",
            "Accuracy : 0.6276190476190476\n",
            "13 Train_loss = 2.035828644324263     Test_loss = 2.038521208849448\n",
            "\n",
            "Accuracy : 0.6416666666666666\n",
            "14 Train_loss = 2.007927012805713     Test_loss = 2.0108413083654058\n",
            "\n",
            "Accuracy : 0.6522619047619047\n",
            "15 Train_loss = 1.9784222699910317     Test_loss = 1.9815558754117337\n",
            "\n",
            "Accuracy : 0.6623809523809524\n",
            "16 Train_loss = 1.947277749802265     Test_loss = 1.950602382727027\n",
            "\n",
            "Accuracy : 0.6738095238095239\n",
            "17 Train_loss = 1.9144650502957261     Test_loss = 1.9179761186573139\n",
            "\n",
            "Accuracy : 0.6810714285714285\n",
            "18 Train_loss = 1.8799820030017416     Test_loss = 1.8836923413831463\n",
            "\n",
            "Accuracy : 0.6878571428571428\n",
            "19 Train_loss = 1.8438567620574429     Test_loss = 1.847780102685993\n",
            "\n",
            "Accuracy : 0.6932142857142858\n",
            "20 Train_loss = 1.8061591667680716     Test_loss = 1.810295778830073\n",
            "\n",
            "Accuracy : 0.6989285714285715\n",
            "21 Train_loss = 1.7670148115454967     Test_loss = 1.77135687097398\n",
            "\n",
            "Accuracy : 0.7041666666666666\n",
            "22 Train_loss = 1.7265581851264495     Test_loss = 1.7311227554282302\n",
            "\n",
            "Accuracy : 0.7077380952380952\n",
            "23 Train_loss = 1.6849762537788238     Test_loss = 1.6897632934071949\n",
            "\n",
            "Accuracy : 0.7114285714285714\n",
            "24 Train_loss = 1.6424688237248457     Test_loss = 1.6474885428443284\n",
            "\n",
            "Accuracy : 0.7146428571428571\n",
            "25 Train_loss = 1.5992799354058347     Test_loss = 1.6045171491577188\n",
            "\n",
            "Accuracy : 0.7182142857142857\n",
            "26 Train_loss = 1.5556756884574017     Test_loss = 1.5611139016811417\n",
            "\n",
            "Accuracy : 0.7214285714285714\n",
            "27 Train_loss = 1.5119409584674441     Test_loss = 1.5175900726908553\n",
            "\n",
            "Accuracy : 0.7253571428571428\n",
            "28 Train_loss = 1.4683727038090018     Test_loss = 1.474245300298566\n",
            "\n",
            "Accuracy : 0.7285714285714286\n",
            "29 Train_loss = 1.4252528104301374     Test_loss = 1.4313675118752136\n",
            "\n",
            "Accuracy : 0.7324999999999999\n",
            "30 Train_loss = 1.3828281032714567     Test_loss = 1.3891794812586173\n",
            "\n",
            "Accuracy : 0.7363095238095239\n",
            "31 Train_loss = 1.3413206608292911     Test_loss = 1.3479073211487471\n",
            "\n",
            "Accuracy : 0.7414285714285714\n",
            "32 Train_loss = 1.300895758357169     Test_loss = 1.30772025623901\n",
            "\n",
            "Accuracy : 0.7455952380952381\n",
            "33 Train_loss = 1.2617069636655578     Test_loss = 1.2687597776960218\n",
            "\n",
            "Accuracy : 0.7511904761904762\n",
            "34 Train_loss = 1.223863363584748     Test_loss = 1.231123705848451\n",
            "\n",
            "Accuracy : 0.7578571428571429\n",
            "35 Train_loss = 1.1874486793751373     Test_loss = 1.1949014043416746\n",
            "\n",
            "Accuracy : 0.7619047619047619\n",
            "36 Train_loss = 1.1525218426277115     Test_loss = 1.1601518640478075\n",
            "\n",
            "Accuracy : 0.7647619047619048\n",
            "37 Train_loss = 1.1191177519767903     Test_loss = 1.1269119084706913\n",
            "\n",
            "Accuracy : 0.7701190476190476\n",
            "38 Train_loss = 1.087235239846205     Test_loss = 1.095183824906748\n",
            "\n",
            "Accuracy : 0.7755952380952381\n",
            "39 Train_loss = 1.0568593197515317     Test_loss = 1.064953238387108\n",
            "\n",
            "Accuracy : 0.7807142857142857\n",
            "40 Train_loss = 1.0279642994968812     Test_loss = 1.0361917121223072\n",
            "\n",
            "Accuracy : 0.7857142857142857\n",
            "41 Train_loss = 1.0005157648809273     Test_loss = 1.0088658257175704\n",
            "\n",
            "Accuracy : 0.7895238095238095\n",
            "42 Train_loss = 0.9744704788472728     Test_loss = 0.9829292885606247\n",
            "\n",
            "Accuracy : 0.7947619047619048\n",
            "43 Train_loss = 0.9497686265678404     Test_loss = 0.9583267022864966\n",
            "\n",
            "Accuracy : 0.7991666666666667\n",
            "44 Train_loss = 0.9263493806487676     Test_loss = 0.9349970957170627\n",
            "\n",
            "Accuracy : 0.8021428571428572\n",
            "45 Train_loss = 0.9041500229241275     Test_loss = 0.912875289208117\n",
            "\n",
            "Accuracy : 0.8065476190476191\n",
            "46 Train_loss = 0.8831020979300913     Test_loss = 0.8918966213950981\n",
            "\n",
            "Accuracy : 0.81\n",
            "47 Train_loss = 0.8631413798437181     Test_loss = 0.8719971286270395\n",
            "\n",
            "Accuracy : 0.8130952380952381\n",
            "48 Train_loss = 0.8442086960086012     Test_loss = 0.8531157124888965\n",
            "\n",
            "Accuracy : 0.815595238095238\n",
            "49 Train_loss = 0.8262410236435759     Test_loss = 0.8351938641724248\n",
            "\n",
            "Accuracy : 0.8186904761904762\n",
            "50 Train_loss = 0.8091807636248998     Test_loss = 0.8181720187219879\n",
            "\n",
            "Accuracy : 0.8210714285714286\n",
            "51 Train_loss = 0.792970645209215     Test_loss = 0.8019968938372383\n",
            "\n",
            "Accuracy : 0.8227380952380953\n",
            "52 Train_loss = 0.7775567061196194     Test_loss = 0.7866119170142865\n",
            "\n",
            "Accuracy : 0.8251190476190476\n",
            "53 Train_loss = 0.7628901619610439     Test_loss = 0.7719728001000029\n",
            "\n",
            "Accuracy : 0.8271428571428572\n",
            "54 Train_loss = 0.7489224696790421     Test_loss = 0.7580291032217383\n",
            "\n",
            "Accuracy : 0.8295238095238096\n",
            "55 Train_loss = 0.7356102419767216     Test_loss = 0.7447348179081278\n",
            "\n",
            "Accuracy : 0.8314285714285714\n",
            "56 Train_loss = 0.7229141130925612     Test_loss = 0.732053851890299\n",
            "\n",
            "Accuracy : 0.834047619047619\n",
            "57 Train_loss = 0.7107953537489368     Test_loss = 0.7199491847578355\n",
            "\n",
            "Accuracy : 0.835952380952381\n",
            "58 Train_loss = 0.6992212770846217     Test_loss = 0.7083889008784883\n",
            "\n",
            "Accuracy : 0.8375\n",
            "59 Train_loss = 0.6881599609111543     Test_loss = 0.6973375216414012\n",
            "\n",
            "Accuracy : 0.8392857142857143\n",
            "60 Train_loss = 0.6775794242107389     Test_loss = 0.6867644800962698\n",
            "\n",
            "Accuracy : 0.8401190476190477\n",
            "61 Train_loss = 0.6674504360509002     Test_loss = 0.6766439715064442\n",
            "\n",
            "Accuracy : 0.8413095238095238\n",
            "62 Train_loss = 0.657746974291166     Test_loss = 0.6669500176682814\n",
            "\n",
            "Accuracy : 0.8425\n",
            "63 Train_loss = 0.648445165120889     Test_loss = 0.6576575503107842\n",
            "\n",
            "Accuracy : 0.8439285714285714\n",
            "64 Train_loss = 0.6395218467280405     Test_loss = 0.648743707736695\n",
            "\n",
            "Accuracy : 0.845952380952381\n",
            "65 Train_loss = 0.6309550232137976     Test_loss = 0.6401857387689538\n",
            "\n",
            "Accuracy : 0.8476190476190476\n",
            "66 Train_loss = 0.6227267215630167     Test_loss = 0.6319672578753774\n",
            "\n",
            "Accuracy : 0.8494047619047619\n",
            "67 Train_loss = 0.6148181554160935     Test_loss = 0.6240673197084048\n",
            "\n",
            "Accuracy : 0.8503571428571428\n",
            "68 Train_loss = 0.6072122699564141     Test_loss = 0.61647061198895\n",
            "\n",
            "Accuracy : 0.8520238095238095\n",
            "69 Train_loss = 0.5998909845956059     Test_loss = 0.6091587680973786\n",
            "\n",
            "Accuracy : 0.8532142857142857\n",
            "70 Train_loss = 0.5928401075602565     Test_loss = 0.6021189970848737\n",
            "\n",
            "Accuracy : 0.8544047619047619\n",
            "71 Train_loss = 0.5860471601171471     Test_loss = 0.5953370653796113\n",
            "\n",
            "Accuracy : 0.8554761904761905\n",
            "72 Train_loss = 0.5794972615159055     Test_loss = 0.5887986398581792\n",
            "\n",
            "Accuracy : 0.8563095238095237\n",
            "73 Train_loss = 0.5731790975513711     Test_loss = 0.5824910411470806\n",
            "\n",
            "Accuracy : 0.8572619047619048\n",
            "74 Train_loss = 0.5670804268785389     Test_loss = 0.576404497754305\n",
            "\n",
            "Accuracy : 0.8583333333333334\n",
            "75 Train_loss = 0.561190977283726     Test_loss = 0.570529109305005\n",
            "\n",
            "Accuracy : 0.8598809523809524\n",
            "76 Train_loss = 0.5555009697307309     Test_loss = 0.5648534602974993\n",
            "\n",
            "Accuracy : 0.8610714285714286\n",
            "77 Train_loss = 0.550000794008465     Test_loss = 0.5593692578053928\n",
            "\n",
            "Accuracy : 0.8617857142857143\n",
            "78 Train_loss = 0.5446814304102039     Test_loss = 0.5540677564830325\n",
            "\n",
            "Accuracy : 0.8626190476190476\n",
            "79 Train_loss = 0.5395343131802447     Test_loss = 0.5489392361111871\n",
            "\n",
            "Accuracy : 0.8629761904761905\n",
            "80 Train_loss = 0.5345513753364225     Test_loss = 0.5439761658026977\n",
            "\n",
            "Accuracy : 0.8636904761904762\n",
            "81 Train_loss = 0.5297257087281916     Test_loss = 0.5391713111979944\n",
            "\n",
            "Accuracy : 0.8646428571428572\n",
            "82 Train_loss = 0.525050688635252     Test_loss = 0.5345172756911805\n",
            "\n",
            "Accuracy : 0.8648809523809524\n",
            "83 Train_loss = 0.520518701570974     Test_loss = 0.5300074751448646\n",
            "\n",
            "Accuracy : 0.8652380952380953\n",
            "84 Train_loss = 0.5161234140848103     Test_loss = 0.5256365778052539\n",
            "\n",
            "Accuracy : 0.8664285714285714\n",
            "85 Train_loss = 0.5118594522080586     Test_loss = 0.5213981583734356\n",
            "\n",
            "Accuracy : 0.8672619047619048\n",
            "86 Train_loss = 0.5077210337065822     Test_loss = 0.5172872078628027\n",
            "\n",
            "Accuracy : 0.8676190476190476\n",
            "87 Train_loss = 0.5037030286126092     Test_loss = 0.5132976204169888\n",
            "\n",
            "Accuracy : 0.868095238095238\n",
            "88 Train_loss = 0.4998009657970946     Test_loss = 0.509424735225907\n",
            "\n",
            "Accuracy : 0.8690476190476191\n",
            "89 Train_loss = 0.4960091361557132     Test_loss = 0.505663846398955\n",
            "\n",
            "Accuracy : 0.8691666666666666\n",
            "90 Train_loss = 0.4923234224058589     Test_loss = 0.5020104816071054\n",
            "\n",
            "Accuracy : 0.8702380952380953\n",
            "91 Train_loss = 0.4887399529533925     Test_loss = 0.4984603810666906\n",
            "\n",
            "Accuracy : 0.8703571428571428\n",
            "92 Train_loss = 0.48525439546506854     Test_loss = 0.49501009812971264\n",
            "\n",
            "Accuracy : 0.8709523809523809\n",
            "93 Train_loss = 0.4818628994526039     Test_loss = 0.49165517313262475\n",
            "\n",
            "Accuracy : 0.8713095238095239\n",
            "94 Train_loss = 0.4785622771646858     Test_loss = 0.48839074254168907\n",
            "\n",
            "Accuracy : 0.8716666666666667\n",
            "95 Train_loss = 0.47534889956180343     Test_loss = 0.4852151504093288\n",
            "\n",
            "Accuracy : 0.8723809523809524\n",
            "96 Train_loss = 0.472219573317624     Test_loss = 0.48212378418774976\n",
            "\n",
            "Accuracy : 0.873452380952381\n",
            "97 Train_loss = 0.4691711576961684     Test_loss = 0.4791143649161088\n",
            "\n",
            "Accuracy : 0.8746428571428572\n",
            "98 Train_loss = 0.4662006804887329     Test_loss = 0.4761824789588263\n",
            "\n",
            "Accuracy : 0.8752380952380953\n",
            "99 Train_loss = 0.46330556848926835     Test_loss = 0.47332763558429997\n",
            "\n",
            "Accuracy : 0.8764285714285714\n",
            "100 Train_loss = 0.4604833932662562     Test_loss = 0.4705457403015349\n",
            "\n",
            "Accuracy : 0.8770238095238095\n",
            "101 Train_loss = 0.457730531185077     Test_loss = 0.4678346981731792\n",
            "\n",
            "Accuracy : 0.8771428571428571\n",
            "102 Train_loss = 0.45504471854627454     Test_loss = 0.46519139002973753\n",
            "\n",
            "Accuracy : 0.8776190476190476\n",
            "103 Train_loss = 0.4524233498781143     Test_loss = 0.4626129705771537\n",
            "\n",
            "Accuracy : 0.8778571428571429\n",
            "104 Train_loss = 0.44986453934110093     Test_loss = 0.46009780193545\n",
            "\n",
            "Accuracy : 0.8782142857142857\n",
            "105 Train_loss = 0.447366302176083     Test_loss = 0.45764382209959886\n",
            "\n",
            "Accuracy : 0.8788095238095238\n",
            "106 Train_loss = 0.4449260786355603     Test_loss = 0.45524848842411814\n",
            "\n",
            "Accuracy : 0.8792857142857142\n",
            "107 Train_loss = 0.4425420385680248     Test_loss = 0.4529094439136678\n",
            "\n",
            "Accuracy : 0.8797619047619047\n",
            "108 Train_loss = 0.4402125507797224     Test_loss = 0.4506258563122802\n",
            "\n",
            "Accuracy : 0.8803571428571428\n",
            "109 Train_loss = 0.43793632331094534     Test_loss = 0.44839501928298664\n",
            "\n",
            "Accuracy : 0.8810714285714286\n",
            "110 Train_loss = 0.43571131394252965     Test_loss = 0.44621487149227557\n",
            "\n",
            "Accuracy : 0.8814285714285715\n",
            "111 Train_loss = 0.4335356881530743     Test_loss = 0.44408467665031554\n",
            "\n",
            "Accuracy : 0.8816666666666667\n",
            "112 Train_loss = 0.431407545835651     Test_loss = 0.44200254249647086\n",
            "\n",
            "Accuracy : 0.8820238095238095\n",
            "113 Train_loss = 0.42932538972751333     Test_loss = 0.43996718625890263\n",
            "\n",
            "Accuracy : 0.8829761904761905\n",
            "114 Train_loss = 0.42728816773533357     Test_loss = 0.43797620543686755\n",
            "\n",
            "Accuracy : 0.8829761904761905\n",
            "115 Train_loss = 0.4252944226854652     Test_loss = 0.43602905237240586\n",
            "\n",
            "Accuracy : 0.8833333333333333\n",
            "116 Train_loss = 0.42334275167095714     Test_loss = 0.4341241117706153\n",
            "\n",
            "Accuracy : 0.883452380952381\n",
            "117 Train_loss = 0.421431417808818     Test_loss = 0.43226045096159127\n",
            "\n",
            "Accuracy : 0.8840476190476191\n",
            "118 Train_loss = 0.4195588922036484     Test_loss = 0.43043652567993956\n",
            "\n",
            "Accuracy : 0.8844047619047619\n",
            "119 Train_loss = 0.41772391295088857     Test_loss = 0.4286508703597453\n",
            "\n",
            "Accuracy : 0.8844047619047619\n",
            "120 Train_loss = 0.4159255270993819     Test_loss = 0.42690223547795925\n",
            "\n",
            "Accuracy : 0.8851190476190476\n",
            "121 Train_loss = 0.4141627345271282     Test_loss = 0.42518954667894454\n",
            "\n",
            "Accuracy : 0.8852380952380953\n",
            "122 Train_loss = 0.41243427523668647     Test_loss = 0.423511034725376\n",
            "\n",
            "Accuracy : 0.8861904761904762\n",
            "123 Train_loss = 0.4107395267661739     Test_loss = 0.42186734098600187\n",
            "\n",
            "Accuracy : 0.8861904761904762\n",
            "124 Train_loss = 0.40907737682229484     Test_loss = 0.4202556145287088\n",
            "\n",
            "Accuracy : 0.886547619047619\n",
            "125 Train_loss = 0.40744688013024655     Test_loss = 0.4186761496558179\n",
            "\n",
            "Accuracy : 0.8871428571428571\n",
            "126 Train_loss = 0.4058466987748878     Test_loss = 0.4171266048936185\n",
            "\n",
            "Accuracy : 0.8876190476190476\n",
            "127 Train_loss = 0.4042762275545947     Test_loss = 0.41560727788575097\n",
            "\n",
            "Accuracy : 0.8877380952380952\n",
            "128 Train_loss = 0.40273437649049176     Test_loss = 0.4141162454380687\n",
            "\n",
            "Accuracy : 0.8878571428571429\n",
            "129 Train_loss = 0.40122014025704367     Test_loss = 0.41265274896063625\n",
            "\n",
            "Accuracy : 0.8879761904761905\n",
            "130 Train_loss = 0.39973297191426876     Test_loss = 0.4112166743506114\n",
            "\n",
            "Accuracy : 0.8883333333333333\n",
            "131 Train_loss = 0.39827216092591977     Test_loss = 0.409806543741346\n",
            "\n",
            "Accuracy : 0.8888095238095238\n",
            "132 Train_loss = 0.3968370581253959     Test_loss = 0.4084225293668718\n",
            "\n",
            "Accuracy : 0.8889285714285714\n",
            "133 Train_loss = 0.395427182224193     Test_loss = 0.4070629747939992\n",
            "\n",
            "Accuracy : 0.8889285714285714\n",
            "134 Train_loss = 0.3940417625415843     Test_loss = 0.40572812386121365\n",
            "\n",
            "Accuracy : 0.8895238095238095\n",
            "135 Train_loss = 0.3926800980951409     Test_loss = 0.40441649211368363\n",
            "\n",
            "Accuracy : 0.8901190476190476\n",
            "136 Train_loss = 0.3913415179721394     Test_loss = 0.4031280897977322\n",
            "\n",
            "Accuracy : 0.8904761904761904\n",
            "137 Train_loss = 0.3900251689799304     Test_loss = 0.4018617297937036\n",
            "\n",
            "Accuracy : 0.8904761904761904\n",
            "138 Train_loss = 0.38873034818914837     Test_loss = 0.400616965865839\n",
            "\n",
            "Accuracy : 0.8904761904761904\n",
            "139 Train_loss = 0.3874567012985318     Test_loss = 0.3993935478088026\n",
            "\n",
            "Accuracy : 0.8907142857142857\n",
            "140 Train_loss = 0.38620349904760076     Test_loss = 0.3981902493220914\n",
            "\n",
            "Accuracy : 0.8911904761904762\n",
            "141 Train_loss = 0.38497017557727203     Test_loss = 0.39700636386172794\n",
            "\n",
            "Accuracy : 0.8911904761904762\n",
            "142 Train_loss = 0.38375646512707384     Test_loss = 0.39584252725641544\n",
            "\n",
            "Accuracy : 0.8914285714285715\n",
            "143 Train_loss = 0.3825617279321821     Test_loss = 0.3946970489845976\n",
            "\n",
            "Accuracy : 0.8916666666666666\n",
            "144 Train_loss = 0.3813852328921567     Test_loss = 0.39357025313020444\n",
            "\n",
            "Accuracy : 0.8920238095238096\n",
            "145 Train_loss = 0.380226530875146     Test_loss = 0.3924607220344957\n",
            "\n",
            "Accuracy : 0.8921428571428571\n",
            "146 Train_loss = 0.379085412848368     Test_loss = 0.3913684868420654\n",
            "\n",
            "Accuracy : 0.8925\n",
            "147 Train_loss = 0.3779613924057515     Test_loss = 0.3902931549521967\n",
            "\n",
            "Accuracy : 0.8928571428571429\n",
            "148 Train_loss = 0.3768539024787574     Test_loss = 0.3892347194534022\n",
            "\n",
            "Accuracy : 0.8929761904761905\n",
            "149 Train_loss = 0.37576250530989536     Test_loss = 0.38819238596248823\n",
            "\n",
            "Accuracy : 0.893452380952381\n",
            "150 Train_loss = 0.3746868695963574     Test_loss = 0.3871651298142438\n",
            "\n",
            "Accuracy : 0.8935714285714286\n",
            "151 Train_loss = 0.3736266889076839     Test_loss = 0.3861533632573129\n",
            "\n",
            "Accuracy : 0.8938095238095238\n",
            "152 Train_loss = 0.3725815733199735     Test_loss = 0.385156447936853\n",
            "\n",
            "Accuracy : 0.8941666666666667\n",
            "153 Train_loss = 0.3715510605674619     Test_loss = 0.38417386037283874\n",
            "\n",
            "Accuracy : 0.8942857142857142\n",
            "154 Train_loss = 0.3705347636104259     Test_loss = 0.383205463561349\n",
            "\n",
            "Accuracy : 0.8944047619047619\n",
            "155 Train_loss = 0.36953249897061574     Test_loss = 0.38225131024683373\n",
            "\n",
            "Accuracy : 0.8944047619047619\n",
            "156 Train_loss = 0.3685439281425918     Test_loss = 0.3813103590183038\n",
            "\n",
            "Accuracy : 0.8945238095238095\n",
            "157 Train_loss = 0.36756865789039506     Test_loss = 0.38038303192504375\n",
            "\n",
            "Accuracy : 0.8945238095238095\n",
            "158 Train_loss = 0.3666062832035374     Test_loss = 0.37946808035747037\n",
            "\n",
            "Accuracy : 0.8947619047619048\n",
            "159 Train_loss = 0.3656565447109429     Test_loss = 0.3785657778803939\n",
            "\n",
            "Accuracy : 0.8951190476190476\n",
            "160 Train_loss = 0.3647192448157953     Test_loss = 0.37767558347049074\n",
            "\n",
            "Accuracy : 0.8952380952380953\n",
            "161 Train_loss = 0.3637939465323222     Test_loss = 0.37679761448897187\n",
            "\n",
            "Accuracy : 0.8952380952380953\n",
            "162 Train_loss = 0.36288042946496707     Test_loss = 0.37593088527938523\n",
            "\n",
            "Accuracy : 0.8958333333333334\n",
            "163 Train_loss = 0.36197844996542183     Test_loss = 0.37507614611227696\n",
            "\n",
            "Accuracy : 0.8961904761904762\n",
            "164 Train_loss = 0.3610876479921364     Test_loss = 0.3742318398012585\n",
            "\n",
            "Accuracy : 0.8964285714285715\n",
            "165 Train_loss = 0.3602080274984318     Test_loss = 0.3733994144608804\n",
            "\n",
            "Accuracy : 0.8967857142857143\n",
            "166 Train_loss = 0.3593392420143596     Test_loss = 0.3725773388789105\n",
            "\n",
            "Accuracy : 0.8969047619047619\n",
            "167 Train_loss = 0.35848117726307305     Test_loss = 0.37176598271302436\n",
            "\n",
            "Accuracy : 0.8970238095238096\n",
            "168 Train_loss = 0.35763353209125465     Test_loss = 0.3709645719997765\n",
            "\n",
            "Accuracy : 0.8967857142857143\n",
            "169 Train_loss = 0.3567959455713427     Test_loss = 0.37017274501187397\n",
            "\n",
            "Accuracy : 0.8969047619047619\n",
            "170 Train_loss = 0.3559680133996116     Test_loss = 0.3693904236055935\n",
            "\n",
            "Accuracy : 0.8970238095238096\n",
            "171 Train_loss = 0.35514979627957344     Test_loss = 0.3686181384895035\n",
            "\n",
            "Accuracy : 0.8972619047619048\n",
            "172 Train_loss = 0.35434098058173163     Test_loss = 0.3678543514104393\n",
            "\n",
            "Accuracy : 0.8976190476190476\n",
            "173 Train_loss = 0.35354139437425103     Test_loss = 0.367099801443537\n",
            "\n",
            "Accuracy : 0.8978571428571429\n",
            "174 Train_loss = 0.35275090866680525     Test_loss = 0.3663539854420123\n",
            "\n",
            "Accuracy : 0.8980952380952381\n",
            "175 Train_loss = 0.3519694365014851     Test_loss = 0.3656166314294992\n",
            "\n",
            "Accuracy : 0.8983333333333333\n",
            "176 Train_loss = 0.3511969011434001     Test_loss = 0.36488751022834004\n",
            "\n",
            "Accuracy : 0.898452380952381\n",
            "177 Train_loss = 0.35043308856087874     Test_loss = 0.36416700966505383\n",
            "\n",
            "Accuracy : 0.8983333333333333\n",
            "178 Train_loss = 0.3496777615713074     Test_loss = 0.36345467761278666\n",
            "\n",
            "Accuracy : 0.8985714285714286\n",
            "179 Train_loss = 0.3489306446022057     Test_loss = 0.3627505132523433\n",
            "\n",
            "Accuracy : 0.8989285714285714\n",
            "180 Train_loss = 0.34819158774615616     Test_loss = 0.362054531428329\n",
            "\n",
            "Accuracy : 0.8990476190476191\n",
            "181 Train_loss = 0.3474604034973838     Test_loss = 0.36136599605924236\n",
            "\n",
            "Accuracy : 0.8991666666666667\n",
            "182 Train_loss = 0.3467368272625098     Test_loss = 0.3606847704170957\n",
            "\n",
            "Accuracy : 0.8994047619047619\n",
            "183 Train_loss = 0.34602068448306444     Test_loss = 0.36001038164628213\n",
            "\n",
            "Accuracy : 0.8995238095238095\n",
            "184 Train_loss = 0.3453118450782878     Test_loss = 0.35934380910635405\n",
            "\n",
            "Accuracy : 0.8996428571428572\n",
            "185 Train_loss = 0.34461036831503705     Test_loss = 0.3586844475584051\n",
            "\n",
            "Accuracy : 0.8995238095238095\n",
            "186 Train_loss = 0.34391615602959386     Test_loss = 0.3580317948924874\n",
            "\n",
            "Accuracy : 0.8996428571428572\n",
            "187 Train_loss = 0.3432289805788549     Test_loss = 0.35738625196162116\n",
            "\n",
            "Accuracy : 0.8996428571428572\n",
            "188 Train_loss = 0.3425487170587421     Test_loss = 0.35674746931742113\n",
            "\n",
            "Accuracy : 0.8997619047619048\n",
            "189 Train_loss = 0.34187521446442953     Test_loss = 0.3561152690848078\n",
            "\n",
            "Accuracy : 0.9001190476190476\n",
            "190 Train_loss = 0.3412083492462131     Test_loss = 0.3554883556813343\n",
            "\n",
            "Accuracy : 0.9002380952380953\n",
            "191 Train_loss = 0.34054784372988045     Test_loss = 0.3548682572692192\n",
            "\n",
            "Accuracy : 0.9002380952380953\n",
            "192 Train_loss = 0.339893675102461     Test_loss = 0.3542541551811811\n",
            "\n",
            "Accuracy : 0.9003571428571429\n",
            "193 Train_loss = 0.3392455876924881     Test_loss = 0.35364635776450365\n",
            "\n",
            "Accuracy : 0.9003571428571429\n",
            "194 Train_loss = 0.3386035890642185     Test_loss = 0.3530440874197886\n",
            "\n",
            "Accuracy : 0.9002380952380953\n",
            "195 Train_loss = 0.33796745798269656     Test_loss = 0.3524476902239425\n",
            "\n",
            "Accuracy : 0.9004761904761904\n",
            "196 Train_loss = 0.3373373272585469     Test_loss = 0.35185686721570736\n",
            "\n",
            "Accuracy : 0.9004761904761904\n",
            "197 Train_loss = 0.3367130151299751     Test_loss = 0.3512715960480577\n",
            "\n",
            "Accuracy : 0.9007142857142857\n",
            "198 Train_loss = 0.33609436840074436     Test_loss = 0.35069139332128635\n",
            "\n",
            "Accuracy : 0.9005952380952381\n",
            "199 Train_loss = 0.33548127941449035     Test_loss = 0.35011649395781214\n",
            "\n",
            "Accuracy : 0.9003571428571429\n",
            "200 Train_loss = 0.334873671918192     Test_loss = 0.34954746862218705\n",
            "\n",
            "Accuracy : 0.9007142857142857\n",
            "201 Train_loss = 0.33427137643382404     Test_loss = 0.3489833228078821\n",
            "\n",
            "Accuracy : 0.9007142857142857\n",
            "202 Train_loss = 0.3336743826820369     Test_loss = 0.3484245128048721\n",
            "\n",
            "Accuracy : 0.900952380952381\n",
            "203 Train_loss = 0.33308271953837665     Test_loss = 0.34787103993159685\n",
            "\n",
            "Accuracy : 0.9013095238095238\n",
            "204 Train_loss = 0.3324960818282078     Test_loss = 0.34732245873419404\n",
            "\n",
            "Accuracy : 0.9013095238095238\n",
            "205 Train_loss = 0.33191443355680583     Test_loss = 0.3467786554250554\n",
            "\n",
            "Accuracy : 0.9013095238095238\n",
            "206 Train_loss = 0.3313376277805079     Test_loss = 0.346239756430375\n",
            "\n",
            "Accuracy : 0.9016666666666666\n",
            "207 Train_loss = 0.33076557078100394     Test_loss = 0.3457056515324319\n",
            "\n",
            "Accuracy : 0.9017857142857143\n",
            "208 Train_loss = 0.3301982085561326     Test_loss = 0.3451764633344628\n",
            "\n",
            "Accuracy : 0.9020238095238096\n",
            "209 Train_loss = 0.32963545763074464     Test_loss = 0.34465159001813545\n",
            "\n",
            "Accuracy : 0.9022619047619047\n",
            "210 Train_loss = 0.3290774831559127     Test_loss = 0.3441311325578426\n",
            "\n",
            "Accuracy : 0.9022619047619047\n",
            "211 Train_loss = 0.3285240719561044     Test_loss = 0.3436147293542661\n",
            "\n",
            "Accuracy : 0.9022619047619047\n",
            "212 Train_loss = 0.3279751570618863     Test_loss = 0.34310288246694026\n",
            "\n",
            "Accuracy : 0.9021428571428571\n",
            "213 Train_loss = 0.32743060623778975     Test_loss = 0.34259533345275106\n",
            "\n",
            "Accuracy : 0.9023809523809524\n",
            "214 Train_loss = 0.32689055774243186     Test_loss = 0.34209178719619615\n",
            "\n",
            "Accuracy : 0.9025\n",
            "215 Train_loss = 0.32635473384838753     Test_loss = 0.3415926230682296\n",
            "\n",
            "Accuracy : 0.9026190476190477\n",
            "216 Train_loss = 0.3258230214443083     Test_loss = 0.341097240555181\n",
            "\n",
            "Accuracy : 0.9026190476190477\n",
            "217 Train_loss = 0.3252956852000908     Test_loss = 0.3406059064881805\n",
            "\n",
            "Accuracy : 0.9027380952380952\n",
            "218 Train_loss = 0.324772434497929     Test_loss = 0.34011938234710415\n",
            "\n",
            "Accuracy : 0.9029761904761905\n",
            "219 Train_loss = 0.32425316737188226     Test_loss = 0.33963613417497807\n",
            "\n",
            "Accuracy : 0.9030952380952381\n",
            "220 Train_loss = 0.32373786923343073     Test_loss = 0.3391565788351449\n",
            "\n",
            "Accuracy : 0.9032142857142857\n",
            "221 Train_loss = 0.32322650333029485     Test_loss = 0.33868090472181944\n",
            "\n",
            "Accuracy : 0.9030952380952381\n",
            "222 Train_loss = 0.3227190694186743     Test_loss = 0.3382089456612783\n",
            "\n",
            "Accuracy : 0.9033333333333333\n",
            "223 Train_loss = 0.32221552061491865     Test_loss = 0.33774037070736984\n",
            "\n",
            "Accuracy : 0.9035714285714286\n",
            "224 Train_loss = 0.3217157138322304     Test_loss = 0.3372751388807409\n",
            "\n",
            "Accuracy : 0.9035714285714286\n",
            "225 Train_loss = 0.3212195273075038     Test_loss = 0.3368137680993491\n",
            "\n",
            "Accuracy : 0.9038095238095238\n",
            "226 Train_loss = 0.32072686733042793     Test_loss = 0.3363562686716314\n",
            "\n",
            "Accuracy : 0.904047619047619\n",
            "227 Train_loss = 0.3202375691939994     Test_loss = 0.3359015317465129\n",
            "\n",
            "Accuracy : 0.9041666666666667\n",
            "228 Train_loss = 0.31975167239146673     Test_loss = 0.3354504453418322\n",
            "\n",
            "Accuracy : 0.9045238095238095\n",
            "229 Train_loss = 0.3192690522617499     Test_loss = 0.3350024677007602\n",
            "\n",
            "Accuracy : 0.9047619047619048\n",
            "230 Train_loss = 0.3187898912870665     Test_loss = 0.3345576090585988\n",
            "\n",
            "Accuracy : 0.9048809523809523\n",
            "231 Train_loss = 0.3183139194858863     Test_loss = 0.33411613800352363\n",
            "\n",
            "Accuracy : 0.9047619047619048\n",
            "232 Train_loss = 0.31784114660644774     Test_loss = 0.3336770235230124\n",
            "\n",
            "Accuracy : 0.9048809523809523\n",
            "233 Train_loss = 0.31737160460664626     Test_loss = 0.3332414110639485\n",
            "\n",
            "Accuracy : 0.9048809523809523\n",
            "234 Train_loss = 0.3169052746134399     Test_loss = 0.33280856677860526\n",
            "\n",
            "Accuracy : 0.905\n",
            "235 Train_loss = 0.316442022226707     Test_loss = 0.332379433941172\n",
            "\n",
            "Accuracy : 0.9053571428571429\n",
            "236 Train_loss = 0.3159817294636816     Test_loss = 0.33195261351054856\n",
            "\n",
            "Accuracy : 0.9054761904761904\n",
            "237 Train_loss = 0.31552433110856987     Test_loss = 0.33152928120232383\n",
            "\n",
            "Accuracy : 0.9053571428571429\n",
            "238 Train_loss = 0.3150698692647632     Test_loss = 0.33110852161686594\n",
            "\n",
            "Accuracy : 0.9052380952380953\n",
            "239 Train_loss = 0.3146184670189055     Test_loss = 0.33069071346943674\n",
            "\n",
            "Accuracy : 0.9052380952380953\n",
            "240 Train_loss = 0.31416981976300645     Test_loss = 0.3302754767526079\n",
            "\n",
            "Accuracy : 0.9053571428571429\n",
            "241 Train_loss = 0.3137238870252429     Test_loss = 0.3298633293517196\n",
            "\n",
            "Accuracy : 0.9054761904761904\n",
            "242 Train_loss = 0.3132807299821188     Test_loss = 0.3294534373708824\n",
            "\n",
            "Accuracy : 0.9057142857142857\n",
            "243 Train_loss = 0.31284020436924964     Test_loss = 0.3290458621835623\n",
            "\n",
            "Accuracy : 0.9060714285714285\n",
            "244 Train_loss = 0.3124024494293419     Test_loss = 0.3286410690317703\n",
            "\n",
            "Accuracy : 0.9061904761904762\n",
            "245 Train_loss = 0.31196752429966196     Test_loss = 0.3282391268108652\n",
            "\n",
            "Accuracy : 0.9061904761904762\n",
            "246 Train_loss = 0.3115352987237082     Test_loss = 0.3278396356966905\n",
            "\n",
            "Accuracy : 0.9063095238095238\n",
            "247 Train_loss = 0.31110582631767775     Test_loss = 0.3274427672752563\n",
            "\n",
            "Accuracy : 0.9063095238095238\n",
            "248 Train_loss = 0.31067891077742865     Test_loss = 0.32704793719451813\n",
            "\n",
            "Accuracy : 0.9063095238095238\n",
            "249 Train_loss = 0.31025443635081096     Test_loss = 0.3266559935363467\n",
            "\n",
            "Accuracy : 0.9063095238095238\n",
            "250 Train_loss = 0.3098323572539585     Test_loss = 0.3262659999022515\n",
            "\n",
            "Accuracy : 0.9063095238095238\n",
            "251 Train_loss = 0.3094128233869185     Test_loss = 0.32587914097187715\n",
            "\n",
            "Accuracy : 0.9061904761904762\n",
            "252 Train_loss = 0.3089957152153758     Test_loss = 0.32549412728730354\n",
            "\n",
            "Accuracy : 0.9061904761904762\n",
            "253 Train_loss = 0.3085812224660354     Test_loss = 0.32511142648610114\n",
            "\n",
            "Accuracy : 0.9061904761904762\n",
            "254 Train_loss = 0.3081690995945042     Test_loss = 0.3247305719390563\n",
            "\n",
            "Accuracy : 0.9064285714285715\n",
            "255 Train_loss = 0.3077592913250424     Test_loss = 0.3243523597493181\n",
            "\n",
            "Accuracy : 0.9064285714285715\n",
            "256 Train_loss = 0.30735183481658274     Test_loss = 0.323975865046059\n",
            "\n",
            "Accuracy : 0.9064285714285715\n",
            "257 Train_loss = 0.30694650005283936     Test_loss = 0.32360181304707075\n",
            "\n",
            "Accuracy : 0.9064285714285715\n",
            "258 Train_loss = 0.30654332686971864     Test_loss = 0.32323002542719587\n",
            "\n",
            "Accuracy : 0.9066666666666666\n",
            "259 Train_loss = 0.3061425490959272     Test_loss = 0.322860744937913\n",
            "\n",
            "Accuracy : 0.9066666666666666\n",
            "260 Train_loss = 0.30574407477868604     Test_loss = 0.32249354987166673\n",
            "\n",
            "Accuracy : 0.9067857142857143\n",
            "261 Train_loss = 0.30534783697044066     Test_loss = 0.3221289617764225\n",
            "\n",
            "Accuracy : 0.9070238095238096\n",
            "262 Train_loss = 0.3049535025898455     Test_loss = 0.32176599487850777\n",
            "\n",
            "Accuracy : 0.9071428571428571\n",
            "263 Train_loss = 0.30456122855611883     Test_loss = 0.3214051512096975\n",
            "\n",
            "Accuracy : 0.9072619047619047\n",
            "264 Train_loss = 0.3041711461205818     Test_loss = 0.32104614082622507\n",
            "\n",
            "Accuracy : 0.9073809523809524\n",
            "265 Train_loss = 0.3037830667997197     Test_loss = 0.32068955895877216\n",
            "\n",
            "Accuracy : 0.9073809523809524\n",
            "266 Train_loss = 0.303396957680081     Test_loss = 0.32033467959258344\n",
            "\n",
            "Accuracy : 0.9075\n",
            "267 Train_loss = 0.3030128922237044     Test_loss = 0.3199819458098516\n",
            "\n",
            "Accuracy : 0.9078571428571429\n",
            "268 Train_loss = 0.3026308688939318     Test_loss = 0.3196308007120428\n",
            "\n",
            "Accuracy : 0.9080952380952381\n",
            "269 Train_loss = 0.30225070191099346     Test_loss = 0.3192817618562022\n",
            "\n",
            "Accuracy : 0.9083333333333333\n",
            "270 Train_loss = 0.30187238308065706     Test_loss = 0.3189343077317295\n",
            "\n",
            "Accuracy : 0.908452380952381\n",
            "271 Train_loss = 0.30149587680594403     Test_loss = 0.31858859273545154\n",
            "\n",
            "Accuracy : 0.9085714285714286\n",
            "272 Train_loss = 0.30112109889656763     Test_loss = 0.3182443734575843\n",
            "\n",
            "Accuracy : 0.9088095238095238\n",
            "273 Train_loss = 0.3007480215396435     Test_loss = 0.3179020844757506\n",
            "\n",
            "Accuracy : 0.9090476190476191\n",
            "274 Train_loss = 0.30037685480544957     Test_loss = 0.3175617959062171\n",
            "\n",
            "Accuracy : 0.9092857142857143\n",
            "275 Train_loss = 0.30000739823294087     Test_loss = 0.31722293750511515\n",
            "\n",
            "Accuracy : 0.9092857142857143\n",
            "276 Train_loss = 0.299639839162339     Test_loss = 0.3168863494682358\n",
            "\n",
            "Accuracy : 0.9092857142857143\n",
            "277 Train_loss = 0.29927415086078074     Test_loss = 0.3165507758268309\n",
            "\n",
            "Accuracy : 0.9091666666666667\n",
            "278 Train_loss = 0.29891031588857575     Test_loss = 0.3162180694702224\n",
            "\n",
            "Accuracy : 0.9092857142857143\n",
            "279 Train_loss = 0.29854831668406023     Test_loss = 0.31588670369501914\n",
            "\n",
            "Accuracy : 0.9092857142857143\n",
            "280 Train_loss = 0.2981880969958189     Test_loss = 0.31555678693482536\n",
            "\n",
            "Accuracy : 0.9092857142857143\n",
            "281 Train_loss = 0.2978296853352868     Test_loss = 0.31522855145883183\n",
            "\n",
            "Accuracy : 0.9094047619047619\n",
            "282 Train_loss = 0.2974731061458143     Test_loss = 0.3149021736993451\n",
            "\n",
            "Accuracy : 0.9094047619047619\n",
            "283 Train_loss = 0.29711815697497435     Test_loss = 0.31457738667051593\n",
            "\n",
            "Accuracy : 0.9094047619047619\n",
            "284 Train_loss = 0.2967648365574569     Test_loss = 0.3142540389574237\n",
            "\n",
            "Accuracy : 0.9094047619047619\n",
            "285 Train_loss = 0.296412923465504     Test_loss = 0.3139319327806241\n",
            "\n",
            "Accuracy : 0.9094047619047619\n",
            "286 Train_loss = 0.29606263799839144     Test_loss = 0.31361180798771376\n",
            "\n",
            "Accuracy : 0.9096428571428572\n",
            "287 Train_loss = 0.2957139099220897     Test_loss = 0.31329299924087295\n",
            "\n",
            "Accuracy : 0.9097619047619048\n",
            "288 Train_loss = 0.2953666168959637     Test_loss = 0.3129758199260243\n",
            "\n",
            "Accuracy : 0.91\n",
            "289 Train_loss = 0.2950209015952846     Test_loss = 0.31266014393195074\n",
            "\n",
            "Accuracy : 0.9101190476190476\n",
            "290 Train_loss = 0.2946766522351877     Test_loss = 0.31234535520666973\n",
            "\n",
            "Accuracy : 0.9102380952380953\n",
            "291 Train_loss = 0.29433371343851356     Test_loss = 0.3120323114577859\n",
            "\n",
            "Accuracy : 0.9102380952380953\n",
            "292 Train_loss = 0.2939922500332119     Test_loss = 0.3117209541883011\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "293 Train_loss = 0.2936522026383449     Test_loss = 0.3114109632361354\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "294 Train_loss = 0.2933136371853768     Test_loss = 0.31110239455779237\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "295 Train_loss = 0.2929766300442542     Test_loss = 0.31079529553940544\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "296 Train_loss = 0.2926411161063344     Test_loss = 0.31048969896397366\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "297 Train_loss = 0.29230707817486407     Test_loss = 0.31018520291374335\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "298 Train_loss = 0.29197451836313043     Test_loss = 0.3098820129357762\n",
            "\n",
            "Accuracy : 0.9104761904761904\n",
            "299 Train_loss = 0.29164348628080167     Test_loss = 0.30957984693691554\n",
            "\n",
            "Accuracy : 0.9108333333333334\n",
            "300 Train_loss = 0.2913138064703692     Test_loss = 0.3092788464021546\n",
            "\n",
            "Accuracy : 0.9110714285714285\n",
            "301 Train_loss = 0.2909853763382105     Test_loss = 0.30897991174213774\n",
            "\n",
            "Accuracy : 0.9110714285714285\n",
            "302 Train_loss = 0.2906584073112603     Test_loss = 0.308682008297585\n",
            "\n",
            "Accuracy : 0.9110714285714285\n",
            "303 Train_loss = 0.2903328590676797     Test_loss = 0.30838611044298603\n",
            "\n",
            "Accuracy : 0.9113095238095238\n",
            "304 Train_loss = 0.2900086215632288     Test_loss = 0.3080914209229729\n",
            "\n",
            "Accuracy : 0.911547619047619\n",
            "305 Train_loss = 0.289685506271608     Test_loss = 0.30779725092108906\n",
            "\n",
            "Accuracy : 0.9116666666666666\n",
            "306 Train_loss = 0.28936356139980984     Test_loss = 0.3075042522374417\n",
            "\n",
            "Accuracy : 0.9121428571428571\n",
            "307 Train_loss = 0.2890428970339     Test_loss = 0.30721204412568887\n",
            "\n",
            "Accuracy : 0.9122619047619047\n",
            "308 Train_loss = 0.28872351646238203     Test_loss = 0.3069216280319932\n",
            "\n",
            "Accuracy : 0.9123809523809524\n",
            "309 Train_loss = 0.2884053699390195     Test_loss = 0.3066317090967012\n",
            "\n",
            "Accuracy : 0.9123809523809524\n",
            "310 Train_loss = 0.28808844393298494     Test_loss = 0.3063439267237403\n",
            "\n",
            "Accuracy : 0.9125\n",
            "311 Train_loss = 0.2877727574669063     Test_loss = 0.3060574261115169\n",
            "\n",
            "Accuracy : 0.9128571428571428\n",
            "312 Train_loss = 0.2874582387704516     Test_loss = 0.30577208285626334\n",
            "\n",
            "Accuracy : 0.9130952380952381\n",
            "313 Train_loss = 0.2871449765087246     Test_loss = 0.3054880614028528\n",
            "\n",
            "Accuracy : 0.9133333333333333\n",
            "314 Train_loss = 0.2868329963135714     Test_loss = 0.3052047160213929\n",
            "\n",
            "Accuracy : 0.9133333333333333\n",
            "315 Train_loss = 0.2865221384973326     Test_loss = 0.30492342448559706\n",
            "\n",
            "Accuracy : 0.9134523809523809\n",
            "316 Train_loss = 0.28621235988367383     Test_loss = 0.30464228524838854\n",
            "\n",
            "Accuracy : 0.9135714285714286\n",
            "317 Train_loss = 0.2859038050985586     Test_loss = 0.3043628491971372\n",
            "\n",
            "Accuracy : 0.9136904761904762\n",
            "318 Train_loss = 0.28559644195300504     Test_loss = 0.3040845616263421\n",
            "\n",
            "Accuracy : 0.9138095238095238\n",
            "319 Train_loss = 0.2852902550640316     Test_loss = 0.3038074396829289\n",
            "\n",
            "Accuracy : 0.914047619047619\n",
            "320 Train_loss = 0.2849853267108887     Test_loss = 0.30353112625977013\n",
            "\n",
            "Accuracy : 0.9141666666666667\n",
            "321 Train_loss = 0.28468138395488973     Test_loss = 0.3032557310646228\n",
            "\n",
            "Accuracy : 0.9147619047619048\n",
            "322 Train_loss = 0.2843785279998385     Test_loss = 0.3029815991269989\n",
            "\n",
            "Accuracy : 0.9147619047619048\n",
            "323 Train_loss = 0.28407676295241685     Test_loss = 0.3027082914654156\n",
            "\n",
            "Accuracy : 0.9147619047619048\n",
            "324 Train_loss = 0.28377605309755904     Test_loss = 0.30243599463561893\n",
            "\n",
            "Accuracy : 0.9147619047619048\n",
            "325 Train_loss = 0.28347635409414157     Test_loss = 0.3021646917819427\n",
            "\n",
            "Accuracy : 0.9148809523809524\n",
            "326 Train_loss = 0.28317763755553643     Test_loss = 0.30189449278765085\n",
            "\n",
            "Accuracy : 0.9148809523809524\n",
            "327 Train_loss = 0.28287988018021476     Test_loss = 0.3016256023514972\n",
            "\n",
            "Accuracy : 0.9148809523809524\n",
            "328 Train_loss = 0.282583259298377     Test_loss = 0.30135697491573815\n",
            "\n",
            "Accuracy : 0.9148809523809524\n",
            "329 Train_loss = 0.2822876964852261     Test_loss = 0.3010898324497232\n",
            "\n",
            "Accuracy : 0.9151190476190476\n",
            "330 Train_loss = 0.28199302065359316     Test_loss = 0.300822934513566\n",
            "\n",
            "Accuracy : 0.9151190476190476\n",
            "331 Train_loss = 0.2816993400936561     Test_loss = 0.30055796587725053\n",
            "\n",
            "Accuracy : 0.9151190476190476\n",
            "332 Train_loss = 0.28140662433275354     Test_loss = 0.30029368189499417\n",
            "\n",
            "Accuracy : 0.915\n",
            "333 Train_loss = 0.28111491651656717     Test_loss = 0.30003027740805877\n",
            "\n",
            "Accuracy : 0.9154761904761904\n",
            "334 Train_loss = 0.2808241291801887     Test_loss = 0.29976806091080765\n",
            "\n",
            "Accuracy : 0.9157142857142857\n",
            "335 Train_loss = 0.28053423741985334     Test_loss = 0.2995063438370766\n",
            "\n",
            "Accuracy : 0.915952380952381\n",
            "336 Train_loss = 0.28024517748645844     Test_loss = 0.29924592939355216\n",
            "\n",
            "Accuracy : 0.915952380952381\n",
            "337 Train_loss = 0.2799570388387943     Test_loss = 0.29898559665372065\n",
            "\n",
            "Accuracy : 0.915952380952381\n",
            "338 Train_loss = 0.2796697498882596     Test_loss = 0.2987266235693446\n",
            "\n",
            "Accuracy : 0.915952380952381\n",
            "339 Train_loss = 0.2793831859818005     Test_loss = 0.29846771094008906\n",
            "\n",
            "Accuracy : 0.9161904761904762\n",
            "340 Train_loss = 0.2790974201153218     Test_loss = 0.29821034257095785\n",
            "\n",
            "Accuracy : 0.9161904761904762\n",
            "341 Train_loss = 0.27881268290329614     Test_loss = 0.2979537036589704\n",
            "\n",
            "Accuracy : 0.9163095238095238\n",
            "342 Train_loss = 0.27852886401310045     Test_loss = 0.29769842527456936\n",
            "\n",
            "Accuracy : 0.9164285714285714\n",
            "343 Train_loss = 0.27824592211267984     Test_loss = 0.29744345355219226\n",
            "\n",
            "Accuracy : 0.9164285714285714\n",
            "344 Train_loss = 0.27796382878427545     Test_loss = 0.2971897043432547\n",
            "\n",
            "Accuracy : 0.9164285714285714\n",
            "345 Train_loss = 0.2776826556034305     Test_loss = 0.2969366786495743\n",
            "\n",
            "Accuracy : 0.9164285714285714\n",
            "346 Train_loss = 0.2774023856432103     Test_loss = 0.29668479309224716\n",
            "\n",
            "Accuracy : 0.916547619047619\n",
            "347 Train_loss = 0.27712282023557805     Test_loss = 0.2964327267895815\n",
            "\n",
            "Accuracy : 0.916547619047619\n",
            "348 Train_loss = 0.27684423110372713     Test_loss = 0.29618245904258206\n",
            "\n",
            "Accuracy : 0.916547619047619\n",
            "349 Train_loss = 0.276566468489563     Test_loss = 0.29593244845096206\n",
            "\n",
            "Accuracy : 0.9166666666666666\n",
            "350 Train_loss = 0.27628948595648645     Test_loss = 0.2956834504526565\n",
            "\n",
            "Accuracy : 0.9166666666666666\n",
            "351 Train_loss = 0.27601328115172374     Test_loss = 0.2954353600278238\n",
            "\n",
            "Accuracy : 0.9167857142857143\n",
            "352 Train_loss = 0.27573767052755094     Test_loss = 0.29518763518348784\n",
            "\n",
            "Accuracy : 0.9167857142857143\n",
            "353 Train_loss = 0.27546267160007804     Test_loss = 0.2949405732694373\n",
            "\n",
            "Accuracy : 0.9171428571428571\n",
            "354 Train_loss = 0.2751884155787389     Test_loss = 0.2946941062135915\n",
            "\n",
            "Accuracy : 0.9171428571428571\n",
            "355 Train_loss = 0.27491495054518517     Test_loss = 0.2944481048768419\n",
            "\n",
            "Accuracy : 0.9172619047619047\n",
            "356 Train_loss = 0.27464240086845865     Test_loss = 0.29420321139644573\n",
            "\n",
            "Accuracy : 0.9175\n",
            "357 Train_loss = 0.27437070139530906     Test_loss = 0.2939589399635506\n",
            "\n",
            "Accuracy : 0.9175\n",
            "358 Train_loss = 0.27409986904597206     Test_loss = 0.29371508651921624\n",
            "\n",
            "Accuracy : 0.9177380952380952\n",
            "359 Train_loss = 0.2738297286211939     Test_loss = 0.29347223304181136\n",
            "\n",
            "Accuracy : 0.9178571428571428\n",
            "360 Train_loss = 0.27356024320188516     Test_loss = 0.29322975783543875\n",
            "\n",
            "Accuracy : 0.9178571428571428\n",
            "361 Train_loss = 0.2732914293024585     Test_loss = 0.29298810954822196\n",
            "\n",
            "Accuracy : 0.9178571428571428\n",
            "362 Train_loss = 0.27302320477810366     Test_loss = 0.29274675559431573\n",
            "\n",
            "Accuracy : 0.9178571428571428\n",
            "363 Train_loss = 0.2727554540145296     Test_loss = 0.29250592729972663\n",
            "\n",
            "Accuracy : 0.9179761904761905\n",
            "364 Train_loss = 0.2724882006932443     Test_loss = 0.29226574550454915\n",
            "\n",
            "Accuracy : 0.9182142857142858\n",
            "365 Train_loss = 0.2722216544434426     Test_loss = 0.29202625232323176\n",
            "\n",
            "Accuracy : 0.9180952380952381\n",
            "366 Train_loss = 0.2719559230583018     Test_loss = 0.2917873267590602\n",
            "\n",
            "Accuracy : 0.9180952380952381\n",
            "367 Train_loss = 0.27169091567386117     Test_loss = 0.29154896685471815\n",
            "\n",
            "Accuracy : 0.9179761904761905\n",
            "368 Train_loss = 0.2714265531388872     Test_loss = 0.29131140901415836\n",
            "\n",
            "Accuracy : 0.9180952380952381\n",
            "369 Train_loss = 0.2711629447345874     Test_loss = 0.2910742193686464\n",
            "\n",
            "Accuracy : 0.9180952380952381\n",
            "370 Train_loss = 0.27090010039457213     Test_loss = 0.2908381021555284\n",
            "\n",
            "Accuracy : 0.9182142857142858\n",
            "371 Train_loss = 0.27063785624343817     Test_loss = 0.29060232969775585\n",
            "\n",
            "Accuracy : 0.9184523809523809\n",
            "372 Train_loss = 0.27037624403736216     Test_loss = 0.2903671770280712\n",
            "\n",
            "Accuracy : 0.9184523809523809\n",
            "373 Train_loss = 0.27011535818082755     Test_loss = 0.2901331511577711\n",
            "\n",
            "Accuracy : 0.9185714285714286\n",
            "374 Train_loss = 0.2698551010368447     Test_loss = 0.2898987336641252\n",
            "\n",
            "Accuracy : 0.9186904761904762\n",
            "375 Train_loss = 0.26959551675338456     Test_loss = 0.28966541573196025\n",
            "\n",
            "Accuracy : 0.9188095238095239\n",
            "376 Train_loss = 0.2693366793947016     Test_loss = 0.28943215193813304\n",
            "\n",
            "Accuracy : 0.9188095238095239\n",
            "377 Train_loss = 0.2690785604838103     Test_loss = 0.2891997599141136\n",
            "\n",
            "Accuracy : 0.9188095238095239\n",
            "378 Train_loss = 0.2688209630567114     Test_loss = 0.28896755774475186\n",
            "\n",
            "Accuracy : 0.9186904761904762\n",
            "379 Train_loss = 0.2685637193717839     Test_loss = 0.2887356416691599\n",
            "\n",
            "Accuracy : 0.9189285714285714\n",
            "380 Train_loss = 0.2683071499352887     Test_loss = 0.28850467748790615\n",
            "\n",
            "Accuracy : 0.9189285714285714\n",
            "381 Train_loss = 0.2680512043530516     Test_loss = 0.28827477619697034\n",
            "\n",
            "Accuracy : 0.919047619047619\n",
            "382 Train_loss = 0.26779594000195767     Test_loss = 0.2880454752198414\n",
            "\n",
            "Accuracy : 0.9191666666666667\n",
            "383 Train_loss = 0.26754111675619385     Test_loss = 0.28781663077996184\n",
            "\n",
            "Accuracy : 0.9191666666666667\n",
            "384 Train_loss = 0.26728680626625395     Test_loss = 0.2875882771857343\n",
            "\n",
            "Accuracy : 0.919404761904762\n",
            "385 Train_loss = 0.26703314678665313     Test_loss = 0.28736046208970917\n",
            "\n",
            "Accuracy : 0.919404761904762\n",
            "386 Train_loss = 0.2667802047028626     Test_loss = 0.2871333117255142\n",
            "\n",
            "Accuracy : 0.9196428571428571\n",
            "387 Train_loss = 0.26652791941401244     Test_loss = 0.28690672437315734\n",
            "\n",
            "Accuracy : 0.9197619047619048\n",
            "388 Train_loss = 0.26627629725103635     Test_loss = 0.28668047761536053\n",
            "\n",
            "Accuracy : 0.9196428571428571\n",
            "389 Train_loss = 0.2660253590451112     Test_loss = 0.28645475536557496\n",
            "\n",
            "Accuracy : 0.9198809523809524\n",
            "390 Train_loss = 0.2657750283641309     Test_loss = 0.2862292839639848\n",
            "\n",
            "Accuracy : 0.9201190476190476\n",
            "391 Train_loss = 0.26552530577539596     Test_loss = 0.28600459507229664\n",
            "\n",
            "Accuracy : 0.9202380952380953\n",
            "392 Train_loss = 0.26527623635380154     Test_loss = 0.28578098720523015\n",
            "\n",
            "Accuracy : 0.9203571428571429\n",
            "393 Train_loss = 0.26502762525622453     Test_loss = 0.2855574812743218\n",
            "\n",
            "Accuracy : 0.9204761904761904\n",
            "394 Train_loss = 0.2647795997756075     Test_loss = 0.2853342283138805\n",
            "\n",
            "Accuracy : 0.9205952380952381\n",
            "395 Train_loss = 0.2645322834430767     Test_loss = 0.2851119763825052\n",
            "\n",
            "Accuracy : 0.9207142857142857\n",
            "396 Train_loss = 0.26428569739420343     Test_loss = 0.2848896931811437\n",
            "\n",
            "Accuracy : 0.9207142857142857\n",
            "397 Train_loss = 0.26403965873142154     Test_loss = 0.2846682293231943\n",
            "\n",
            "Accuracy : 0.9205952380952381\n",
            "398 Train_loss = 0.2637941654367569     Test_loss = 0.2844470588801588\n",
            "\n",
            "Accuracy : 0.9208333333333334\n",
            "399 Train_loss = 0.2635492748020689     Test_loss = 0.28422668224795694\n",
            "\n",
            "Accuracy : 0.9208333333333334\n",
            "400 Train_loss = 0.26330510400005014     Test_loss = 0.2840067848848125\n",
            "\n",
            "Accuracy : 0.9208333333333334\n",
            "401 Train_loss = 0.26306148296594556     Test_loss = 0.2837876426760272\n",
            "\n",
            "Accuracy : 0.9208333333333334\n",
            "402 Train_loss = 0.26281821647875403     Test_loss = 0.2835684329449395\n",
            "\n",
            "Accuracy : 0.920952380952381\n",
            "403 Train_loss = 0.2625753780045894     Test_loss = 0.28334994490617493\n",
            "\n",
            "Accuracy : 0.920952380952381\n",
            "404 Train_loss = 0.2623330286520589     Test_loss = 0.28313222012357425\n",
            "\n",
            "Accuracy : 0.9210714285714285\n",
            "405 Train_loss = 0.26209124732805     Test_loss = 0.2829154297618871\n",
            "\n",
            "Accuracy : 0.9211904761904762\n",
            "406 Train_loss = 0.26185006337647143     Test_loss = 0.28269883757052267\n",
            "\n",
            "Accuracy : 0.9213095238095238\n",
            "407 Train_loss = 0.26160951991152526     Test_loss = 0.28248337047558475\n",
            "\n",
            "Accuracy : 0.9215476190476191\n",
            "408 Train_loss = 0.2613694999803925     Test_loss = 0.28226783363824465\n",
            "\n",
            "Accuracy : 0.9216666666666666\n",
            "409 Train_loss = 0.26112997282762906     Test_loss = 0.28205319657383243\n",
            "\n",
            "Accuracy : 0.9217857142857143\n",
            "410 Train_loss = 0.26089100892802936     Test_loss = 0.28183902264878885\n",
            "\n",
            "Accuracy : 0.9219047619047619\n",
            "411 Train_loss = 0.26065259589138834     Test_loss = 0.2816252118026\n",
            "\n",
            "Accuracy : 0.9219047619047619\n",
            "412 Train_loss = 0.26041466552479986     Test_loss = 0.28141195284041376\n",
            "\n",
            "Accuracy : 0.9220238095238096\n",
            "413 Train_loss = 0.26017727725875417     Test_loss = 0.28119907902693975\n",
            "\n",
            "Accuracy : 0.9221428571428572\n",
            "414 Train_loss = 0.2599402245779894     Test_loss = 0.28098612031635445\n",
            "\n",
            "Accuracy : 0.9226190476190477\n",
            "415 Train_loss = 0.2597035065722029     Test_loss = 0.28077400368402194\n",
            "\n",
            "Accuracy : 0.9227380952380952\n",
            "416 Train_loss = 0.2594672587588503     Test_loss = 0.2805622657470191\n",
            "\n",
            "Accuracy : 0.9228571428571428\n",
            "417 Train_loss = 0.25923157452366624     Test_loss = 0.28035080166368614\n",
            "\n",
            "Accuracy : 0.9228571428571428\n",
            "418 Train_loss = 0.25899638591838786     Test_loss = 0.2801406286739996\n",
            "\n",
            "Accuracy : 0.9228571428571428\n",
            "419 Train_loss = 0.2587617504704921     Test_loss = 0.2799299980606518\n",
            "\n",
            "Accuracy : 0.9229761904761905\n",
            "420 Train_loss = 0.2585275133975715     Test_loss = 0.2797196736311317\n",
            "\n",
            "Accuracy : 0.9230952380952381\n",
            "421 Train_loss = 0.25829387240354734     Test_loss = 0.2795098647863021\n",
            "\n",
            "Accuracy : 0.9230952380952381\n",
            "422 Train_loss = 0.25806075574022397     Test_loss = 0.2793008946160915\n",
            "\n",
            "Accuracy : 0.9230952380952381\n",
            "423 Train_loss = 0.2578280946216298     Test_loss = 0.27909158129004213\n",
            "\n",
            "Accuracy : 0.9233333333333333\n",
            "424 Train_loss = 0.25759584031303134     Test_loss = 0.2788830064465869\n",
            "\n",
            "Accuracy : 0.9235714285714286\n",
            "425 Train_loss = 0.25736416294845965     Test_loss = 0.27867483658096076\n",
            "\n",
            "Accuracy : 0.9236904761904762\n",
            "426 Train_loss = 0.25713300233362474     Test_loss = 0.27846688939969666\n",
            "\n",
            "Accuracy : 0.9239285714285714\n",
            "427 Train_loss = 0.2569023249948645     Test_loss = 0.2782591940801294\n",
            "\n",
            "Accuracy : 0.924047619047619\n",
            "428 Train_loss = 0.25667221282896474     Test_loss = 0.2780520985217545\n",
            "\n",
            "Accuracy : 0.9241666666666667\n",
            "429 Train_loss = 0.2564425627326215     Test_loss = 0.27784510806519497\n",
            "\n",
            "Accuracy : 0.9241666666666667\n",
            "430 Train_loss = 0.2562134282083449     Test_loss = 0.2776390198520799\n",
            "\n",
            "Accuracy : 0.9242857142857143\n",
            "431 Train_loss = 0.2559847089906577     Test_loss = 0.27743270972101514\n",
            "\n",
            "Accuracy : 0.924404761904762\n",
            "432 Train_loss = 0.25575631323965947     Test_loss = 0.2772272110601359\n",
            "\n",
            "Accuracy : 0.924404761904762\n",
            "433 Train_loss = 0.2555283457938714     Test_loss = 0.2770224610217368\n",
            "\n",
            "Accuracy : 0.9245238095238095\n",
            "434 Train_loss = 0.2553008345879677     Test_loss = 0.2768176521148834\n",
            "\n",
            "Accuracy : 0.9247619047619048\n",
            "435 Train_loss = 0.2550739483946721     Test_loss = 0.27661390878514863\n",
            "\n",
            "Accuracy : 0.9247619047619048\n",
            "436 Train_loss = 0.2548475550101098     Test_loss = 0.276409987594776\n",
            "\n",
            "Accuracy : 0.9248809523809524\n",
            "437 Train_loss = 0.25462163677407984     Test_loss = 0.27620688344393374\n",
            "\n",
            "Accuracy : 0.925\n",
            "438 Train_loss = 0.2543962271146867     Test_loss = 0.2760039685327616\n",
            "\n",
            "Accuracy : 0.925\n",
            "439 Train_loss = 0.25417131262876724     Test_loss = 0.275801658485392\n",
            "\n",
            "Accuracy : 0.9251190476190476\n",
            "440 Train_loss = 0.2539469031293338     Test_loss = 0.2755996260372415\n",
            "\n",
            "Accuracy : 0.9251190476190476\n",
            "441 Train_loss = 0.2537229465379898     Test_loss = 0.27539804920963584\n",
            "\n",
            "Accuracy : 0.9252380952380952\n",
            "442 Train_loss = 0.25349938278675566     Test_loss = 0.2751971447101443\n",
            "\n",
            "Accuracy : 0.9253571428571429\n",
            "443 Train_loss = 0.25327615175406204     Test_loss = 0.274996198455711\n",
            "\n",
            "Accuracy : 0.9253571428571429\n",
            "444 Train_loss = 0.2530533527395599     Test_loss = 0.2747956835874039\n",
            "\n",
            "Accuracy : 0.9253571428571429\n",
            "445 Train_loss = 0.2528309205456683     Test_loss = 0.27459576896001764\n",
            "\n",
            "Accuracy : 0.9253571428571429\n",
            "446 Train_loss = 0.2526089617181376     Test_loss = 0.2743968772875311\n",
            "\n",
            "Accuracy : 0.9254761904761905\n",
            "447 Train_loss = 0.2523873472142729     Test_loss = 0.27419832851297593\n",
            "\n",
            "Accuracy : 0.9255952380952381\n",
            "448 Train_loss = 0.2521659476359812     Test_loss = 0.27399915446300666\n",
            "\n",
            "Accuracy : 0.9255952380952381\n",
            "449 Train_loss = 0.25194497910210695     Test_loss = 0.2738011113068316\n",
            "\n",
            "Accuracy : 0.9258333333333333\n",
            "450 Train_loss = 0.25172442481806834     Test_loss = 0.2736032472930241\n",
            "\n",
            "Accuracy : 0.9258333333333333\n",
            "451 Train_loss = 0.2515041219086978     Test_loss = 0.2734060226284969\n",
            "\n",
            "Accuracy : 0.9258333333333333\n",
            "452 Train_loss = 0.25128409071978863     Test_loss = 0.27320850546907177\n",
            "\n",
            "Accuracy : 0.925952380952381\n",
            "453 Train_loss = 0.2510644572261636     Test_loss = 0.27301171848569405\n",
            "\n",
            "Accuracy : 0.925952380952381\n",
            "454 Train_loss = 0.2508452556506474     Test_loss = 0.27281545892855574\n",
            "\n",
            "Accuracy : 0.925952380952381\n",
            "455 Train_loss = 0.2506265596869366     Test_loss = 0.272619660432473\n",
            "\n",
            "Accuracy : 0.9260714285714285\n",
            "456 Train_loss = 0.2504082506860475     Test_loss = 0.272424375499681\n",
            "\n",
            "Accuracy : 0.9261904761904762\n",
            "457 Train_loss = 0.2501902801947056     Test_loss = 0.2722293874340544\n",
            "\n",
            "Accuracy : 0.9261904761904762\n",
            "458 Train_loss = 0.2499726183888182     Test_loss = 0.27203458104222267\n",
            "\n",
            "Accuracy : 0.9261904761904762\n",
            "459 Train_loss = 0.24975524428652637     Test_loss = 0.27184015301376235\n",
            "\n",
            "Accuracy : 0.9261904761904762\n",
            "460 Train_loss = 0.24953820655619827     Test_loss = 0.2716454350833447\n",
            "\n",
            "Accuracy : 0.9261904761904762\n",
            "461 Train_loss = 0.24932164612859867     Test_loss = 0.27145241245505375\n",
            "\n",
            "Accuracy : 0.9263095238095238\n",
            "462 Train_loss = 0.24910542415361905     Test_loss = 0.2712586214872861\n",
            "\n",
            "Accuracy : 0.9263095238095238\n",
            "463 Train_loss = 0.24888958144648032     Test_loss = 0.27106557946702303\n",
            "\n",
            "Accuracy : 0.9263095238095238\n",
            "464 Train_loss = 0.24867410357527883     Test_loss = 0.27087236598612113\n",
            "\n",
            "Accuracy : 0.9263095238095238\n",
            "465 Train_loss = 0.2484589768462193     Test_loss = 0.2706790646526876\n",
            "\n",
            "Accuracy : 0.9263095238095238\n",
            "466 Train_loss = 0.24824420490051738     Test_loss = 0.27048626864607916\n",
            "\n",
            "Accuracy : 0.9263095238095238\n",
            "467 Train_loss = 0.2480299192079221     Test_loss = 0.27029364368519015\n",
            "\n",
            "Accuracy : 0.9264285714285714\n",
            "468 Train_loss = 0.2478160694475816     Test_loss = 0.2701016947624337\n",
            "\n",
            "Accuracy : 0.9264285714285714\n",
            "469 Train_loss = 0.24760256814037787     Test_loss = 0.2699099480561146\n",
            "\n",
            "Accuracy : 0.9264285714285714\n",
            "470 Train_loss = 0.24738938599802773     Test_loss = 0.2697186259827421\n",
            "\n",
            "Accuracy : 0.9264285714285714\n",
            "471 Train_loss = 0.24717672620712067     Test_loss = 0.26952741986053447\n",
            "\n",
            "Accuracy : 0.9264285714285714\n",
            "472 Train_loss = 0.2469645247763447     Test_loss = 0.26933690799292415\n",
            "\n",
            "Accuracy : 0.9265476190476191\n",
            "473 Train_loss = 0.24675264596849095     Test_loss = 0.26914647833488503\n",
            "\n",
            "Accuracy : 0.9265476190476191\n",
            "474 Train_loss = 0.24654098530118274     Test_loss = 0.2689558830779833\n",
            "\n",
            "Accuracy : 0.9266666666666666\n",
            "475 Train_loss = 0.24632959541850546     Test_loss = 0.26876635597471166\n",
            "\n",
            "Accuracy : 0.9266666666666666\n",
            "476 Train_loss = 0.24611852814960117     Test_loss = 0.2685766048018377\n",
            "\n",
            "Accuracy : 0.9267857142857143\n",
            "477 Train_loss = 0.2459077940513004     Test_loss = 0.2683872511476371\n",
            "\n",
            "Accuracy : 0.9270238095238095\n",
            "478 Train_loss = 0.24569740601829093     Test_loss = 0.26819810381275716\n",
            "\n",
            "Accuracy : 0.9270238095238095\n",
            "479 Train_loss = 0.24548744494461625     Test_loss = 0.2680095814749805\n",
            "\n",
            "Accuracy : 0.9271428571428572\n",
            "480 Train_loss = 0.24527796552603728     Test_loss = 0.26782131229340705\n",
            "\n",
            "Accuracy : 0.9271428571428572\n",
            "481 Train_loss = 0.24506878227070447     Test_loss = 0.2676336237200317\n",
            "\n",
            "Accuracy : 0.9271428571428572\n",
            "482 Train_loss = 0.24485981679649052     Test_loss = 0.26744632476187996\n",
            "\n",
            "Accuracy : 0.9270238095238095\n",
            "483 Train_loss = 0.2446512328590473     Test_loss = 0.26725906639258556\n",
            "\n",
            "Accuracy : 0.9270238095238095\n",
            "484 Train_loss = 0.24444297857801883     Test_loss = 0.26707206446406756\n",
            "\n",
            "Accuracy : 0.9271428571428572\n",
            "485 Train_loss = 0.24423503093326762     Test_loss = 0.2668850845630179\n",
            "\n",
            "Accuracy : 0.9271428571428572\n",
            "486 Train_loss = 0.24402738319848313     Test_loss = 0.2666984296375728\n",
            "\n",
            "Accuracy : 0.9271428571428572\n",
            "487 Train_loss = 0.24382010210611849     Test_loss = 0.26651249678012123\n",
            "\n",
            "Accuracy : 0.9272619047619047\n",
            "488 Train_loss = 0.24361317711830172     Test_loss = 0.2663265849045724\n",
            "\n",
            "Accuracy : 0.9272619047619047\n",
            "489 Train_loss = 0.24340653003573923     Test_loss = 0.2661408519251723\n",
            "\n",
            "Accuracy : 0.9273809523809524\n",
            "490 Train_loss = 0.24320025286368974     Test_loss = 0.2659551575505926\n",
            "\n",
            "Accuracy : 0.9273809523809524\n",
            "491 Train_loss = 0.24299436717677617     Test_loss = 0.26576952518990377\n",
            "\n",
            "Accuracy : 0.9273809523809524\n",
            "492 Train_loss = 0.2427888145384816     Test_loss = 0.26558449876210716\n",
            "\n",
            "Accuracy : 0.9273809523809524\n",
            "493 Train_loss = 0.24258357744000392     Test_loss = 0.265399866296045\n",
            "\n",
            "Accuracy : 0.9273809523809524\n",
            "494 Train_loss = 0.24237852613088787     Test_loss = 0.265215316221547\n",
            "\n",
            "Accuracy : 0.9276190476190476\n",
            "495 Train_loss = 0.2421736302550557     Test_loss = 0.2650305978274199\n",
            "\n",
            "Accuracy : 0.9276190476190476\n",
            "496 Train_loss = 0.24196906025228618     Test_loss = 0.2648463972108837\n",
            "\n",
            "Accuracy : 0.9277380952380953\n",
            "497 Train_loss = 0.24176466095548033     Test_loss = 0.26466238926638297\n",
            "\n",
            "Accuracy : 0.9277380952380953\n",
            "498 Train_loss = 0.2415605432225915     Test_loss = 0.26447852564376384\n",
            "\n",
            "Accuracy : 0.9278571428571428\n",
            "499 Train_loss = 0.24135674776460092     Test_loss = 0.2642952562958862\n",
            "\n",
            "Accuracy : 0.9278571428571428\n",
            "500 Train_loss = 0.24115311818066995     Test_loss = 0.2641116140515988\n",
            "\n",
            "Accuracy : 0.9280952380952381\n",
            "501 Train_loss = 0.24094978029040562     Test_loss = 0.2639289203994149\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "502 Train_loss = 0.2407467463177488     Test_loss = 0.26374623773152506\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "503 Train_loss = 0.2405439780320893     Test_loss = 0.2635637907267975\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "504 Train_loss = 0.24034146191103892     Test_loss = 0.26338144103970745\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "505 Train_loss = 0.24013910321595763     Test_loss = 0.2631989245761912\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "506 Train_loss = 0.23993710878770402     Test_loss = 0.2630172107574306\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "507 Train_loss = 0.2397354463065924     Test_loss = 0.2628357095240336\n",
            "\n",
            "Accuracy : 0.9279761904761905\n",
            "508 Train_loss = 0.23953403612734175     Test_loss = 0.26265455350018146\n",
            "\n",
            "Accuracy : 0.9280952380952381\n",
            "509 Train_loss = 0.23933292942021342     Test_loss = 0.2624734400434071\n",
            "\n",
            "Accuracy : 0.9280952380952381\n",
            "510 Train_loss = 0.23913208677346526     Test_loss = 0.26229254919942857\n",
            "\n",
            "Accuracy : 0.9280952380952381\n",
            "511 Train_loss = 0.2389314476248745     Test_loss = 0.2621118302697524\n",
            "\n",
            "Accuracy : 0.9280952380952381\n",
            "512 Train_loss = 0.23873108757907835     Test_loss = 0.26193149193178383\n",
            "\n",
            "Accuracy : 0.9282142857142857\n",
            "513 Train_loss = 0.2385309371296196     Test_loss = 0.261751041587037\n",
            "\n",
            "Accuracy : 0.9282142857142857\n",
            "514 Train_loss = 0.23833098384959456     Test_loss = 0.2615709557172741\n",
            "\n",
            "Accuracy : 0.9282142857142857\n",
            "515 Train_loss = 0.23813123107451817     Test_loss = 0.26139136724870543\n",
            "\n",
            "Accuracy : 0.9282142857142857\n",
            "516 Train_loss = 0.23793166181250372     Test_loss = 0.26121237449591\n",
            "\n",
            "Accuracy : 0.9282142857142857\n",
            "517 Train_loss = 0.23773242700360472     Test_loss = 0.2610334837944326\n",
            "\n",
            "Accuracy : 0.9283333333333333\n",
            "518 Train_loss = 0.23753358758065526     Test_loss = 0.2608546642769273\n",
            "\n",
            "Accuracy : 0.9283333333333333\n",
            "519 Train_loss = 0.23733513098169767     Test_loss = 0.2606763825265089\n",
            "\n",
            "Accuracy : 0.9284523809523809\n",
            "520 Train_loss = 0.23713693152475035     Test_loss = 0.2604978461183488\n",
            "\n",
            "Accuracy : 0.9286904761904762\n",
            "521 Train_loss = 0.23693882865050284     Test_loss = 0.26031964901554516\n",
            "\n",
            "Accuracy : 0.9286904761904762\n",
            "522 Train_loss = 0.23674104492760525     Test_loss = 0.26014207975475645\n",
            "\n",
            "Accuracy : 0.9286904761904762\n",
            "523 Train_loss = 0.23654338626724     Test_loss = 0.25996427403951056\n",
            "\n",
            "Accuracy : 0.9286904761904762\n",
            "524 Train_loss = 0.23634584051103755     Test_loss = 0.2597868965397988\n",
            "\n",
            "Accuracy : 0.9288095238095238\n",
            "525 Train_loss = 0.23614851111737795     Test_loss = 0.2596094958038714\n",
            "\n",
            "Accuracy : 0.9288095238095238\n",
            "526 Train_loss = 0.2359513388370085     Test_loss = 0.2594317085945072\n",
            "\n",
            "Accuracy : 0.9288095238095238\n",
            "527 Train_loss = 0.23575450643099477     Test_loss = 0.2592551755049703\n",
            "\n",
            "Accuracy : 0.9288095238095238\n",
            "528 Train_loss = 0.23555795945746316     Test_loss = 0.259078622312802\n",
            "\n",
            "Accuracy : 0.9289285714285714\n",
            "529 Train_loss = 0.2353616706751834     Test_loss = 0.25890280396157994\n",
            "\n",
            "Accuracy : 0.929047619047619\n",
            "530 Train_loss = 0.23516566058802446     Test_loss = 0.2587268638630515\n",
            "\n",
            "Accuracy : 0.929047619047619\n",
            "531 Train_loss = 0.2349698884189298     Test_loss = 0.2585517792828705\n",
            "\n",
            "Accuracy : 0.9289285714285714\n",
            "532 Train_loss = 0.2347743459824756     Test_loss = 0.2583761998116025\n",
            "\n",
            "Accuracy : 0.9289285714285714\n",
            "533 Train_loss = 0.23457903970414068     Test_loss = 0.2582005777102201\n",
            "\n",
            "Accuracy : 0.929047619047619\n",
            "534 Train_loss = 0.23438405686802818     Test_loss = 0.25802562558468184\n",
            "\n",
            "Accuracy : 0.9291666666666667\n",
            "535 Train_loss = 0.2341892893245683     Test_loss = 0.2578508059005893\n",
            "\n",
            "Accuracy : 0.9294047619047618\n",
            "536 Train_loss = 0.23399480115165688     Test_loss = 0.2576758021503278\n",
            "\n",
            "Accuracy : 0.9297619047619048\n",
            "537 Train_loss = 0.23380062535279109     Test_loss = 0.25750137053692457\n",
            "\n",
            "Accuracy : 0.9297619047619048\n",
            "538 Train_loss = 0.23360673299535561     Test_loss = 0.25732726696864255\n",
            "\n",
            "Accuracy : 0.9297619047619048\n",
            "539 Train_loss = 0.23341319989267792     Test_loss = 0.25715335903783904\n",
            "\n",
            "Accuracy : 0.9298809523809524\n",
            "540 Train_loss = 0.23321990888395824     Test_loss = 0.2569798993414346\n",
            "\n",
            "Accuracy : 0.9298809523809524\n",
            "541 Train_loss = 0.23302683192015466     Test_loss = 0.25680640665108717\n",
            "\n",
            "Accuracy : 0.9298809523809524\n",
            "542 Train_loss = 0.2328340712308988     Test_loss = 0.256633750382091\n",
            "\n",
            "Accuracy : 0.9301190476190476\n",
            "543 Train_loss = 0.23264157273245234     Test_loss = 0.25646136974612876\n",
            "\n",
            "Accuracy : 0.9301190476190476\n",
            "544 Train_loss = 0.23244924881547024     Test_loss = 0.2562890891703035\n",
            "\n",
            "Accuracy : 0.9301190476190476\n",
            "545 Train_loss = 0.2322571154508338     Test_loss = 0.2561166983800985\n",
            "\n",
            "Accuracy : 0.9303571428571429\n",
            "546 Train_loss = 0.23206497732949624     Test_loss = 0.2559448215273435\n",
            "\n",
            "Accuracy : 0.9303571428571429\n",
            "547 Train_loss = 0.2318729383561539     Test_loss = 0.25577287620425576\n",
            "\n",
            "Accuracy : 0.9303571428571429\n",
            "548 Train_loss = 0.2316810058978324     Test_loss = 0.255601594925158\n",
            "\n",
            "Accuracy : 0.9304761904761905\n",
            "549 Train_loss = 0.23148937532457856     Test_loss = 0.25543009040485476\n",
            "\n",
            "Accuracy : 0.9307142857142857\n",
            "550 Train_loss = 0.23129803264990273     Test_loss = 0.25525945052469934\n",
            "\n",
            "Accuracy : 0.9307142857142857\n",
            "551 Train_loss = 0.2311068301834372     Test_loss = 0.25508812853865603\n",
            "\n",
            "Accuracy : 0.9308333333333333\n",
            "552 Train_loss = 0.23091585295631134     Test_loss = 0.254917862854852\n",
            "\n",
            "Accuracy : 0.930952380952381\n",
            "553 Train_loss = 0.23072511190587375     Test_loss = 0.2547472807421504\n",
            "\n",
            "Accuracy : 0.9310714285714285\n",
            "554 Train_loss = 0.2305345917382328     Test_loss = 0.25457737994805585\n",
            "\n",
            "Accuracy : 0.9310714285714285\n",
            "555 Train_loss = 0.2303442611005253     Test_loss = 0.2544074430010017\n",
            "\n",
            "Accuracy : 0.9310714285714285\n",
            "556 Train_loss = 0.2301540410139088     Test_loss = 0.25423756808852427\n",
            "\n",
            "Accuracy : 0.9313095238095238\n",
            "557 Train_loss = 0.22996391037608074     Test_loss = 0.2540679221096577\n",
            "\n",
            "Accuracy : 0.9313095238095238\n",
            "558 Train_loss = 0.2297740341435608     Test_loss = 0.25389879400929904\n",
            "\n",
            "Accuracy : 0.9313095238095238\n",
            "559 Train_loss = 0.22958433507067116     Test_loss = 0.25372931987142455\n",
            "\n",
            "Accuracy : 0.9314285714285714\n",
            "560 Train_loss = 0.22939477319796533     Test_loss = 0.2535601942972551\n",
            "\n",
            "Accuracy : 0.9314285714285714\n",
            "561 Train_loss = 0.22920540720960506     Test_loss = 0.2533915211217803\n",
            "\n",
            "Accuracy : 0.9314285714285714\n",
            "562 Train_loss = 0.22901620738932627     Test_loss = 0.25322306694961033\n",
            "\n",
            "Accuracy : 0.9315476190476191\n",
            "563 Train_loss = 0.228827194565339     Test_loss = 0.2530551208771195\n",
            "\n",
            "Accuracy : 0.9315476190476191\n",
            "564 Train_loss = 0.22863835312971828     Test_loss = 0.2528870652850886\n",
            "\n",
            "Accuracy : 0.9317857142857143\n",
            "565 Train_loss = 0.22844970685044205     Test_loss = 0.2527192725965101\n",
            "\n",
            "Accuracy : 0.9319047619047619\n",
            "566 Train_loss = 0.22826134696851375     Test_loss = 0.25255226279907717\n",
            "\n",
            "Accuracy : 0.9320238095238095\n",
            "567 Train_loss = 0.2280732030869141     Test_loss = 0.2523850178886707\n",
            "\n",
            "Accuracy : 0.9320238095238095\n",
            "568 Train_loss = 0.2278852813804838     Test_loss = 0.25221758693875185\n",
            "\n",
            "Accuracy : 0.9320238095238095\n",
            "569 Train_loss = 0.22769765931721742     Test_loss = 0.2520508756541914\n",
            "\n",
            "Accuracy : 0.9321428571428572\n",
            "570 Train_loss = 0.22751039148828256     Test_loss = 0.2518841617290996\n",
            "\n",
            "Accuracy : 0.9321428571428572\n",
            "571 Train_loss = 0.22732335323116568     Test_loss = 0.25171750604464554\n",
            "\n",
            "Accuracy : 0.9321428571428572\n",
            "572 Train_loss = 0.22713655474847055     Test_loss = 0.2515513215190059\n",
            "\n",
            "Accuracy : 0.9321428571428572\n",
            "573 Train_loss = 0.2269499615757372     Test_loss = 0.25138436705315537\n",
            "\n",
            "Accuracy : 0.9321428571428572\n",
            "574 Train_loss = 0.22676370538303492     Test_loss = 0.2512181061404909\n",
            "\n",
            "Accuracy : 0.9322619047619047\n",
            "575 Train_loss = 0.22657761776724947     Test_loss = 0.2510517791733916\n",
            "\n",
            "Accuracy : 0.9322619047619047\n",
            "576 Train_loss = 0.22639170519308313     Test_loss = 0.250886213266791\n",
            "\n",
            "Accuracy : 0.9323809523809524\n",
            "577 Train_loss = 0.22620605513741068     Test_loss = 0.25072055428924594\n",
            "\n",
            "Accuracy : 0.9325\n",
            "578 Train_loss = 0.22602067840525142     Test_loss = 0.25055541372917833\n",
            "\n",
            "Accuracy : 0.9326190476190477\n",
            "579 Train_loss = 0.2258354427715989     Test_loss = 0.25039023186048376\n",
            "\n",
            "Accuracy : 0.9326190476190477\n",
            "580 Train_loss = 0.22565041664278507     Test_loss = 0.25022547765697056\n",
            "\n",
            "Accuracy : 0.9326190476190477\n",
            "581 Train_loss = 0.22546560633651744     Test_loss = 0.25006070927229973\n",
            "\n",
            "Accuracy : 0.9327380952380953\n",
            "582 Train_loss = 0.2252810158914326     Test_loss = 0.24989593875219318\n",
            "\n",
            "Accuracy : 0.9327380952380953\n",
            "583 Train_loss = 0.22509657623138332     Test_loss = 0.2497316907382694\n",
            "\n",
            "Accuracy : 0.9329761904761905\n",
            "584 Train_loss = 0.22491226053190091     Test_loss = 0.24956717169068346\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "585 Train_loss = 0.22472814037056843     Test_loss = 0.24940299738874203\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "586 Train_loss = 0.2245442749729262     Test_loss = 0.24923912445848861\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "587 Train_loss = 0.224360724282118     Test_loss = 0.24907537266004273\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "588 Train_loss = 0.22417743083086908     Test_loss = 0.24891218919032804\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "589 Train_loss = 0.22399435255211153     Test_loss = 0.24874938104910035\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "590 Train_loss = 0.2238114503577623     Test_loss = 0.24858682431588872\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "591 Train_loss = 0.22362873553184578     Test_loss = 0.24842400614561203\n",
            "\n",
            "Accuracy : 0.9332142857142858\n",
            "592 Train_loss = 0.22344621474906537     Test_loss = 0.24826129508942818\n",
            "\n",
            "Accuracy : 0.9332142857142858\n",
            "593 Train_loss = 0.223263927820883     Test_loss = 0.24809879829611894\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "594 Train_loss = 0.22308199786904617     Test_loss = 0.2479371990868707\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "595 Train_loss = 0.22290038138244045     Test_loss = 0.2477749413178317\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "596 Train_loss = 0.2227190342546144     Test_loss = 0.24761342024463223\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "597 Train_loss = 0.22253781467563266     Test_loss = 0.24745179827375047\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "598 Train_loss = 0.22235663372672151     Test_loss = 0.24729041501068985\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "599 Train_loss = 0.2221755618182877     Test_loss = 0.24712828012436028\n",
            "\n",
            "Accuracy : 0.9330952380952381\n",
            "600 Train_loss = 0.22199467620244095     Test_loss = 0.24696756923362678\n",
            "\n",
            "Accuracy : 0.9332142857142858\n",
            "601 Train_loss = 0.22181394305893062     Test_loss = 0.24680619160741538\n",
            "\n",
            "Accuracy : 0.9333333333333333\n",
            "602 Train_loss = 0.22163332816610834     Test_loss = 0.24664537811714912\n",
            "\n",
            "Accuracy : 0.9333333333333333\n",
            "603 Train_loss = 0.2214529362619626     Test_loss = 0.24648437070090093\n",
            "\n",
            "Accuracy : 0.9333333333333333\n",
            "604 Train_loss = 0.2212728441923945     Test_loss = 0.2463240289208161\n",
            "\n",
            "Accuracy : 0.9333333333333333\n",
            "605 Train_loss = 0.22109301749866112     Test_loss = 0.24616318724021832\n",
            "\n",
            "Accuracy : 0.9333333333333333\n",
            "606 Train_loss = 0.2209132477639655     Test_loss = 0.2460031791697732\n",
            "\n",
            "Accuracy : 0.9333333333333333\n",
            "607 Train_loss = 0.22073356468915517     Test_loss = 0.24584268211197213\n",
            "\n",
            "Accuracy : 0.9334523809523809\n",
            "608 Train_loss = 0.22055409670147794     Test_loss = 0.24568278709306665\n",
            "\n",
            "Accuracy : 0.9334523809523809\n",
            "609 Train_loss = 0.22037485812007432     Test_loss = 0.24552251159989585\n",
            "\n",
            "Accuracy : 0.9335714285714286\n",
            "610 Train_loss = 0.22019590018210453     Test_loss = 0.24536280441754435\n",
            "\n",
            "Accuracy : 0.9335714285714286\n",
            "611 Train_loss = 0.22001718731357103     Test_loss = 0.24520317536869513\n",
            "\n",
            "Accuracy : 0.9335714285714286\n",
            "612 Train_loss = 0.21983871172996447     Test_loss = 0.24504325957950474\n",
            "\n",
            "Accuracy : 0.9335714285714286\n",
            "613 Train_loss = 0.21966047510808648     Test_loss = 0.24488421054494547\n",
            "\n",
            "Accuracy : 0.9335714285714286\n",
            "614 Train_loss = 0.21948245334288696     Test_loss = 0.24472505595788882\n",
            "\n",
            "Accuracy : 0.9336904761904762\n",
            "615 Train_loss = 0.21930461439056437     Test_loss = 0.24456620832409298\n",
            "\n",
            "Accuracy : 0.9338095238095239\n",
            "616 Train_loss = 0.21912700183651224     Test_loss = 0.2444079290243273\n",
            "\n",
            "Accuracy : 0.9339285714285714\n",
            "617 Train_loss = 0.21894959547287224     Test_loss = 0.24424978885293946\n",
            "\n",
            "Accuracy : 0.9339285714285714\n",
            "618 Train_loss = 0.21877245724869787     Test_loss = 0.24409184001340703\n",
            "\n",
            "Accuracy : 0.9339285714285714\n",
            "619 Train_loss = 0.21859553200620457     Test_loss = 0.24393398604661104\n",
            "\n",
            "Accuracy : 0.9339285714285714\n",
            "620 Train_loss = 0.21841879751832735     Test_loss = 0.24377633971793763\n",
            "\n",
            "Accuracy : 0.934047619047619\n",
            "621 Train_loss = 0.21824224774619858     Test_loss = 0.2436186374857512\n",
            "\n",
            "Accuracy : 0.934047619047619\n",
            "622 Train_loss = 0.21806591618963767     Test_loss = 0.2434611895751375\n",
            "\n",
            "Accuracy : 0.9341666666666667\n",
            "623 Train_loss = 0.21788963419477067     Test_loss = 0.2433036952866332\n",
            "\n",
            "Accuracy : 0.9341666666666667\n",
            "624 Train_loss = 0.21771358099297364     Test_loss = 0.24314628797353785\n",
            "\n",
            "Accuracy : 0.9341666666666667\n",
            "625 Train_loss = 0.21753777876167602     Test_loss = 0.2429892566582332\n",
            "\n",
            "Accuracy : 0.9341666666666667\n",
            "626 Train_loss = 0.21736224147115737     Test_loss = 0.24283233262564666\n",
            "\n",
            "Accuracy : 0.9342857142857143\n",
            "627 Train_loss = 0.21718689809517305     Test_loss = 0.24267593136432974\n",
            "\n",
            "Accuracy : 0.9342857142857143\n",
            "628 Train_loss = 0.2170116842498616     Test_loss = 0.24251934508131381\n",
            "\n",
            "Accuracy : 0.9342857142857143\n",
            "629 Train_loss = 0.2168366300501396     Test_loss = 0.24236285672965419\n",
            "\n",
            "Accuracy : 0.934404761904762\n",
            "630 Train_loss = 0.21666172788203744     Test_loss = 0.24220687398093735\n",
            "\n",
            "Accuracy : 0.934404761904762\n",
            "631 Train_loss = 0.2164870780202409     Test_loss = 0.24205125633939253\n",
            "\n",
            "Accuracy : 0.9345238095238095\n",
            "632 Train_loss = 0.21631262847950064     Test_loss = 0.24189551953453697\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "633 Train_loss = 0.2161383793343197     Test_loss = 0.24174040434407482\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "634 Train_loss = 0.21596438649632285     Test_loss = 0.24158516023589052\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "635 Train_loss = 0.21579063872282522     Test_loss = 0.24143025958285158\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "636 Train_loss = 0.21561714030366372     Test_loss = 0.2412753304549091\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "637 Train_loss = 0.21544379353284013     Test_loss = 0.24112096798649657\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "638 Train_loss = 0.21527058084489584     Test_loss = 0.24096639198393938\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "639 Train_loss = 0.21509744340904843     Test_loss = 0.2408120481804441\n",
            "\n",
            "Accuracy : 0.9346428571428571\n",
            "640 Train_loss = 0.21492449666648708     Test_loss = 0.2406580820577736\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "641 Train_loss = 0.21475163749209084     Test_loss = 0.24050377478706514\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "642 Train_loss = 0.21457895916741465     Test_loss = 0.24034962036204827\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "643 Train_loss = 0.21440643221650618     Test_loss = 0.24019612609245813\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "644 Train_loss = 0.21423408712673223     Test_loss = 0.2400423684595273\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "645 Train_loss = 0.21406182652015443     Test_loss = 0.239888486463628\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "646 Train_loss = 0.21388961770902265     Test_loss = 0.23973439494217755\n",
            "\n",
            "Accuracy : 0.9347619047619048\n",
            "647 Train_loss = 0.21371769766027088     Test_loss = 0.23958089367413907\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "648 Train_loss = 0.2135460095869717     Test_loss = 0.23942681266074958\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "649 Train_loss = 0.2133745911165751     Test_loss = 0.23927355360481567\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "650 Train_loss = 0.21320348928171726     Test_loss = 0.23912048221382698\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "651 Train_loss = 0.21303266953427236     Test_loss = 0.23896813715090645\n",
            "\n",
            "Accuracy : 0.935\n",
            "652 Train_loss = 0.2128619506528552     Test_loss = 0.2388156999808784\n",
            "\n",
            "Accuracy : 0.935\n",
            "653 Train_loss = 0.2126912352046479     Test_loss = 0.23866312659232813\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "654 Train_loss = 0.21252088585711423     Test_loss = 0.23851119293199355\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "655 Train_loss = 0.2123507819802844     Test_loss = 0.23835981139234091\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "656 Train_loss = 0.2121809545184939     Test_loss = 0.23820848303025388\n",
            "\n",
            "Accuracy : 0.9348809523809524\n",
            "657 Train_loss = 0.21201121751469307     Test_loss = 0.23805672226639762\n",
            "\n",
            "Accuracy : 0.935\n",
            "658 Train_loss = 0.21184163896965758     Test_loss = 0.2379051473670212\n",
            "\n",
            "Accuracy : 0.935\n",
            "659 Train_loss = 0.2116723588731791     Test_loss = 0.23775406505929164\n",
            "\n",
            "Accuracy : 0.9351190476190476\n",
            "660 Train_loss = 0.21150323804523133     Test_loss = 0.237602722481699\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "661 Train_loss = 0.21133432508482958     Test_loss = 0.23745193453856708\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "662 Train_loss = 0.21116569874176733     Test_loss = 0.23730179037141338\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "663 Train_loss = 0.21099728894268818     Test_loss = 0.23715152655485094\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "664 Train_loss = 0.21082907458000422     Test_loss = 0.23700156299119918\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "665 Train_loss = 0.2106611250978607     Test_loss = 0.2368521378166819\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "666 Train_loss = 0.2104934072193985     Test_loss = 0.23670272652333763\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "667 Train_loss = 0.2103259863216884     Test_loss = 0.236553765677287\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "668 Train_loss = 0.21015873946554298     Test_loss = 0.23640497126735838\n",
            "\n",
            "Accuracy : 0.9353571428571429\n",
            "669 Train_loss = 0.20999162226918358     Test_loss = 0.23625654837700022\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "670 Train_loss = 0.20982470776866244     Test_loss = 0.2361080510636928\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "671 Train_loss = 0.20965804983515782     Test_loss = 0.23595972582796504\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "672 Train_loss = 0.20949155558763824     Test_loss = 0.23581175948596717\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "673 Train_loss = 0.2093251365326972     Test_loss = 0.2356634274545947\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "674 Train_loss = 0.20915890082494115     Test_loss = 0.23551601453002693\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "675 Train_loss = 0.20899278484344022     Test_loss = 0.23536855921622368\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "676 Train_loss = 0.20882691245511778     Test_loss = 0.23522113413432705\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "677 Train_loss = 0.20866132110900845     Test_loss = 0.23507407405966735\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "678 Train_loss = 0.20849594367815136     Test_loss = 0.23492709775856313\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "679 Train_loss = 0.2083307524652228     Test_loss = 0.23478022052825115\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "680 Train_loss = 0.20816573978497693     Test_loss = 0.23463341560916615\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "681 Train_loss = 0.20800088246478476     Test_loss = 0.23448657508443446\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "682 Train_loss = 0.20783628316031666     Test_loss = 0.23434039045260247\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "683 Train_loss = 0.20767188199171174     Test_loss = 0.23419385634795567\n",
            "\n",
            "Accuracy : 0.9354761904761905\n",
            "684 Train_loss = 0.20750767599510736     Test_loss = 0.23404818664652022\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "685 Train_loss = 0.20734363267846792     Test_loss = 0.23390248978838582\n",
            "\n",
            "Accuracy : 0.9355952380952381\n",
            "686 Train_loss = 0.20717984315382337     Test_loss = 0.23375692792609004\n",
            "\n",
            "Accuracy : 0.9357142857142857\n",
            "687 Train_loss = 0.20701618827573104     Test_loss = 0.2336120230533676\n",
            "\n",
            "Accuracy : 0.9357142857142857\n",
            "688 Train_loss = 0.20685270277461343     Test_loss = 0.2334663955939511\n",
            "\n",
            "Accuracy : 0.9358333333333333\n",
            "689 Train_loss = 0.20668933987963917     Test_loss = 0.23332124241016108\n",
            "\n",
            "Accuracy : 0.9358333333333333\n",
            "690 Train_loss = 0.2065261325094876     Test_loss = 0.2331761659297731\n",
            "\n",
            "Accuracy : 0.9358333333333333\n",
            "691 Train_loss = 0.20636310425336774     Test_loss = 0.233031356029545\n",
            "\n",
            "Accuracy : 0.9357142857142857\n",
            "692 Train_loss = 0.20620038045966332     Test_loss = 0.23288683753244543\n",
            "\n",
            "Accuracy : 0.9358333333333333\n",
            "693 Train_loss = 0.20603775735015212     Test_loss = 0.23274252295941772\n",
            "\n",
            "Accuracy : 0.935952380952381\n",
            "694 Train_loss = 0.2058753199963195     Test_loss = 0.23259818276388944\n",
            "\n",
            "Accuracy : 0.935952380952381\n",
            "695 Train_loss = 0.20571295406184234     Test_loss = 0.23245417376015437\n",
            "\n",
            "Accuracy : 0.935952380952381\n",
            "696 Train_loss = 0.2055507879507367     Test_loss = 0.23231064937057674\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "697 Train_loss = 0.20538883044056505     Test_loss = 0.23216712062613426\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "698 Train_loss = 0.20522694643291034     Test_loss = 0.23202377561828222\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "699 Train_loss = 0.2050652944915616     Test_loss = 0.23188061347935943\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "700 Train_loss = 0.20490385258088792     Test_loss = 0.23173715248115814\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "701 Train_loss = 0.20474273499364365     Test_loss = 0.2315942302662633\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "702 Train_loss = 0.20458183947576267     Test_loss = 0.2314515741975884\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "703 Train_loss = 0.20442138833648826     Test_loss = 0.2313093247677277\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "704 Train_loss = 0.2042611217579489     Test_loss = 0.23116689588190337\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "705 Train_loss = 0.20410105443571758     Test_loss = 0.23102502755715024\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "706 Train_loss = 0.20394121460130302     Test_loss = 0.23088299651353952\n",
            "\n",
            "Accuracy : 0.9360714285714286\n",
            "707 Train_loss = 0.20378165173749518     Test_loss = 0.23074189171210094\n",
            "\n",
            "Accuracy : 0.9361904761904762\n",
            "708 Train_loss = 0.20362224539719112     Test_loss = 0.2306004942133817\n",
            "\n",
            "Accuracy : 0.9363095238095238\n",
            "709 Train_loss = 0.2034631170532393     Test_loss = 0.2304594264850359\n",
            "\n",
            "Accuracy : 0.9363095238095238\n",
            "710 Train_loss = 0.20330424618457754     Test_loss = 0.23031811345544143\n",
            "\n",
            "Accuracy : 0.9363095238095238\n",
            "711 Train_loss = 0.20314558047913606     Test_loss = 0.23017771871400036\n",
            "\n",
            "Accuracy : 0.9364285714285714\n",
            "712 Train_loss = 0.2029870974616689     Test_loss = 0.23003683879746178\n",
            "\n",
            "Accuracy : 0.9365476190476191\n",
            "713 Train_loss = 0.20282893092492577     Test_loss = 0.22989628412311786\n",
            "\n",
            "Accuracy : 0.9364285714285714\n",
            "714 Train_loss = 0.20267104048144644     Test_loss = 0.22975615976495128\n",
            "\n",
            "Accuracy : 0.9364285714285714\n",
            "715 Train_loss = 0.20251332064645625     Test_loss = 0.22961569619521674\n",
            "\n",
            "Accuracy : 0.9364285714285714\n",
            "716 Train_loss = 0.2023557727379562     Test_loss = 0.22947542467267448\n",
            "\n",
            "Accuracy : 0.9364285714285714\n",
            "717 Train_loss = 0.20219826196530177     Test_loss = 0.2293349287681019\n",
            "\n",
            "Accuracy : 0.9365476190476191\n",
            "718 Train_loss = 0.20204094058500538     Test_loss = 0.22919513018266482\n",
            "\n",
            "Accuracy : 0.9365476190476191\n",
            "719 Train_loss = 0.20188378506740468     Test_loss = 0.22905545461846705\n",
            "\n",
            "Accuracy : 0.9367857142857143\n",
            "720 Train_loss = 0.20172675566047024     Test_loss = 0.22891535207305438\n",
            "\n",
            "Accuracy : 0.9369047619047619\n",
            "721 Train_loss = 0.20156982626952147     Test_loss = 0.2287756153294917\n",
            "\n",
            "Accuracy : 0.9369047619047619\n",
            "722 Train_loss = 0.20141298850544795     Test_loss = 0.22863576685571196\n",
            "\n",
            "Accuracy : 0.9369047619047619\n",
            "723 Train_loss = 0.20125629158972688     Test_loss = 0.2284955699954005\n",
            "\n",
            "Accuracy : 0.9371428571428572\n",
            "724 Train_loss = 0.2010997678169099     Test_loss = 0.22835648243036166\n",
            "\n",
            "Accuracy : 0.9371428571428572\n",
            "725 Train_loss = 0.20094343690082622     Test_loss = 0.228217045614377\n",
            "\n",
            "Accuracy : 0.9371428571428572\n",
            "726 Train_loss = 0.20078728808366803     Test_loss = 0.22807792091990348\n",
            "\n",
            "Accuracy : 0.9371428571428572\n",
            "727 Train_loss = 0.20063127969120823     Test_loss = 0.22793898056349668\n",
            "\n",
            "Accuracy : 0.9373809523809524\n",
            "728 Train_loss = 0.20047540631533403     Test_loss = 0.22779998886809516\n",
            "\n",
            "Accuracy : 0.9373809523809524\n",
            "729 Train_loss = 0.20031964034925281     Test_loss = 0.22766139371818653\n",
            "\n",
            "Accuracy : 0.9373809523809524\n",
            "730 Train_loss = 0.20016416360248646     Test_loss = 0.22752338850941684\n",
            "\n",
            "Accuracy : 0.9373809523809524\n",
            "731 Train_loss = 0.20000887413457927     Test_loss = 0.22738470157829851\n",
            "\n",
            "Accuracy : 0.9373809523809524\n",
            "732 Train_loss = 0.19985365015271456     Test_loss = 0.22724639561628315\n",
            "\n",
            "Accuracy : 0.9375\n",
            "733 Train_loss = 0.19969857200006658     Test_loss = 0.22710813124089868\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "734 Train_loss = 0.1995436302911033     Test_loss = 0.22696950006615177\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "735 Train_loss = 0.19938872241872793     Test_loss = 0.22683118033581404\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "736 Train_loss = 0.19923402797258755     Test_loss = 0.22669308147376174\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "737 Train_loss = 0.19907955196582064     Test_loss = 0.22655538154198118\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "738 Train_loss = 0.19892537878220198     Test_loss = 0.22641818062254526\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "739 Train_loss = 0.19877141204626117     Test_loss = 0.22628076757888707\n",
            "\n",
            "Accuracy : 0.9375\n",
            "740 Train_loss = 0.19861767545761178     Test_loss = 0.22614366801549018\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "741 Train_loss = 0.19846412293792126     Test_loss = 0.22600728468990752\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "742 Train_loss = 0.19831085482441327     Test_loss = 0.22587112542661109\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "743 Train_loss = 0.19815775067188915     Test_loss = 0.22573548912696587\n",
            "\n",
            "Accuracy : 0.9376190476190476\n",
            "744 Train_loss = 0.19800482526568206     Test_loss = 0.22559945848589227\n",
            "\n",
            "Accuracy : 0.9378571428571428\n",
            "745 Train_loss = 0.19785204006764717     Test_loss = 0.22546455399045356\n",
            "\n",
            "Accuracy : 0.9379761904761905\n",
            "746 Train_loss = 0.1976994283815554     Test_loss = 0.22532920971719161\n",
            "\n",
            "Accuracy : 0.9379761904761905\n",
            "747 Train_loss = 0.19754699052691235     Test_loss = 0.22519460937152389\n",
            "\n",
            "Accuracy : 0.9379761904761905\n",
            "748 Train_loss = 0.19739471179519474     Test_loss = 0.22505988895762066\n",
            "\n",
            "Accuracy : 0.9378571428571428\n",
            "749 Train_loss = 0.19724267800382128     Test_loss = 0.22492534244138787\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "750 Train_loss = 0.1970909091814907     Test_loss = 0.2247911075639737\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "751 Train_loss = 0.19693933873878847     Test_loss = 0.22465685722688344\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "752 Train_loss = 0.1967879830585929     Test_loss = 0.2245230000861234\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "753 Train_loss = 0.19663681687042658     Test_loss = 0.224389109676442\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "754 Train_loss = 0.19648584816315265     Test_loss = 0.22425560993072258\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "755 Train_loss = 0.19633510307116017     Test_loss = 0.2241221517847256\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "756 Train_loss = 0.19618449759865525     Test_loss = 0.22398922328695195\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "757 Train_loss = 0.19603418112346133     Test_loss = 0.22385695630188235\n",
            "\n",
            "Accuracy : 0.9377380952380953\n",
            "758 Train_loss = 0.1958841600343809     Test_loss = 0.2237242479199914\n",
            "\n",
            "Accuracy : 0.9379761904761905\n",
            "759 Train_loss = 0.1957343920380818     Test_loss = 0.2235921063071412\n",
            "\n",
            "Accuracy : 0.9379761904761905\n",
            "760 Train_loss = 0.19558471238852992     Test_loss = 0.22346016321336679\n",
            "\n",
            "Accuracy : 0.9382142857142857\n",
            "761 Train_loss = 0.19543521922904616     Test_loss = 0.22332802123524226\n",
            "\n",
            "Accuracy : 0.9382142857142857\n",
            "762 Train_loss = 0.1952858875835507     Test_loss = 0.22319626433404294\n",
            "\n",
            "Accuracy : 0.9383333333333334\n",
            "763 Train_loss = 0.19513660717058337     Test_loss = 0.22306431066345445\n",
            "\n",
            "Accuracy : 0.9384523809523809\n",
            "764 Train_loss = 0.19498752736335445     Test_loss = 0.2229326831816006\n",
            "\n",
            "Accuracy : 0.9384523809523809\n",
            "765 Train_loss = 0.19483868309186755     Test_loss = 0.22280193343182575\n",
            "\n",
            "Accuracy : 0.9385714285714286\n",
            "766 Train_loss = 0.19469011201306594     Test_loss = 0.22267100295988623\n",
            "\n",
            "Accuracy : 0.9385714285714286\n",
            "767 Train_loss = 0.1945418183539842     Test_loss = 0.2225403577759954\n",
            "\n",
            "Accuracy : 0.9386904761904762\n",
            "768 Train_loss = 0.1943937718962463     Test_loss = 0.22240979218697554\n",
            "\n",
            "Accuracy : 0.9388095238095238\n",
            "769 Train_loss = 0.19424594029475492     Test_loss = 0.22227935463405832\n",
            "\n",
            "Accuracy : 0.9389285714285714\n",
            "770 Train_loss = 0.19409828292434     Test_loss = 0.2221494634219114\n",
            "\n",
            "Accuracy : 0.9389285714285714\n",
            "771 Train_loss = 0.1939508578766343     Test_loss = 0.22201923761119932\n",
            "\n",
            "Accuracy : 0.9389285714285714\n",
            "772 Train_loss = 0.19380359182606965     Test_loss = 0.22188955113031913\n",
            "\n",
            "Accuracy : 0.939047619047619\n",
            "773 Train_loss = 0.19365641645166198     Test_loss = 0.2217602224373156\n",
            "\n",
            "Accuracy : 0.939047619047619\n",
            "774 Train_loss = 0.19350933205224996     Test_loss = 0.22163040370029752\n",
            "\n",
            "Accuracy : 0.939047619047619\n",
            "775 Train_loss = 0.19336244977138575     Test_loss = 0.22150087919078945\n",
            "\n",
            "Accuracy : 0.9391666666666667\n",
            "776 Train_loss = 0.1932158258275993     Test_loss = 0.2213722214970081\n",
            "\n",
            "Accuracy : 0.9391666666666667\n",
            "777 Train_loss = 0.19306927601263335     Test_loss = 0.221243420615227\n",
            "\n",
            "Accuracy : 0.9391666666666667\n",
            "778 Train_loss = 0.19292274193533945     Test_loss = 0.22111441737474216\n",
            "\n",
            "Accuracy : 0.9391666666666667\n",
            "779 Train_loss = 0.19277618941166538     Test_loss = 0.22098514861368768\n",
            "\n",
            "Accuracy : 0.9392857142857143\n",
            "780 Train_loss = 0.19262978558424812     Test_loss = 0.2208558836189398\n",
            "\n",
            "Accuracy : 0.9392857142857143\n",
            "781 Train_loss = 0.1924835512783334     Test_loss = 0.22072719727121826\n",
            "\n",
            "Accuracy : 0.9394047619047619\n",
            "782 Train_loss = 0.19233745527062776     Test_loss = 0.22059825296895175\n",
            "\n",
            "Accuracy : 0.9394047619047619\n",
            "783 Train_loss = 0.19219161101860668     Test_loss = 0.22047005785194973\n",
            "\n",
            "Accuracy : 0.9395238095238095\n",
            "784 Train_loss = 0.19204589362592986     Test_loss = 0.22034130327465265\n",
            "\n",
            "Accuracy : 0.9395238095238095\n",
            "785 Train_loss = 0.19190038935843787     Test_loss = 0.22021323837502346\n",
            "\n",
            "Accuracy : 0.9395238095238095\n",
            "786 Train_loss = 0.19175512990132862     Test_loss = 0.22008558138674492\n",
            "\n",
            "Accuracy : 0.9395238095238095\n",
            "787 Train_loss = 0.19161006006856598     Test_loss = 0.21995813652554483\n",
            "\n",
            "Accuracy : 0.9395238095238095\n",
            "788 Train_loss = 0.19146513974944235     Test_loss = 0.21983071870302215\n",
            "\n",
            "Accuracy : 0.9395238095238095\n",
            "789 Train_loss = 0.19132041771769392     Test_loss = 0.21970293570226065\n",
            "\n",
            "Accuracy : 0.9396428571428571\n",
            "790 Train_loss = 0.19117582882153533     Test_loss = 0.21957556339686968\n",
            "\n",
            "Accuracy : 0.9396428571428571\n",
            "791 Train_loss = 0.19103139376004355     Test_loss = 0.21944840569127305\n",
            "\n",
            "Accuracy : 0.9397619047619048\n",
            "792 Train_loss = 0.1908870705644398     Test_loss = 0.2193213998960555\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "793 Train_loss = 0.19074291238846974     Test_loss = 0.21919465813687222\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "794 Train_loss = 0.19059893798147493     Test_loss = 0.21906740897946078\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "795 Train_loss = 0.19045518360146071     Test_loss = 0.21894119783119675\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "796 Train_loss = 0.19031161320213835     Test_loss = 0.21881438340718637\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "797 Train_loss = 0.19016817338637884     Test_loss = 0.21868850759734323\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "798 Train_loss = 0.19002483112836918     Test_loss = 0.21856226772726467\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "799 Train_loss = 0.1898816008929677     Test_loss = 0.2184361933290291\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "800 Train_loss = 0.18973852790763607     Test_loss = 0.21831052932713244\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "801 Train_loss = 0.1895954930445272     Test_loss = 0.21818460536852916\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "802 Train_loss = 0.18945260590930982     Test_loss = 0.21805874418625557\n",
            "\n",
            "Accuracy : 0.9398809523809524\n",
            "803 Train_loss = 0.18930982678723576     Test_loss = 0.2179330883709125\n",
            "\n",
            "Accuracy : 0.94\n",
            "804 Train_loss = 0.18916729066599972     Test_loss = 0.21780790987372772\n",
            "\n",
            "Accuracy : 0.94\n",
            "805 Train_loss = 0.1890249231943003     Test_loss = 0.21768299329954788\n",
            "\n",
            "Accuracy : 0.94\n",
            "806 Train_loss = 0.18888276112579613     Test_loss = 0.2175578034555994\n",
            "\n",
            "Accuracy : 0.94\n",
            "807 Train_loss = 0.18874069124016737     Test_loss = 0.21743275009409768\n",
            "\n",
            "Accuracy : 0.94\n",
            "808 Train_loss = 0.18859876663118955     Test_loss = 0.2173082793555568\n",
            "\n",
            "Accuracy : 0.9401190476190476\n",
            "809 Train_loss = 0.18845703532123753     Test_loss = 0.21718411744529537\n",
            "\n",
            "Accuracy : 0.9402380952380952\n",
            "810 Train_loss = 0.188315468162015     Test_loss = 0.217059752461574\n",
            "\n",
            "Accuracy : 0.9404761904761905\n",
            "811 Train_loss = 0.1881741750618706     Test_loss = 0.21693577252801088\n",
            "\n",
            "Accuracy : 0.940595238095238\n",
            "812 Train_loss = 0.18803310549148147     Test_loss = 0.21681222486017368\n",
            "\n",
            "Accuracy : 0.940595238095238\n",
            "813 Train_loss = 0.18789204026724982     Test_loss = 0.2166885663464623\n",
            "\n",
            "Accuracy : 0.940595238095238\n",
            "814 Train_loss = 0.1877510502058775     Test_loss = 0.21656513633025964\n",
            "\n",
            "Accuracy : 0.940595238095238\n",
            "815 Train_loss = 0.1876100615700919     Test_loss = 0.21644190546075362\n",
            "\n",
            "Accuracy : 0.940595238095238\n",
            "816 Train_loss = 0.1874692161663809     Test_loss = 0.2163188191170163\n",
            "\n",
            "Accuracy : 0.940595238095238\n",
            "817 Train_loss = 0.1873287305334028     Test_loss = 0.2161960833464012\n",
            "\n",
            "Accuracy : 0.9407142857142857\n",
            "818 Train_loss = 0.1871885148622708     Test_loss = 0.21607341204282574\n",
            "\n",
            "Accuracy : 0.9407142857142857\n",
            "819 Train_loss = 0.18704837697523102     Test_loss = 0.21595099187945976\n",
            "\n",
            "Accuracy : 0.9408333333333333\n",
            "820 Train_loss = 0.18690838140205857     Test_loss = 0.21582834041505874\n",
            "\n",
            "Accuracy : 0.9408333333333333\n",
            "821 Train_loss = 0.18676857140666756     Test_loss = 0.21570559136316136\n",
            "\n",
            "Accuracy : 0.9408333333333333\n",
            "822 Train_loss = 0.18662894416119966     Test_loss = 0.21558378798072944\n",
            "\n",
            "Accuracy : 0.9408333333333333\n",
            "823 Train_loss = 0.18648943910625634     Test_loss = 0.21546198728928215\n",
            "\n",
            "Accuracy : 0.9408333333333333\n",
            "824 Train_loss = 0.1863501100034241     Test_loss = 0.2153403340096085\n",
            "\n",
            "Accuracy : 0.9408333333333333\n",
            "825 Train_loss = 0.18621102886694194     Test_loss = 0.2152190999804289\n",
            "\n",
            "Accuracy : 0.940952380952381\n",
            "826 Train_loss = 0.1860721189695858     Test_loss = 0.2150978529503893\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "827 Train_loss = 0.18593333746420604     Test_loss = 0.2149768113595903\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "828 Train_loss = 0.18579478080736878     Test_loss = 0.21485622161462953\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "829 Train_loss = 0.1856564402780258     Test_loss = 0.21473596467163572\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "830 Train_loss = 0.18551826986522263     Test_loss = 0.21461534955179357\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "831 Train_loss = 0.18538030141445697     Test_loss = 0.21449536689885404\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "832 Train_loss = 0.18524260268900106     Test_loss = 0.21437538361532343\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "833 Train_loss = 0.1851051030098018     Test_loss = 0.21425599079379062\n",
            "\n",
            "Accuracy : 0.9413095238095238\n",
            "834 Train_loss = 0.18496776289831043     Test_loss = 0.2141361301846967\n",
            "\n",
            "Accuracy : 0.9414285714285714\n",
            "835 Train_loss = 0.18483062248093224     Test_loss = 0.21401694648168704\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "836 Train_loss = 0.1846935618725845     Test_loss = 0.21389735492633086\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "837 Train_loss = 0.18455665633403512     Test_loss = 0.21377801655647277\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "838 Train_loss = 0.18441992295142323     Test_loss = 0.21365924250926463\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "839 Train_loss = 0.1842833090031565     Test_loss = 0.21353993476436314\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "840 Train_loss = 0.18414682824613443     Test_loss = 0.21342106746214065\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "841 Train_loss = 0.1840104839730519     Test_loss = 0.2133021022894038\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "842 Train_loss = 0.1838743382768037     Test_loss = 0.2131832012862246\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "843 Train_loss = 0.1837383446094325     Test_loss = 0.21306426746664953\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "844 Train_loss = 0.1836025373540614     Test_loss = 0.21294584066770977\n",
            "\n",
            "Accuracy : 0.9415476190476191\n",
            "845 Train_loss = 0.1834668234460734     Test_loss = 0.2128275131751129\n",
            "\n",
            "Accuracy : 0.9417857142857143\n",
            "846 Train_loss = 0.1833312527686386     Test_loss = 0.21270929785193043\n",
            "\n",
            "Accuracy : 0.9417857142857143\n",
            "847 Train_loss = 0.18319583784505428     Test_loss = 0.2125912344544563\n",
            "\n",
            "Accuracy : 0.9417857142857143\n",
            "848 Train_loss = 0.18306057995582717     Test_loss = 0.21247312910013497\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "849 Train_loss = 0.1829255653285199     Test_loss = 0.2123554560977883\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "850 Train_loss = 0.1827906666279654     Test_loss = 0.21223788710880812\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "851 Train_loss = 0.18265602872805886     Test_loss = 0.21212099556052363\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "852 Train_loss = 0.18252160133092066     Test_loss = 0.21200364765664462\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "853 Train_loss = 0.18238734963884654     Test_loss = 0.21188690567325202\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "854 Train_loss = 0.1822533108252152     Test_loss = 0.2117702245240464\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "855 Train_loss = 0.18211943070972203     Test_loss = 0.2116536815968701\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "856 Train_loss = 0.18198565335360958     Test_loss = 0.21153743015310295\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "857 Train_loss = 0.18185201944808047     Test_loss = 0.21142092535965873\n",
            "\n",
            "Accuracy : 0.9419047619047619\n",
            "858 Train_loss = 0.18171852846460598     Test_loss = 0.21130536457078894\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "859 Train_loss = 0.18158513545953078     Test_loss = 0.21118948727012124\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "860 Train_loss = 0.18145190353177637     Test_loss = 0.2110734543069739\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "861 Train_loss = 0.18131886994488114     Test_loss = 0.21095810359287515\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "862 Train_loss = 0.18118599631431517     Test_loss = 0.21084293471578797\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "863 Train_loss = 0.18105329001674011     Test_loss = 0.21072800228124816\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "864 Train_loss = 0.18092073479101167     Test_loss = 0.2106126069981793\n",
            "\n",
            "Accuracy : 0.9420238095238095\n",
            "865 Train_loss = 0.18078835898023793     Test_loss = 0.2104976403303317\n",
            "\n",
            "Accuracy : 0.9421428571428572\n",
            "866 Train_loss = 0.18065609003898608     Test_loss = 0.21038243467386025\n",
            "\n",
            "Accuracy : 0.9421428571428572\n",
            "867 Train_loss = 0.18052399895605387     Test_loss = 0.2102676707161622\n",
            "\n",
            "Accuracy : 0.9421428571428572\n",
            "868 Train_loss = 0.18039207121816248     Test_loss = 0.21015233911523665\n",
            "\n",
            "Accuracy : 0.9421428571428572\n",
            "869 Train_loss = 0.180260324950613     Test_loss = 0.21003779948003135\n",
            "\n",
            "Accuracy : 0.9422619047619047\n",
            "870 Train_loss = 0.18012874263624     Test_loss = 0.20992328509757013\n",
            "\n",
            "Accuracy : 0.9422619047619047\n",
            "871 Train_loss = 0.17999735721529037     Test_loss = 0.20980950207934923\n",
            "\n",
            "Accuracy : 0.9423809523809524\n",
            "872 Train_loss = 0.17986604767707953     Test_loss = 0.20969530836997236\n",
            "\n",
            "Accuracy : 0.9423809523809524\n",
            "873 Train_loss = 0.17973480647843124     Test_loss = 0.20958100268487864\n",
            "\n",
            "Accuracy : 0.9423809523809524\n",
            "874 Train_loss = 0.17960369317415986     Test_loss = 0.20946741276583314\n",
            "\n",
            "Accuracy : 0.9423809523809524\n",
            "875 Train_loss = 0.17947281506309123     Test_loss = 0.20935327517906574\n",
            "\n",
            "Accuracy : 0.9425\n",
            "876 Train_loss = 0.17934214010732466     Test_loss = 0.20924012403844408\n",
            "\n",
            "Accuracy : 0.9426190476190476\n",
            "877 Train_loss = 0.17921166374020203     Test_loss = 0.20912651690707068\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "878 Train_loss = 0.17908134498791237     Test_loss = 0.20901347268380385\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "879 Train_loss = 0.17895117192500132     Test_loss = 0.2088998824085544\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "880 Train_loss = 0.17882111262520636     Test_loss = 0.20878698633399936\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "881 Train_loss = 0.1786911613800201     Test_loss = 0.20867375098607852\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "882 Train_loss = 0.17856136611142137     Test_loss = 0.20856095703685423\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "883 Train_loss = 0.17843170115610874     Test_loss = 0.2084484319189052\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "884 Train_loss = 0.17830218297530054     Test_loss = 0.20833624279631055\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "885 Train_loss = 0.1781727840289434     Test_loss = 0.20822413546268198\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "886 Train_loss = 0.1780435637657543     Test_loss = 0.2081119563598965\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "887 Train_loss = 0.17791448495509726     Test_loss = 0.20800018840009643\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "888 Train_loss = 0.17778553922324125     Test_loss = 0.207888665284328\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "889 Train_loss = 0.17765670715037002     Test_loss = 0.20777691773150758\n",
            "\n",
            "Accuracy : 0.9427380952380953\n",
            "890 Train_loss = 0.17752798317581414     Test_loss = 0.207665744881073\n",
            "\n",
            "Accuracy : 0.9428571428571428\n",
            "891 Train_loss = 0.17739937088604749     Test_loss = 0.20755473907321575\n",
            "\n",
            "Accuracy : 0.9429761904761905\n",
            "892 Train_loss = 0.17727086133028555     Test_loss = 0.20744321496652726\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "893 Train_loss = 0.17714248506619648     Test_loss = 0.20733245246328375\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "894 Train_loss = 0.17701422288963004     Test_loss = 0.20722122437294144\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "895 Train_loss = 0.1768861489343245     Test_loss = 0.20711025491476112\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "896 Train_loss = 0.1767582891387046     Test_loss = 0.20699975742936935\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "897 Train_loss = 0.17663059304485795     Test_loss = 0.20688906098265558\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "898 Train_loss = 0.17650306415441538     Test_loss = 0.20677889985280706\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "899 Train_loss = 0.17637563906031964     Test_loss = 0.20666917211517424\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "900 Train_loss = 0.17624830498584065     Test_loss = 0.2065591202185622\n",
            "\n",
            "Accuracy : 0.9430952380952381\n",
            "901 Train_loss = 0.17612112405381586     Test_loss = 0.20644926576392567\n",
            "\n",
            "Accuracy : 0.9429761904761905\n",
            "902 Train_loss = 0.1759940514150726     Test_loss = 0.20633969210643016\n",
            "\n",
            "Accuracy : 0.9429761904761905\n",
            "903 Train_loss = 0.17586706297852284     Test_loss = 0.20623087878157195\n",
            "\n",
            "Accuracy : 0.9429761904761905\n",
            "904 Train_loss = 0.17574023893600801     Test_loss = 0.20612085888277462\n",
            "\n",
            "Accuracy : 0.9429761904761905\n",
            "905 Train_loss = 0.17561358628709242     Test_loss = 0.20601205704648032\n",
            "\n",
            "Accuracy : 0.9432142857142857\n",
            "906 Train_loss = 0.17548711075991905     Test_loss = 0.20590288857585434\n",
            "\n",
            "Accuracy : 0.9432142857142857\n",
            "907 Train_loss = 0.17536079213664407     Test_loss = 0.20579440069545754\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "908 Train_loss = 0.17523458884391682     Test_loss = 0.20568543149359006\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "909 Train_loss = 0.17510853892128042     Test_loss = 0.20557680602369838\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "910 Train_loss = 0.17498253895468252     Test_loss = 0.2054681950328195\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "911 Train_loss = 0.17485672359812438     Test_loss = 0.2053598507975532\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "912 Train_loss = 0.1747311145073924     Test_loss = 0.2052516672747276\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "913 Train_loss = 0.1746055535623078     Test_loss = 0.20514349490572023\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "914 Train_loss = 0.17448007655576483     Test_loss = 0.2050350323784456\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "915 Train_loss = 0.17435473683766842     Test_loss = 0.20492726180592266\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "916 Train_loss = 0.1742295278858143     Test_loss = 0.2048189927645017\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "917 Train_loss = 0.17410446134025798     Test_loss = 0.20471123984807071\n",
            "\n",
            "Accuracy : 0.9433333333333334\n",
            "918 Train_loss = 0.1739796186838917     Test_loss = 0.20460395207814933\n",
            "\n",
            "Accuracy : 0.9434523809523809\n",
            "919 Train_loss = 0.17385491693277283     Test_loss = 0.2044963079246889\n",
            "\n",
            "Accuracy : 0.9436904761904762\n",
            "920 Train_loss = 0.17373035327256114     Test_loss = 0.20438895765175913\n",
            "\n",
            "Accuracy : 0.9436904761904762\n",
            "921 Train_loss = 0.1736058891177063     Test_loss = 0.2042818282936016\n",
            "\n",
            "Accuracy : 0.9436904761904762\n",
            "922 Train_loss = 0.1734815875402598     Test_loss = 0.20417441867188704\n",
            "\n",
            "Accuracy : 0.9436904761904762\n",
            "923 Train_loss = 0.17335741933300572     Test_loss = 0.2040675719072066\n",
            "\n",
            "Accuracy : 0.9438095238095238\n",
            "924 Train_loss = 0.17323335932181305     Test_loss = 0.20396109227163547\n",
            "\n",
            "Accuracy : 0.9439285714285715\n",
            "925 Train_loss = 0.17310943137872797     Test_loss = 0.20385419092203153\n",
            "\n",
            "Accuracy : 0.9439285714285715\n",
            "926 Train_loss = 0.17298566305404253     Test_loss = 0.20374811603750492\n",
            "\n",
            "Accuracy : 0.9439285714285715\n",
            "927 Train_loss = 0.17286206179350178     Test_loss = 0.20364219135021597\n",
            "\n",
            "Accuracy : 0.944047619047619\n",
            "928 Train_loss = 0.1727385584001989     Test_loss = 0.20353652163341057\n",
            "\n",
            "Accuracy : 0.944047619047619\n",
            "929 Train_loss = 0.17261522732131254     Test_loss = 0.20343057391002578\n",
            "\n",
            "Accuracy : 0.944047619047619\n",
            "930 Train_loss = 0.17249206803018283     Test_loss = 0.2033249844795597\n",
            "\n",
            "Accuracy : 0.944047619047619\n",
            "931 Train_loss = 0.17236904939502187     Test_loss = 0.20321913670675443\n",
            "\n",
            "Accuracy : 0.944047619047619\n",
            "932 Train_loss = 0.17224613830513388     Test_loss = 0.20311433218324493\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "933 Train_loss = 0.17212341930899544     Test_loss = 0.20300914260403458\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "934 Train_loss = 0.1720008297937492     Test_loss = 0.202904622282604\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "935 Train_loss = 0.17187839758869847     Test_loss = 0.2027997972274395\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "936 Train_loss = 0.17175620811869205     Test_loss = 0.2026956619921661\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "937 Train_loss = 0.1716341582418064     Test_loss = 0.20259148968774748\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "938 Train_loss = 0.1715122690578563     Test_loss = 0.202487312499818\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "939 Train_loss = 0.171390509303022     Test_loss = 0.20238300140159063\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "940 Train_loss = 0.17126889852234412     Test_loss = 0.20227924312556825\n",
            "\n",
            "Accuracy : 0.9441666666666667\n",
            "941 Train_loss = 0.171147463128864     Test_loss = 0.20217518399240977\n",
            "\n",
            "Accuracy : 0.9442857142857143\n",
            "942 Train_loss = 0.1710262093406702     Test_loss = 0.2020714272675542\n",
            "\n",
            "Accuracy : 0.9442857142857143\n",
            "943 Train_loss = 0.1709051322972954     Test_loss = 0.20196743955558646\n",
            "\n",
            "Accuracy : 0.9442857142857143\n",
            "944 Train_loss = 0.17078427779167854     Test_loss = 0.201864227114072\n",
            "\n",
            "Accuracy : 0.9442857142857143\n",
            "945 Train_loss = 0.1706635870263342     Test_loss = 0.20176031890037757\n",
            "\n",
            "Accuracy : 0.9444047619047619\n",
            "946 Train_loss = 0.17054302387895873     Test_loss = 0.20165781840184618\n",
            "\n",
            "Accuracy : 0.9445238095238095\n",
            "947 Train_loss = 0.1704225235900126     Test_loss = 0.20155451842393163\n",
            "\n",
            "Accuracy : 0.9445238095238095\n",
            "948 Train_loss = 0.1703020973067421     Test_loss = 0.20145151463439764\n",
            "\n",
            "Accuracy : 0.9445238095238095\n",
            "949 Train_loss = 0.17018179737849423     Test_loss = 0.20134830279131238\n",
            "\n",
            "Accuracy : 0.9445238095238095\n",
            "950 Train_loss = 0.17006161131884417     Test_loss = 0.20124581249013412\n",
            "\n",
            "Accuracy : 0.9445238095238095\n",
            "951 Train_loss = 0.16994153164141193     Test_loss = 0.2011429395228792\n",
            "\n",
            "Accuracy : 0.9445238095238095\n",
            "952 Train_loss = 0.16982157776002124     Test_loss = 0.2010405061044294\n",
            "\n",
            "Accuracy : 0.9444047619047619\n",
            "953 Train_loss = 0.1697018144079105     Test_loss = 0.2009378858956798\n",
            "\n",
            "Accuracy : 0.9446428571428571\n",
            "954 Train_loss = 0.16958217577926987     Test_loss = 0.20083562470583588\n",
            "\n",
            "Accuracy : 0.9446428571428571\n",
            "955 Train_loss = 0.16946266570403465     Test_loss = 0.20073345990429145\n",
            "\n",
            "Accuracy : 0.9446428571428571\n",
            "956 Train_loss = 0.169343307404649     Test_loss = 0.20063123354109094\n",
            "\n",
            "Accuracy : 0.9446428571428571\n",
            "957 Train_loss = 0.16922407148527224     Test_loss = 0.20052918297516528\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "958 Train_loss = 0.16910492884880277     Test_loss = 0.2004277099994369\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "959 Train_loss = 0.16898588172753506     Test_loss = 0.20032550283359418\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "960 Train_loss = 0.168866953397018     Test_loss = 0.2002239771267389\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "961 Train_loss = 0.1687480757243252     Test_loss = 0.20012252453723492\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "962 Train_loss = 0.16862932761158042     Test_loss = 0.2000210852999948\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "963 Train_loss = 0.16851067143460596     Test_loss = 0.19991995654507252\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "964 Train_loss = 0.1683921500819877     Test_loss = 0.1998186964376444\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "965 Train_loss = 0.16827377173582572     Test_loss = 0.19971803097227236\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "966 Train_loss = 0.16815550459284512     Test_loss = 0.19961730641937656\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "967 Train_loss = 0.16803735687972768     Test_loss = 0.19951634331154922\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "968 Train_loss = 0.16791931579373012     Test_loss = 0.19941579481285235\n",
            "\n",
            "Accuracy : 0.9447619047619048\n",
            "969 Train_loss = 0.1678013513887807     Test_loss = 0.19931518228167955\n",
            "\n",
            "Accuracy : 0.9448809523809524\n",
            "970 Train_loss = 0.16768348641393002     Test_loss = 0.19921478170510276\n",
            "\n",
            "Accuracy : 0.9448809523809524\n",
            "971 Train_loss = 0.1675656459059037     Test_loss = 0.19911416555536512\n",
            "\n",
            "Accuracy : 0.9448809523809524\n",
            "972 Train_loss = 0.1674479399516249     Test_loss = 0.19901381734896825\n",
            "\n",
            "Accuracy : 0.945\n",
            "973 Train_loss = 0.16733034830036964     Test_loss = 0.1989134995305162\n",
            "\n",
            "Accuracy : 0.945\n",
            "974 Train_loss = 0.16721279974843264     Test_loss = 0.1988131457228187\n",
            "\n",
            "Accuracy : 0.945\n",
            "975 Train_loss = 0.16709536768993194     Test_loss = 0.19871274096573785\n",
            "\n",
            "Accuracy : 0.945\n",
            "976 Train_loss = 0.166978099840587     Test_loss = 0.1986132029620554\n",
            "\n",
            "Accuracy : 0.945\n",
            "977 Train_loss = 0.166860953141006     Test_loss = 0.19851336383861676\n",
            "\n",
            "Accuracy : 0.945\n",
            "978 Train_loss = 0.16674392536774735     Test_loss = 0.19841376108308112\n",
            "\n",
            "Accuracy : 0.9451190476190476\n",
            "979 Train_loss = 0.16662709093790373     Test_loss = 0.1983145523805386\n",
            "\n",
            "Accuracy : 0.9451190476190476\n",
            "980 Train_loss = 0.16651042730739846     Test_loss = 0.1982150746451585\n",
            "\n",
            "Accuracy : 0.9451190476190476\n",
            "981 Train_loss = 0.16639393160199573     Test_loss = 0.19811579930053297\n",
            "\n",
            "Accuracy : 0.9451190476190476\n",
            "982 Train_loss = 0.1662776111926087     Test_loss = 0.1980167070594218\n",
            "\n",
            "Accuracy : 0.9452380952380952\n",
            "983 Train_loss = 0.16616145970286383     Test_loss = 0.19791809340878594\n",
            "\n",
            "Accuracy : 0.9452380952380952\n",
            "984 Train_loss = 0.16604545350354136     Test_loss = 0.19781941124733954\n",
            "\n",
            "Accuracy : 0.9452380952380952\n",
            "985 Train_loss = 0.1659296000649003     Test_loss = 0.1977211249085751\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "986 Train_loss = 0.16581388214531234     Test_loss = 0.19762286029197773\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "987 Train_loss = 0.16569827357137912     Test_loss = 0.19752474012513452\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "988 Train_loss = 0.16558279221148603     Test_loss = 0.19742653906401714\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "989 Train_loss = 0.16546747189145883     Test_loss = 0.19732837387360463\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "990 Train_loss = 0.16535225757917313     Test_loss = 0.19723023844809862\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "991 Train_loss = 0.1652371625071312     Test_loss = 0.19713204217061264\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "992 Train_loss = 0.16512223152618222     Test_loss = 0.19703412809667087\n",
            "\n",
            "Accuracy : 0.9453571428571429\n",
            "993 Train_loss = 0.16500737785663297     Test_loss = 0.1969361676393121\n",
            "\n",
            "Accuracy : 0.9454761904761905\n",
            "994 Train_loss = 0.16489263746982535     Test_loss = 0.19683907651050253\n",
            "\n",
            "Accuracy : 0.9454761904761905\n",
            "995 Train_loss = 0.16477797294122218     Test_loss = 0.1967412256829921\n",
            "\n",
            "Accuracy : 0.9457142857142857\n",
            "996 Train_loss = 0.16466343112761314     Test_loss = 0.19664399651230516\n",
            "\n",
            "Accuracy : 0.9457142857142857\n",
            "997 Train_loss = 0.1645489988220789     Test_loss = 0.19654676470038857\n",
            "\n",
            "Accuracy : 0.9458333333333333\n",
            "998 Train_loss = 0.16443468801931282     Test_loss = 0.19644953354200906\n",
            "\n",
            "Accuracy : 0.9458333333333333\n",
            "999 Train_loss = 0.16432053027992868     Test_loss = 0.1963525082599886\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses = [] \n",
        "test_losses = []\n",
        "NUM_ITERS = 1000\n",
        "\n",
        "finy_test = y_test\n",
        "finyhat_test = 0\n",
        "\n",
        "for _ in range(NUM_ITERS):\n",
        "    yhat = model.predict(X_train)\n",
        "    train_loss = model.categorical_cross_entropy_loss(y_train, yhat)\n",
        "    yhat_test = model.predict(X_test)\n",
        "    test_loss = model.categorical_cross_entropy_loss(y_test, yhat_test)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    model.fit_once(X_train, y_train, 0.1)\n",
        "    if(len(test_losses) >= 6 and (test_losses[-1] > test_losses[-6])):\n",
        "      # print(\"Test loss[-1]\", test_losses[-1], \" Test loss[-6]\", test_losses[-6])\n",
        "      print(\"Early Stopping\")\n",
        "      break\n",
        "\n",
        "    print(\"Accuracy : \" + str(1 - (yhat_test.argmax(axis=1) != y_test).sum()/len(y_test)) )\n",
        "    print(_, \"Train_loss = \" + str(train_loss) + \"     Test_loss = \" + str(test_loss))\n",
        "    print(\"\")\n",
        "    \n",
        "    if( _ == NUM_ITERS-1):\n",
        "       finyhat_test = yhat_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(test_losses)\n",
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8tmYt8QQOBqD",
        "outputId": "d8bab4e2-7480-42fc-f2b2-2142628c7bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbbbb7ef4d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnJgsJCYTsEAJhXyM7IihSFffWn15baatWq7W2Vettr11u78+2/mr1Xlvbeq1r3UtdqhZQWVQEERVrwLBvYV8SCFsWyDYz398fmbaIICHbycy8n4/HPHJm5mTmfSC8OfnOOd9jzjlERCTy+bwOICIirUOFLiISJVToIiJRQoUuIhIlVOgiIlFChS4iEiXiTraCmXUCFgGJ4fVfds79/Jh1EoFngTHAfuAq59zWz3vdzMxMV1BQ0LzUIiIxaunSpfucc1nHe+6khQ7UAec456rNLB5YbGZznHNLjlrnBuCgc66/mU0D/hu46vNetKCggKKioiZugoiIAJjZthM9d9IhF9eoOnw3Pnw79myky4BnwssvA+eamTUjq4iINFOTxtDNzG9mxcBe4C3n3EfHrJIH7ABwzgWACiDjOK9zk5kVmVlReXl5y5KLiMinNKnQnXNB59xIoCcw3syGN+fNnHOPOefGOufGZmUddwhIRESa6ZSOcnHOHQIWABce89QuIB/AzOKArjR+OCoiIu3kpIVuZllmlhZeTgKmAuuOWW0W8I3w8pXAO06zfomItKumHOXSHXjGzPw0/gfwknPudTO7Cyhyzs0CngCeM7MS4AAwrc0Si4jIcZ200J1zK4BRx3n8zqOWa4Evt240ERE5FRF3pui+TcWsffpWGmoPex1FRKRDibhC31KyliFbn2VL8UKvo4iIdCgRV+j9xk4l4HxUrpnvdRQRkQ4l4go9PSOTkrgBdCn70OsoIiIdSsQVOsD+rPH0qVtP7eEKr6OIiHQYEVnoyYPOId6CbF76ttdRREQ6jIgs9P5jz6Xe+alet8DrKCIiHUZEFnpqalc2Jgym295j5wgTEYldEVnoAIeyJ9C3YSPVFQe8jiIi0iFEbKF3GXIOfnNsXjrP6ygiIh1CxBZ6/9FfoNbFU7t+oddRREQ6hIgt9KTkzmxMHEbmPo2ji4hABBc6QFXuBPoGt1Cxv8zrKCIinovoQu82/DwANn+scXQRkYgu9H4jJnPEJVJfstDrKCIinovoQk9ITKQk6TRyDnzsdRQREc9FdKEDHOlxBgWhHewr3e51FBERT0V8oWcWTgVgq45HF5EYF/GF3qfwDCpJJrjpXa+jiIh4KuIL3R8Xz5bkEfQ4VOR1FBERT0V8oQPU9ZxEvitl97aNXkcREfFMVBR69ojzAdixTOPoIhK7oqLQew8ZyyFSYet7XkcREfFMVBS6+fxsSRlFr4oiXCjkdRwREU9ERaEDBHudSXf2sW3TGq+jiIh4ImoKvceoxnH03cVvepxERMQbUVPo3fuNYD9pxG1b7HUUERFPRE2hm8/H9i5jKKheRiiocXQRiT1RU+gA9DmLbA5Ssq7Y6yQiIu0uqgq95+gLAdi7XOPoIhJ7oqrQs3oNZq9lkLDzfa+jiIi0u6gqdMzYlTaO/oc/oSEQ8DqNiEi7iq5CB3x9J5NuVWxYqYteiEhsibpC7z2mcRx938q3PU4iItK+oq7Q03r0o9SXS/JujaOLSGyJukIHKEsfx8CaFdTW1XsdRUSk3URloSf0n0JXO8z64g+8jiIi0m6istB7j70AgINr5nucRESk/Zy00M0s38wWmNkaM1ttZt8/zjpTzKzCzIrDtzvbJm7TpGTms9Pfk9TSD72MISLSruKasE4A+KFzbpmZpQJLzewt59yx89S+55y7tPUjNk955ukMKnuD6iM1pCQneR1HRKTNnXQP3TlX6pxbFl6uAtYCeW0drKWSBk4hxWpZv2yR11FERNrFKY2hm1kBMAr46DhPn2Fmy81sjpkNO8H332RmRWZWVF5efsphT0XBmMZx9Mq177Tp+4iIdBRNLnQzSwFeAW53zlUe8/QyoLdzbgTwv8CM472Gc+4x59xY59zYrKys5mZukk5pOWyLKyBtz5I2fR8RkY6iSYVuZvE0lvl059yrxz7vnKt0zlWHl2cD8WaW2apJm+Fg9gQGN6zhYEWV11FERNpcU45yMeAJYK1z7v4TrJMbXg8zGx9+3f2tGbQ5UgZ/gSSrZ/3SBV5HERFpc03ZQ58EXAOcc9RhiReb2c1mdnN4nSuBVWa2HHgAmOacc22Uucl6jz6fkDOObFjodRQRkTZ30sMWnXOLATvJOg8CD7ZWqNYSn5LO1sT+pJcf7zNcEZHoEpVnih6tIncCQwLr2LP/oNdRRETaVNQXetch55JoATYu1TQAIhLdor7Q80eeSwAfdRsXeh1FRKRNRX2h+5O6sD1xENn7/+51FBGRNhX1hQ5Q3WMig4Ml7Czb63UUEZE2ExOFnj78POItyKait7yOIiLSZmKi0PMKz6aBOBo2aaIuEYleMVHoltCZbUnD6H7wYzrA+U4iIm0iJgodoLbnRAa7zWzescvrKCIibSJmCj278Dz85ti27G2vo4iItInYKfShZ1FHAqEtGkcXkegUM4VOXCLbOxeSX1FEMKRxdBGJPrFT6EBD/iQGsY0NW7Z6HUVEpNXFVKHnjjwfgJ2fvOlxEhGR1hdThZ4+YAI1dMK39T2vo4iItLqYKnT88exIHUlB1TLqAyGv04iItKrYKnQg1Pss+tku1m7Y4HUUEZFWFXOF3mNU4zh66XLN6yIi0SXmCr1LnzFUW2fid7zvdRQRkVYVc4WOz8/urqPpf3gZtQ1Br9OIiLSa2Ct0wPpMprftYeWa1V5HERFpNTFZ6HmjLwCgfIXG0UUkesRkoSfnFVJpXei06wOvo4iItJqYLHR8Pkq7jWVQTTFVNfVepxERaRWxWehAfL+zybN9rFq13OsoIiKtImYLPW904/Ho+1bN9ziJiEjriNlCT8wdwkFfOim7NY4uItEhZgsdM8ozxjGsfjkHquu8TiMi0mKxW+hAwsAvkG2HWLm8yOsoIiItFtOFnheeH71ira4zKiKRL6YLPT6zL/v9WXQtW+J1FBGRFovpQseM/VkTGN6wkrJDR7xOIyLSIrFd6EDyoClkWBWriz/0OoqISIvEfKH3CI+jV69b4HESEZGWiflC93Xrxd64HqTvXYJzzus4IiLNFvOFDlCRM4ERwdVs31fldRQRkWZToQOpQ8+hix1hbbGuYiQikeukhW5m+Wa2wMzWmNlqM/v+cdYxM3vAzErMbIWZjW6buG0jp/A8AGo3LPQ2iIhIC8Q1YZ0A8EPn3DIzSwWWmtlbzrk1R61zETAgfDsdeDj8NSJYl+7sSehF1r6PcM5hZl5HEhE5ZSfdQ3fOlTrnloWXq4C1QN4xq10GPOsaLQHSzKx7q6dtQ1XdJzIitJaNpQe9jiIi0iynNIZuZgXAKOCjY57KA3YcdX8nny19zOwmMysys6Ly8vJTS9rG0oaeS4rVsvGTRV5HERFpliYXupmlAK8AtzvnKpvzZs65x5xzY51zY7OysprzEm0mc/i5ANSXvOtxEhGR5mlSoZtZPI1lPt059+pxVtkF5B91v2f4scjROYPdnfrR/eDHBEM6Hl1EIk9TjnIx4AlgrXPu/hOsNgu4Nny0ywSgwjlX2oo520VNj4mMdOtYu6NjDQeJiDRFU/bQJwHXAOeYWXH4drGZ3WxmN4fXmQ1sBkqAx4Hvtk3ctpVReB6drIFNxQu9jiIicspOetiic24x8LnH8bnGc+a/11qhvJI2eArBmT5CmxYBX/E6jojIKdGZokdLSqMsaQA9K4qoD4S8TiMickpU6Meoyz+TEWxg5daI+whARGKcCv0Y2aedR4IF2Vas6XRFJLKo0I+RMuAsAvhhy3teRxEROSUq9GMlplKWMpQ+VUupqQ96nUZEpMlU6McR6HUmhbaJ4pIdJ19ZRKSDUKEfR86IqcRZiHfffo3quoDXcUREmkSFfhxJfScS8HXi/H3PcOMjb7Ovus7rSCIiJ6VCP574JOKufIyRcVu588CPueGh2Wzbf9jrVCIin0uFfiJDL8P3tRcYHFfGH478lO8+NItVuyq8TiUickIq9M/T/zx8184gP6GaJ4L/lzsefZXFG/d5nUpE5LhU6CfT+wz8179BdlKI6f5fcO/Tf2XW8t1epxIR+QwVelN0H4Hvm3NJS0nmhYRf8dQLL/HE4i1epxIR+RQVelNlDcR3wzyS07J5vtM9vDP7Re6Zs5bGiSZFRLynQj8Vab3wfXMuiVl9eSbxN2x570V++NflNAQ1M6OIeE+FfqpSc7Dr3sDfYwSPJDyAK36BG58p4rBOQBIRj6nQmyM5Hbt2Jr4+k/hdwsMUbJrO1x5fwn6dgCQiHlKhN1diCnztrzDoYn4Z/zRn73mWKx/+gB0HjnidTERilAq9JeI7wVeehcKv8AP/i1x7+CmueOh9Vu/WCUgi0v5Oek1ROQl/PFz+KCSmcn3RE6SFavjqowEeuWYcE/tnep1ORGKI9tBbg88Hl/wWzvwBl4fe5PcJD3HjUx/y+gqdgCQi7Ud76K3FDM77OXTqwjlv/4LnUmr5+vPfZV/VSK6b1MfrdCISA7SH3trO/He45H5G133MjK6/477XlvI/c9fpBCQRaXMq9LYw7gbsiscZVLeKud1+w18WFnPHyyt0ApKItCkVels57cvYtOn0rN/M/G73smjpSm56togj9ToBSUTahgq9LQ26CLv6ZTKC5czvdg+bNqzma49/xIHD9V4nE5EopEJva30mw7WzSHXVvNn119SVruHKRz5g50GdgCQirUuF3h56joHr59ApzpjV+W6yq9ZwxUMfsLa00utkIhJFVOjtJWcofHMu8UmpTI+/m9FuDV959EOWbN7vdTIRiRIq9PaU3heun4u/aw8ednfzxaRVXPvk31mwbq/XyUQkCqjQ21vXPLh+DpY9iLvrfs0Nacu46bki5q4q9TqZiEQ4FboXOmfCN17Deo7nR9X38cP09/neXz5hZvEur5OJSATTqf9e6dQVrn4F++t13LzxQdIyqrn9xRC1DUGuGtfL63QiEoFU6F5KSIZp02HGd5m28mm6Zlbx3VccNfVBzf8iIqdMhe61f0y/m9SNi/7+KNMzq7jmtWuoDYS4+ex+XqcTkQiiQu8IfD646L8hOYOJC3/N3zIP8+U536KmPsjt5w3AzLxOKCIRQIXeUZjBlB9DUjdOm3MHs9MPc9n8W6hpCPLTiwar1EXkpE56lIuZPWlme81s1Qmen2JmFWZWHL7d2foxY8jpN8EVf6Jv7Sre7HYfryz6hDtnriYU0vS7IvL5mnLY4tPAhSdZ5z3n3Mjw7a6Wx4pxp30Zm/Y83Ru282baPbyzpIgfv7KCoEpdRD7HSQvdObcIONAOWeRoA8/Hrvkb6e4Qc7vczbJlH3H7i8WaU11ETqi1Tiw6w8yWm9kcMxt2opXM7CYzKzKzovLy8lZ66yjW+wzs+jmkxsPrne9m+4pFfG/6MuoCQa+TiUgH1BqFvgzo7ZwbAfwvMONEKzrnHnPOjXXOjc3KymqFt44BucPhhnkkpXTl5eR7qF43n5ueXUptg0pdRD6txYXunKt0zlWHl2cD8WaW2eJk8i/pfeGb84jP6MNzne4jadMbXP/Uxxyu09WPRORfWlzoZpZr4WPqzGx8+DU1J2xr69Idrp+Nv8coHo5/gILtL3PNEx9RWdvgdTIR6SCactji88CHwCAz22lmN5jZzWZ2c3iVK4FVZrYceACY5nSJ+7aR1A2unYH1P4d74h5nQulzfP3xjzioS9qJCGBede/YsWNdUVGRJ+8d8QL1MONmWPUKj4e+yMtp3+LP35pAVmqi18lEpI2Z2VLn3NjjPafpcyNRXAJc8TiMvYFv+V7jW4d+x1cfWUxpRY3XyUTEQyr0SOXzwyW/hck/4krfAn5cfS9XP/IuOw7o4tMisUqFHsnM4JyfwYX3MtX+zq9r/h/XPfIOm8urvU4mIh5QoUeDCd+Byx9lvK3lgfo7+dYjb7K+rMrrVCLSzlTo0WLENGzadIb4d/Gn4H/x/UdfY9WuCq9TiUg7UqFHk0EX4bvmVXonVPK0+7/89PFXWbrtoNepRKSdqNCjTcEkfNe/QVYyPMed3PPE83y4Sed5icQCFXo06j4C/w1vktqlK8/47uKhp5/isUWbqA9opkaRaKZCj1YZ/fDf+CaJGb140n8vh+bdyxd/P59FGzTLpUi0UqFHsy49iLthLvGDL+BH8S/xxOFbefLpR/n2c0U6Xl0kCqnQo11yOkybDle/So/0FJ5OuI+rSn7E9fe/yO/e2qBpeEWiiAo9VvQ/F993PoCpdzElYR1z4u/A/+7dXPybN5m7qhTNpyYS+VTosSQuASZ9H9+tS4kffjm3xc3g+fpbmfmXh7nmTx9RslcnI4lEMhV6LOrSHf7tcbhuNtlZ2Tyc8Adu2fUf3PL75/nV62uo0hzrIhFJhR7LCiZh314EF93H+MTtvJHwE3KW/IpL75vDy0t3EgppGEYkkqjQY50/Dk6/Cd9ty/CP/jo3xs3mb+423n/lQa58+H1NHyASQXSBC/m0XUtxb9yB7V5KMYP5Wf21nDZ2MndcMIj0zglepxOJebrAhTRd3hjsxrfhSw9yWvI+Xkv4L4Z98gsuu+81nv1wK4GgzjYV6ahU6PJZPh+MvgbfrUvxnX4TX497h9m+21n3+gN86YF3+fuWA14nFJHj0JCLnFzZKtycO7BtH7DO+vKftdfS87Qp/OfFQ8jt2snrdCIxRUMu0jK5w7HrZsO/PcGgzjW8mvgLzl77c7782xk8tLCEuoDONhXpCFTo0jRmUHgldmsRTLqdK+I+YJ7/B+x76/dc8rsFLFi31+uEIjFPQy7SPPs2wtyfQMnbbPH14j9rryHQ60ymjevFxYXdSUrwe51QJCp93pCLCl2azzlYPwc39yfYoW0U+UbwbO1ZfBA/gfNHFjBtXD6FeV0xM6+TikQNFbq0rYYaWPIQruhJrGInNb4UZgQm8GLDZGqzR3LV+F5cPiqPtGQdxy7SUip0aR+hEGxdBJ9Mx62dhQVq2e7PZ3rtmbzOZEYPH8JVY/OZ2C8Dn0977SLNoUKX9ldbAav/Bp9Mh51/J4SfxYzgL/WTWd9lIpeP68uVY3rSIy3J66QiEUWFLt7atxGKp+OKX8CqS6nydeHl+jN4JXQ2mQPGcdXYfM4dkkNCnA66EjkZFbp0DKEgbFoAxX/GrX0DC9WzwQp4of4s3k2cwjljhnLVuHz6Z6d6nVSkw1KhS8dz5ACsegVXPB3b/QlB/MwPjeKlwNlU5J3NleP7cOlpPeicGOd1UpEWO1wXoKyylrKKWkoraumX1ZlRvbo167VU6NKx7VkNxX8htPwFfEf2cdC68teGM3nDN4XBp03gqvH5jMpP0+GP0uE456isCVBaWUNZxb8Ku6yiltLKWsoqaiitqKWqNvCp77vxzD7816VDm/WeKnSJDMEG2PgWrvjPsH4e5gKsdH15MXA2a9LP4+LxQ7l8VB4ZKYleJ5VoFahr/Dl0IUKhEAeP1LOnsobyihr2VNWyt7KGvZW1lFfWUF5Zy96qWuoagvhw2D9uBpmd48hOTSQrJYGclHiywsuZKQlkp8STntWdTt26NyuiCl0iz+F9sOIlgp/8Gf/e1TQQx7zgWP4WmkxDwWSmDs/ngmG5ZHfR5GDSOvbP/wNp7/0SP+0wN9Gk22HqL5v1rSp0iVzOQdkK+GQ6weUv4q87RBWdmRccw5zQeA7nncV5hb24YFgu+enJXqeVCFU297fkLrmL99wotnYZTWqneFKSEujSKZ7UpAS6JCXSJSmezonx+Hy+xrmNsKO++k6wHL7/z+Xw45kDIXd4s7Kq0CU6BOpg0wLcmhmE1s7GX1/BEZKYFxzN3OB4ynPP5NzCAi4Ylkv/7BSv00qE2PHG/5D/8d284zuD3jc9T7/c5n1Y2V5U6BJ9AvWwZRGsmUFw7ev4aw9SY52YHxjJ7OB4dmScyZTCAi4cnsvQ7l30gaoc16aZ99Dvk3tZGDeJAd95gbyMLl5HOikVukS3YANsXQxrZhJcMwt/zX7qLJEFgdOYHTydDV0nMrmwLxcMy2VUfpqmHRAA1r7yK4asvI/34s9kyC0vktk1Mn6rU6FL7AgFYdsHsGYmoTUz8R3eSwPxLAoV8kZgPCs6T2LS8L5cMDyX8QXpxPl1dmosKn7hl4xcdz/vJ05m+G0v0bVz5ExB0aJCN7MngUuBvc65z4ziW+Pvsn8ALgaOANc555adLJQKXdpcKAQ7PoK1switnoGvajcB4njfDef1wHiKEs9g/ND+XFiYy8R+GSTGaQ73WPDRc3dy+qY/sCR5CiNue4mkTpF1GGxLC30yUA08e4JCvxi4lcZCPx34g3Pu9JOFUqFLuwqFYPcyWDOD0OqZ+Cq2E8THR244rwXG8UHcBEYOGcBFw3M5e2C2LtARhZxzvPfUz5i8/Y8UpZzDabe9SEJC5E3p3OIhFzMrAF4/QaE/Cix0zj0fvr8emOKcK/2811Shi2ecg9LixmGZ1TPxHdxMCB9FDGFWw3je9Y1nyICBTB2aw7lDckjvHHn/6OXTQiHH/Md/wtTSRyjueh6Ft76APy7e61jN0taF/jpwr3Nucfj+fODHzrnPtLWZ3QTcBNCrV68x27ZtO4XNEGkDzsGeVbBmJm71TGz/BkIYa6w/c+pHscCNIqXXSM4flsvUoTn0zujsdWI5RQ3BEPMe+RGXlj/O6ozzGfrdv2D+yCxz6ECFfjTtoUuHtHcdrJ2FWz8H2934UdBey2Rew0jmh0ZTnjmeLwzrxdShORTmddURMx1cbUOQ2Q/9B1ccfJIN2Rcy4Nt/jugyh88v9NaYym4XkH/U/Z7hx0QiT/ZgyB6Mnf0jqNoDG+eRvWEeXy+ZzzWBt6mtSuS99wuZvmgUq5JPZ9TQwUwdmsMZ+lC1w6muC/D6gz9gWtUzbO5+CQO/9Rz4ovvvqDX20C8BbuFfH4o+4Jwbf7LX1B66RJSG2sZj3TfMIbRuDr6qxn2WFa4fbwdG8UHcOHIGjuP8YblMGZRN16TI3guMdAcO1zP7jz/g6iPPsaPnF8n/5jNRU+YtPcrleWAKkAnsAX4OxAM45x4JH7b4IHAhjYctXn+y4RZQoUsEc65xyt8Ncwitn4vtWorh2EM6bwdGsdCNpqHgLL4wrDfnDc0hT5fZa1dlFbXMfejfua7uL5T2vozu33gqasocdGKRSNuqLoeNb+LWzyFU8g7+wGFqSWBxcBjzQ6PZlXUWo4cP4/yhuQzpnqppCNrQtv2HeevhH3Bj4AXK+15B1tV/iqoyBxW6SPsJ1IWHZubRsHY28VU7AFgZKmB+aDQrk8+g17AzmDqsO+P6pBOvM1VbzbqySt597D/4duhFDgy4kvSvPhZ1ZQ4qdBFvOAfl62D9HBrWzsG/uwgfIfa4brwTHMkS/xgCvc5k1MDeTOyXyeDcVB0100zLth/koyfv4Dv8lcpBX6HLVY9EZZmDCl2kYzi8H0reIrB2Nq5kPvGBaoL4KA71Y3GokOKE0aT0PZ0JA3KY1C+T3hnJGp5pgsUb97H8zz/me/Yy1UOnkXLlQ1Fb5qBCF+l4AvWwqwg2vUP9hvnElxVjhDhMEh8Eh7IoVMiG5LHkDyhkYv9MJvXPJEdXZ/qMuStLKXnpZ9zif4WaYdNI+reHwRfdw1gqdJGOruYgbFmE27SAwMb5xFduB2A3mbwbKGRxqJDd6eMY3r8vk/pnMKFvBmnJsT0lwV8/3k7pzJ9zW9yr1BV+jcTL/xj1ZQ4qdJHIc2Bz49WZNi0gtPld/PWVhDBWuz4sCg5ncaiQmtyxnN6/O2f0y2B8n3SSE1rjPMHI8OR7m6madxffj/sbDSOuJv6y/42JMgcVukhkCwZg9yeweQGhkvmwswifC1BriSwJDuG94HA+4DRSeg5nYv8sJvXPZGR+Gglx0Vdwzjl+/9YG/It+zW1xMwiOvAb/lx6ImTIHFbpIdKmrajw0ctM7hEoW4DuwEYD9vgwWNgxlUbCQpf4R9O3Tl9P7pDM4N5WBOankpSVF9FE0oZDjrtdWk/HxfdwaN4PQqG/g++LvY6rMQYUuEt0O7YDNCxsLfvNCfDUHANjkK+Dd+sFsdHlsdbns9vekS1Y+A3JS6Z+TwsDsVAbkpJDfLbnDF30gGOLHL6+gz8r7uSVuJm70ddilv4u5MgcVukjsCIWgbAVsegc2L8Dt+DsWqP3n07XWie3ksiGQwxbXna2hXHb5e0BGf7p3z6N/dgoDslMYmJNKfnoy/nYq+iP1AcoqaimrrGVPZS1lFXXs+cdyZS27DhzhG7XP8r24Wbgx12OX3B+TZQ4qdJHYFQpB5S7YXwIHNsH+TbC/hOC+EnyHtmEu+M9VK0lhUyiXLS6XLaFcdvh6EEzrS1LuQHp1z2ZATioDslPondG5yUUfDDn2Vdf9s6z3hgv6H4VdVlFDZVUF8bUH6WZVdLNqutH4NTfuMN0TjpATd5gcDtC3ZiWM/SZc/NuYLXNQoYvI8QQb4OC2cNGXwP4SAuUlhPaVkHB496dW3ePS2Opy2RzqznbrQW1qb+KyB5KWN5CCnHRqG4KUVdRw8NABDh/cS33VPoLV+7Dag6S5ysaypppuVkW6VZPlr6abVdPVVRLvGk6csVMaJGdAcjr0OwfO/klMlzm0/XzoIhKJ/PGQ2b/xxgXAUYVQfwQObgkX/SbSyzfSec8GRhxcTqf6BY3zqm6F0BZjNxnEE6AbVSRY8NPvEX5BhxHs1A2S0vGnZGLJvRtLOin9X4WdnPHp+53SwK+KOhX60xKRz0pIhpxhjTca58v+5wzvNYfCe/WbCe7dQErZRvwJSVjXLEjJPE5Bp2Od0oiL8T3r9qBCF5FTk5QGeWMgbwzxQJrXeeSf9F+miEiUUKGLiEQJFbqISJRQoYuIRAkVuohIlFChi4hECRW6iEiUUKGLiEQJz+ZyMbNyYFszvz0T2NeKcbykbemYomVbomU7QNvyD72dc1nHe8KzQnUDvZYAAAOySURBVG8JMys60eQ0kUbb0jFFy7ZEy3aAtqUpNOQiIhIlVOgiIlEiUgv9Ma8DtCJtS8cULdsSLdsB2paTisgxdBER+axI3UMXEZFjqNBFRKJExBW6mV1oZuvNrMTMfuJ1nuYys3wzW2Bma8xstZl93+tMLWFmfjP7xMxe9zpLS5hZmpm9bGbrzGytmZ3hdabmMrN/D/9srTKz582sk9eZmsrMnjSzvWa26qjH0s3sLTPbGP7azcuMTXWCbbkv/DO2wsz+Zmatcp2QiCp0M/MDfwQuAoYCXzWzod6marYA8EPn3FBgAvC9CN4WgO8Da70O0Qr+AMx1zg0GRhCh22RmecBtwFjn3HDAD0zzNtUpeRq48JjHfgLMd84NAOaH70eCp/nstrwFDHfOnQZsAH7aGm8UUYUOjAdKnHObnXP1wAvAZR5nahbnXKlzbll4uYrG4sjzNlXzmFlP4BLgT15naQkz6wpMBp4AcM7VO+cOeZuqReKAJDOLA5KB3R7naTLn3CLgwDEPXwY8E15+Bvg/7RqqmY63Lc65N51zgfDdJUDP1nivSCv0PGDHUfd3EqEleDQzKwBGAR95m6TZfg/8CAh5HaSF+gDlwFPh4aM/mVlnr0M1h3NuF/AbYDtQClQ45970NlWL5TjnSsPLZUCOl2Fa0TeBOa3xQpFW6FHHzFKAV4DbnXOVXuc5VWZ2KbDXObfU6yytIA4YDTzsnBsFHCZyfq3/lPD48mU0/ifVA+hsZld7m6r1uMbjrSP+mGsz+xmNw6/TW+P1Iq3QdwH5R93vGX4sIplZPI1lPt0596rXeZppEvAlM9tK4xDYOWb2Z28jNdtOYKdz7h+/Kb1MY8FHovOALc65cudcA/AqMNHjTC21x8y6A4S/7vU4T4uY2XXApcDXXSudEBRphf4xMMDM+phZAo0f8szyOFOzmJnROFa71jl3v9d5mss591PnXE/nXAGNfx/vOOcick/QOVcG7DCzQeGHzgXWeBipJbYDE8wsOfyzdi4R+gHvUWYB3wgvfwOY6WGWFjGzC2kcpvySc+5Ia71uRBV6+EOEW4B5NP5wvuScW+1tqmabBFxD4x5tcfh2sdehhFuB6Wa2AhgJ/NrjPM0S/i3jZWAZsJLGf+sRc+q8mT0PfAgMMrOdZnYDcC8w1cw20vgbyL1eZmyqE2zLg0Aq8Fb43/4jrfJeOvVfRCQ6RNQeuoiInJgKXUQkSqjQRUSihApdRCRKqNBFRKKECl1EJEqo0EVEosT/BzCFCoRxQySjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h9pjEHTZsJ7",
        "outputId": "4cbf3eb7-7e73-4b1f-99aa-9720bd4d9191"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 6, ..., 7, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "finyhat_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqGoAQcXZsJ8",
        "outputId": "6ba3ae54-0d9b-4dde-9029-972dbbc88cbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 6, ..., 7, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR1MjKSxZsJ8",
        "outputId": "d800ae77-f29a-4127-d1aa-e7318aa5d415"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07119047619047619"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "(finyhat_test.argmax(axis=1) != y_test).sum()/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4kLeQs1ZsJ9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XUv_G0LMLD6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TTuTWZaBLD3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M7CwkPLLLD0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oZywSNMYLDox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Making submission"
      ],
      "metadata": {
        "id": "GqyKAgYuFaav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZztXQzIaZsJ9"
      },
      "outputs": [],
      "source": [
        "X_te = test_df.to_numpy()\n",
        "X_te = X_te/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Xhbd-tZsJ9"
      },
      "outputs": [],
      "source": [
        "y_te = model.predict(X_te).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVqtY96oZsJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3389293f-b77b-49f8-ccfe-a1f33ad331f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 9, ..., 3, 9, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "y_te"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df['Label'] = y_te"
      ],
      "metadata": {
        "id": "PZ7hZ5wXMSoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.to_csv(\"NN_twolayer_normal_128_256_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "ukZeYkA8MSk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MmTNbZqBMSiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zI40_lOUMSew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VMSIeNFyMSaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucTUl_xoZsJ9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aRiZQE9ZsJ-"
      },
      "source": [
        "## Getting some data\n",
        "\n",
        "This is random data. DO NOT USE THIS. This is just to show you what the function calls would be like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZCU7_5CZsJ-"
      },
      "outputs": [],
      "source": [
        "NUM_ROWS = 10000\n",
        "NUM_COLUMNS_X = 200 \n",
        "NUM_CLASSES = 5\n",
        "X = np.random.uniform(size=(NUM_ROWS,NUM_COLUMNS_X))\n",
        "y = np.random.randint(size=(NUM_ROWS,),low=0,high=NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LRm83PKZsJ-"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetworkClassifier([(NUM_COLUMNS_X, \"relu\"), (200, \"relu\"), (NUM_CLASSES, \"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Kl6BohZsJ-"
      },
      "outputs": [],
      "source": [
        "yd = np.zeros((len(y), NUM_CLASSES))\n",
        "for i in range(len(y)):\n",
        "    yd[i][y[i]-1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaAgphWgZsJ_",
        "outputId": "17551f72-22e6-44f7-e4b0-27f2aaac6ab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6.51735571e-04, 9.88383807e-01, 6.17773969e-03, 4.46074257e-04,\n",
              "        4.34064348e-03],\n",
              "       [1.03730682e-03, 9.84018546e-01, 8.62198428e-03, 6.68718651e-04,\n",
              "        5.65344466e-03],\n",
              "       [1.47501066e-03, 9.80120147e-01, 1.01080563e-02, 9.41745652e-04,\n",
              "        7.35504012e-03],\n",
              "       ...,\n",
              "       [1.07377647e-03, 9.83331962e-01, 8.94290440e-03, 7.64428204e-04,\n",
              "        5.88692908e-03],\n",
              "       [1.21479588e-03, 9.81413921e-01, 9.76396501e-03, 8.35904428e-04,\n",
              "        6.77141363e-03],\n",
              "       [1.13575878e-03, 9.83710729e-01, 8.39080987e-03, 7.56295056e-04,\n",
              "        6.00640749e-03]])"
            ]
          },
          "execution_count": 374,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqETj7FKZsJ_",
        "outputId": "949ff763-558a-4ed0-96d9-8a9067087566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.793445531816353"
            ]
          },
          "execution_count": 375,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.categorical_cross_entropy_loss(y, model.predict(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKAS32kTZsJ_"
      },
      "outputs": [],
      "source": [
        "losses = [] \n",
        "NUM_ITERS = 100\n",
        "for _ in range(NUM_ITERS):\n",
        "    yhat = model.predict(X)\n",
        "    loss = model.categorical_cross_entropy_loss(y, yhat)\n",
        "    losses.append(loss)\n",
        "    model.fit_once(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY7gtorHZsKA",
        "outputId": "1347dd7a-52b0-484a-8d8a-9322e1ea0c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4.793445531816353,\n",
              " 4.401753425856968,\n",
              " 4.021828510590914,\n",
              " 3.6597644849216624,\n",
              " 3.3234590729271893,\n",
              " 3.0216763923272665,\n",
              " 2.761871481079625,\n",
              " 2.5474775802452263,\n",
              " 2.376481663143961,\n",
              " 2.242523181984943,\n",
              " 2.1375644686610658,\n",
              " 2.054181558787989,\n",
              " 1.9865785440529005,\n",
              " 1.9306287590757683,\n",
              " 1.8835204183743917,\n",
              " 1.8433588423018594,\n",
              " 1.8088501501263066,\n",
              " 1.7790810848963745,\n",
              " 1.7533755101472572,\n",
              " 1.7312045484170067,\n",
              " 1.7121321142377146,\n",
              " 1.6957830252151016,\n",
              " 1.6818250946759143,\n",
              " 1.6699595640209275,\n",
              " 1.6599162418531153,\n",
              " 1.651451074887023,\n",
              " 1.6443447882988351,\n",
              " 1.6384018361938462,\n",
              " 1.633449288226895,\n",
              " 1.6293355118664818,\n",
              " 1.6259286400297552,\n",
              " 1.623114876944084,\n",
              " 1.6207967172112359,\n",
              " 1.6188911522196578,\n",
              " 1.6173279260877305,\n",
              " 1.6160478874546296,\n",
              " 1.6150014677118636,\n",
              " 1.6141473026612811,\n",
              " 1.6134510038086969,\n",
              " 1.612884077567911,\n",
              " 1.6124229852243417,\n",
              " 1.612048333127781,\n",
              " 1.6117441807762636,\n",
              " 1.6114974537929225,\n",
              " 1.6112974489317355,\n",
              " 1.6111354188981633,\n",
              " 1.6110042257268051,\n",
              " 1.6108980525683105,\n",
              " 1.6108121648957476,\n",
              " 1.6107427132761363,\n",
              " 1.6106865709220948,\n",
              " 1.610641200216784,\n",
              " 1.6106045432814,\n",
              " 1.6105749324260785,\n",
              " 1.6105510169957702,\n",
              " 1.6105317036994085,\n",
              " 1.6105161080023196,\n",
              " 1.6105035145777895,\n",
              " 1.610493345163417,\n",
              " 1.6104851324604361,\n",
              " 1.6104784989576795,\n",
              " 1.6104731397638257,\n",
              " 1.6104688086984864,\n",
              " 1.61046530703018,\n",
              " 1.610462474362313,\n",
              " 1.6104601812609334,\n",
              " 1.610458323293883,\n",
              " 1.610456816212946,\n",
              " 1.6104555920611063,\n",
              " 1.610454596028215,\n",
              " 1.6104537839118436,\n",
              " 1.610453120067332,\n",
              " 1.6104525757531163,\n",
              " 1.610452127795378,\n",
              " 1.610451757510557,\n",
              " 1.6104514498360707,\n",
              " 1.6104511926290896,\n",
              " 1.6104509761009513,\n",
              " 1.6104507923610198,\n",
              " 1.6104506350488448,\n",
              " 1.6104504990375514,\n",
              " 1.610450380194685,\n",
              " 1.6104502751893943,\n",
              " 1.61045018133698,\n",
              " 1.6104500964735744,\n",
              " 1.6104500188551218,\n",
              " 1.6104499470759401,\n",
              " 1.6104498800030813,\n",
              " 1.6104498167234194,\n",
              " 1.6104497565009994,\n",
              " 1.610449698742665,\n",
              " 1.6104496429703512,\n",
              " 1.610449588798754,\n",
              " 1.6104495359173276,\n",
              " 1.6104494840757848,\n",
              " 1.6104494330723984,\n",
              " 1.6104493827445818,\n",
              " 1.6104493329612957,\n",
              " 1.6104492836169222,\n",
              " 1.6104492346263366]"
            ]
          },
          "execution_count": 377,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl5EmAk2ZsKA"
      },
      "outputs": [],
      "source": [
        "q = np.array([[1, -1, 2], [1, 2, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uUbtv4WZsKA",
        "outputId": "17cc6c3e-7fdc-4a60-c510-c070464d6acb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 0, 3],\n",
              "       [3, 4, 5]])"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q + np.array([[1], [2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIUNx1sGZsKA",
        "outputId": "8aa6bc19-e601-4499-e6ce-2f2de59d3bde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.07382656],\n",
              "       [0.07878063],\n",
              "       [0.02466814],\n",
              "       [0.08475965]])"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " np.random.uniform(low=0, high=0.1, size=(4, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9nQFSAtZsKB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVhBv2CZsKB",
        "outputId": "80b82e7b-540b-4f35-8355-2fb49c73db73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25949646, 0.03511903, 0.70538451],\n",
              "       [0.09003057, 0.24472847, 0.66524096]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = np.array([[1, -1, 2], [1, 2, 3]])\n",
        "np.exp(q) / np.tile(np.exp(q).sum(axis=1), (3, 1)).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdEE8t6XZsKB",
        "outputId": "9700244d-5245-413a-96d0-f0c6a76e5d09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25949646, 0.03511903, 0.70538451],\n",
              "       [0.09003057, 0.24472847, 0.66524096]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "softmaxActivate(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVELzNLYZsKB"
      },
      "outputs": [],
      "source": [
        "l = [softmaxActivate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qinHHKgZsKB",
        "outputId": "8ab5bd35-1b22-424b-a32d-83858636075a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25949646, 0.03511903, 0.70538451],\n",
              "       [0.09003057, 0.24472847, 0.66524096]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l[0](q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8uQijniZsKB",
        "outputId": "8111aaa4-56fc-4450-cac8-e49bac72ae81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.71828183,  0.36787944,  7.3890561 ],\n",
              "       [ 2.71828183,  7.3890561 , 20.08553692]])"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.exp(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozQ1oAD8ZsKC"
      },
      "outputs": [],
      "source": [
        "r = np.array([-1,5,6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGjxts06ZsKC"
      },
      "outputs": [],
      "source": [
        "r[r<0] = 0\n",
        "r[r>0] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJnyo3cuZsKC",
        "outputId": "9b6f929d-4817-4fc0-b41f-3a4abd6e7765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1])"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43S2cmrDZsKC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "3e8fb002e6e83f8cdbe11f489f5734d63338be518a5eeb53c4bb6f16064b3c51"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "notebook_changes_256_256.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-aRiZQE9ZsJ-"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}