{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB3aQxfqZsJq"
      },
      "source": [
        "Please read the assignment description document."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWOjK1DweJS",
        "outputId": "2c697376-8fa0-498f-8a48-90adaf3de963"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcoKSbpvZsJu"
      },
      "source": [
        "# Imports: No other imports allowed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oha8pGPvZsJv"
      },
      "outputs": [],
      "source": [
        "import numpy as np #No using automatic differentiation allowed from here!\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noaSPo4WZsJw"
      },
      "source": [
        "## Class template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gPuym061ZsJx"
      },
      "outputs": [],
      "source": [
        "def linearActivate(X):\n",
        "    return X\n",
        "\n",
        "def reluActivate(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "def softmaxActivate(X):\n",
        "    expval = np.exp(X - np.max(X, axis=0, keepdims=True))\n",
        "    return expval / np.sum(expval, axis=0, keepdims=True)\n",
        "\n",
        "def linearActivateGrad(X):\n",
        "    return 1\n",
        "\n",
        "def reluActivateGrad(X):\n",
        "    ar = X\n",
        "    ar[ar >= 0] = 1\n",
        "    ar[ar < 0] = 0\n",
        "    return ar\n",
        "\n",
        "def softmaxActivateGrad(X):\n",
        "    val = softmaxActivate(X)\n",
        "    return val * (1-val)\n",
        "    \n",
        "\n",
        "class NeuralNetworkClassifier: \n",
        "    \n",
        "    def __init__(self, layers): \n",
        "        #### CHANGE THE CODE BELOW  \n",
        "        \n",
        "        # The number of layers, including the input layer\n",
        "        self.num_layers = len(layers)\n",
        "        \n",
        "        # Information about each layer (like the size, activation function etc)\n",
        "        self.linfo = {}\n",
        "        \n",
        "        # For each layers, give the info, following the convention that layer 0 is the input layer\n",
        "        for l in range(0, self.num_layers):\n",
        "            \n",
        "            self.linfo[l] = list(layers[l])\n",
        "            if(self.linfo[l][1] == 'linear'):\n",
        "                self.linfo[l].append(linearActivate)\n",
        "                self.linfo[l].append(linearActivateGrad)\n",
        "                \n",
        "            elif(self.linfo[l][1] == 'relu'):\n",
        "                self.linfo[l].append(reluActivate)\n",
        "                self.linfo[l].append(reluActivateGrad)\n",
        "                \n",
        "            else:\n",
        "                self.linfo[l].append(softmaxActivate)\n",
        "                self.linfo[l].append(softmaxActivateGrad)\n",
        "                \n",
        "            \n",
        "        # Parameters for each layer\n",
        "        self.weights = {}\n",
        "        self.bias = {}\n",
        "        \n",
        "        # Randomly initializing the parameters for the layers (except the input one) \n",
        "        for l in range(1, self.num_layers):\n",
        "            div = self.linfo[l-1][0] + self.linfo[l][0]\n",
        "            self.weights[l] = np.random.randn(self.linfo[l][0], self.linfo[l-1][0])/np.sqrt(div)\n",
        "            self.bias[l] = np.random.randn(self.linfo[l][0], 1)/np.sqrt(div)\n",
        "        \n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n",
        "        \n",
        "    def predict(self, X): \n",
        "        #### CHANGE THE CODE BELOW \n",
        "\n",
        "        Z = {}\n",
        "        A = {}\n",
        "        cura = X.T\n",
        "        \n",
        "        for l in range(1, self.num_layers):\n",
        "            Z[l] = (self.weights[l] @ cura) + self.bias[l]\n",
        "            activation_fun = self.linfo[l][2]\n",
        "            A[l] = activation_fun(Z[l])\n",
        "            cura = A[l]\n",
        "        \n",
        "        return cura.T\n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n",
        "    def fit_once(self, X, y, alpha=0.001): \n",
        "        #### CHANGE THE CODE BELOW\n",
        "        \n",
        "        y_d = np.zeros((len(y), self.linfo[len(self.linfo)-1][0]))\n",
        "        for i in range(len(y)):\n",
        "            y_d[i][y[i]] = 1\n",
        "        y_d = y_d.T\n",
        "          \n",
        "        Z = {}\n",
        "        A = {}\n",
        "        Z[0] = X.T\n",
        "        A[0] = X.T\n",
        "        for l in range(1, self.num_layers):\n",
        "            Z[l] = (self.weights[l] @ A[l-1]) + self.bias[l]\n",
        "            activation_fun = self.linfo[l][2]\n",
        "            A[l] = activation_fun(Z[l])\n",
        "        \n",
        "        dZ = {}\n",
        "        dW = {}\n",
        "        db = {}\n",
        "        m = X.shape[0]\n",
        "        dZ[self.num_layers-1] = A[self.num_layers-1] - y_d\n",
        "        dW[self.num_layers-1] = (1/m) * (dZ[self.num_layers-1] @ A[self.num_layers-2].T)\n",
        "        db[self.num_layers-1] = (1/m) * np.sum(dZ[self.num_layers-1], axis=1, keepdims=True)\n",
        "        \n",
        "        \n",
        "        for l in range(self.num_layers-2, 0, -1):\n",
        "            activationGrad = self.linfo[l][3]\n",
        "            dZ[l] = (self.weights[l+1].T @ dZ[l+1]) * activationGrad(Z[l])\n",
        "            dW[l] = (1/m) * (dZ[l] @ A[l-1].T)\n",
        "            db[l] = (1/m) * np.sum(dZ[l], axis=1, keepdims=True)\n",
        "        \n",
        "        \n",
        "        for l in range(1, self.num_layers):\n",
        "            assert(self.weights[l].shape == dW[l].shape)\n",
        "            self.weights[l] -= alpha*dW[l]\n",
        "            assert(self.bias[l].shape == db[l].shape)\n",
        "            self.bias[l] -= alpha*db[l]\n",
        "        \n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n",
        "        \n",
        "    def categorical_cross_entropy_loss(self, y, yhat):\n",
        "      \n",
        "        #### CHANGE THE CODE BELOW\n",
        "        \n",
        "        sh = (len(y), self.linfo[len(self.linfo)-1][0])\n",
        "        y_d = np.zeros(sh)\n",
        "        for i in range(len(y)):\n",
        "            y_d[i][y[i]] = 1\n",
        "            \n",
        "        yhat = np.clip(yhat, 1e-7, 1-1e-7)\n",
        "        logs = -np.log(np.sum(y_d * yhat, axis=1)) \n",
        "        return logs.mean()\n",
        "    \n",
        "        #### CHANGE THE CODE ABOVE\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDqiM44ZZsJ1"
      },
      "source": [
        "# Example main code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DSQ1wniFZsJ1"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignment3/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignment3/test.csv')\n",
        "sample_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Assignment3/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "JBm5GEK9ZsJ1",
        "outputId": "7448a1a7-5dfc-4bf4-92f1-1f2dadc8a2e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f0aab032-6ce9-4e61-81fa-993d9ffe6f0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0aab032-6ce9-4e61-81fa-993d9ffe6f0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0aab032-6ce9-4e61-81fa-993d9ffe6f0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0aab032-6ce9-4e61-81fa-993d9ffe6f0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-B3sZ0kBZsJ3",
        "outputId": "c3ae9ef6-6dcb-4330-daed-12a8934b52b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cb30209e-b452-410b-832a-06606b19c57d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb30209e-b452-410b-832a-06606b19c57d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb30209e-b452-410b-832a-06606b19c57d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb30209e-b452-410b-832a-06606b19c57d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0       0       0       0       0  ...         0         0         0         0\n",
              "1       0       0       0       0  ...         0         0         0         0\n",
              "2       0       0       0       0  ...         0         0         0         0\n",
              "3       0       0       0       0  ...         0         0         0         0\n",
              "4       0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-NUhdfZgZsJ4",
        "outputId": "2d89decc-c441-4557-9f02-944523c57498"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8769366c-115d-4feb-9db6-049720f51d08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8769366c-115d-4feb-9db6-049720f51d08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8769366c-115d-4feb-9db6-049720f51d08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8769366c-115d-4feb-9db6-049720f51d08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      0\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sample_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JGJcgKcnZsJ5"
      },
      "outputs": [],
      "source": [
        "X = train_df.iloc[:, 1:].to_numpy()\n",
        "y = train_df['label'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X/255"
      ],
      "metadata": {
        "id": "ev17sc_jyEVB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T1FZ5nQiZsJ5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.20, random_state=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WP0DNpjwZsJ5"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetworkClassifier([(X_train.shape[1], \"relu\"), (128, \"relu\"), (256, \"relu\"), (10, \"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI6BMMShZsJ6",
        "outputId": "c6171b27-0e01-4ea5-a7f1-accf6c5599b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9489285714285715\n",
            "0 Train_loss = 0.1522271963256     Test_loss = 0.18731616915541172\n",
            "\n",
            "Accuracy : 0.9491666666666667\n",
            "1 Train_loss = 0.15213883190890382     Test_loss = 0.18724319705686554\n",
            "\n",
            "Accuracy : 0.9491666666666667\n",
            "2 Train_loss = 0.15205052967802116     Test_loss = 0.18717028758389687\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "3 Train_loss = 0.1519623041528851     Test_loss = 0.18709734106049294\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "4 Train_loss = 0.15187418253077775     Test_loss = 0.18702428599991752\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "5 Train_loss = 0.15178605807243234     Test_loss = 0.18695129624075502\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "6 Train_loss = 0.1516979725772247     Test_loss = 0.18687812686076888\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "7 Train_loss = 0.15160993218070823     Test_loss = 0.18680509147246796\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "8 Train_loss = 0.15152190476562474     Test_loss = 0.1867322154375375\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "9 Train_loss = 0.1514339894790321     Test_loss = 0.18665958203849303\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "10 Train_loss = 0.15134617137969186     Test_loss = 0.18658664149088183\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "11 Train_loss = 0.1512583498625365     Test_loss = 0.18651405457907236\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "12 Train_loss = 0.15117050805281493     Test_loss = 0.18644123616298242\n",
            "\n",
            "Accuracy : 0.9492857142857143\n",
            "13 Train_loss = 0.151082693615858     Test_loss = 0.1863684969904706\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "14 Train_loss = 0.1509949069318756     Test_loss = 0.18629629637942557\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "15 Train_loss = 0.15090724416249587     Test_loss = 0.1862235060645505\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "16 Train_loss = 0.1508196245413782     Test_loss = 0.18615050018071705\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "17 Train_loss = 0.15073210515348953     Test_loss = 0.186077800173993\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "18 Train_loss = 0.15064458693964308     Test_loss = 0.18600548432668285\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "19 Train_loss = 0.15055705656253562     Test_loss = 0.18593350422433635\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "20 Train_loss = 0.15046950818984067     Test_loss = 0.1858606602301504\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "21 Train_loss = 0.15038199274489775     Test_loss = 0.18578904097371943\n",
            "\n",
            "Accuracy : 0.9494047619047619\n",
            "22 Train_loss = 0.15029454866715944     Test_loss = 0.18571656081157148\n",
            "\n",
            "Accuracy : 0.9495238095238095\n",
            "23 Train_loss = 0.1502071349520029     Test_loss = 0.18564378997382452\n",
            "\n",
            "Accuracy : 0.9495238095238095\n",
            "24 Train_loss = 0.1501197986562743     Test_loss = 0.1855717896119665\n",
            "\n",
            "Accuracy : 0.9495238095238095\n",
            "25 Train_loss = 0.1500325223127825     Test_loss = 0.18549971696295564\n",
            "\n",
            "Accuracy : 0.9496428571428571\n",
            "26 Train_loss = 0.14994535142311854     Test_loss = 0.18542818327504643\n",
            "\n",
            "Accuracy : 0.9496428571428571\n",
            "27 Train_loss = 0.1498582410189383     Test_loss = 0.1853565236588211\n",
            "\n",
            "Accuracy : 0.9496428571428571\n",
            "28 Train_loss = 0.14977121582900074     Test_loss = 0.18528487335477548\n",
            "\n",
            "Accuracy : 0.9497619047619048\n",
            "29 Train_loss = 0.1496842557360202     Test_loss = 0.18521361827672775\n",
            "\n",
            "Accuracy : 0.9497619047619048\n",
            "30 Train_loss = 0.1495973773822099     Test_loss = 0.18514170303184233\n",
            "\n",
            "Accuracy : 0.9497619047619048\n",
            "31 Train_loss = 0.14951070810680067     Test_loss = 0.18507098308009945\n",
            "\n",
            "Accuracy : 0.9497619047619048\n",
            "32 Train_loss = 0.149424190743621     Test_loss = 0.18499992146239422\n",
            "\n",
            "Accuracy : 0.9498809523809524\n",
            "33 Train_loss = 0.14933777884884838     Test_loss = 0.18492903173051517\n",
            "\n",
            "Accuracy : 0.95\n",
            "34 Train_loss = 0.14925149214100275     Test_loss = 0.184858328771586\n",
            "\n",
            "Accuracy : 0.95\n",
            "35 Train_loss = 0.14916535228992914     Test_loss = 0.1847871703383013\n",
            "\n",
            "Accuracy : 0.9501190476190476\n",
            "36 Train_loss = 0.14907928237590223     Test_loss = 0.18471635202584805\n",
            "\n",
            "Accuracy : 0.9501190476190476\n",
            "37 Train_loss = 0.148993287556533     Test_loss = 0.18464584043188345\n",
            "\n",
            "Accuracy : 0.9502380952380952\n",
            "38 Train_loss = 0.14890741278571543     Test_loss = 0.18457542689447137\n",
            "\n",
            "Accuracy : 0.9502380952380952\n",
            "39 Train_loss = 0.1488215688010206     Test_loss = 0.1845052585047229\n",
            "\n",
            "Accuracy : 0.9502380952380952\n",
            "40 Train_loss = 0.1487357307698096     Test_loss = 0.18443444792966074\n",
            "\n",
            "Accuracy : 0.9502380952380952\n",
            "41 Train_loss = 0.1486499295084376     Test_loss = 0.18436410461178687\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "42 Train_loss = 0.1485641662738563     Test_loss = 0.18429342771361895\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "43 Train_loss = 0.14847851608079554     Test_loss = 0.1842229597521594\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "44 Train_loss = 0.14839296786888187     Test_loss = 0.1841527430110943\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "45 Train_loss = 0.1483075015230691     Test_loss = 0.18408267708226161\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "46 Train_loss = 0.14822214576588794     Test_loss = 0.18401250720578471\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "47 Train_loss = 0.14813685538601906     Test_loss = 0.18394324945393914\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "48 Train_loss = 0.1480516438955575     Test_loss = 0.1838733851343113\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "49 Train_loss = 0.14796658871613086     Test_loss = 0.18380397382709487\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "50 Train_loss = 0.14788162741337355     Test_loss = 0.18373437989565702\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "51 Train_loss = 0.14779669971963033     Test_loss = 0.18366476275275836\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "52 Train_loss = 0.14771184288448222     Test_loss = 0.18359526769791912\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "53 Train_loss = 0.14762708621158263     Test_loss = 0.18352546954385532\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "54 Train_loss = 0.147542386955912     Test_loss = 0.18345633235942108\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "55 Train_loss = 0.1474577739771119     Test_loss = 0.18338766666904963\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "56 Train_loss = 0.14737322905946007     Test_loss = 0.1833186021423149\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "57 Train_loss = 0.14728882951788744     Test_loss = 0.1832497814008489\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "58 Train_loss = 0.1472045575955057     Test_loss = 0.1831815692820723\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "59 Train_loss = 0.1471203790188949     Test_loss = 0.18311303799600923\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "60 Train_loss = 0.14703629098118556     Test_loss = 0.18304458723925066\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "61 Train_loss = 0.14695222643016323     Test_loss = 0.18297659489377263\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "62 Train_loss = 0.14686827240178627     Test_loss = 0.1829088640227306\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "63 Train_loss = 0.1467844571664307     Test_loss = 0.18284061432308568\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "64 Train_loss = 0.14670073363460387     Test_loss = 0.1827729181504369\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "65 Train_loss = 0.1466170894333904     Test_loss = 0.18270504229131868\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "66 Train_loss = 0.14653351076695428     Test_loss = 0.18263766431466077\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "67 Train_loss = 0.14645000150350757     Test_loss = 0.18256975250448715\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "68 Train_loss = 0.14636653949731618     Test_loss = 0.18250243896681317\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "69 Train_loss = 0.14628317273188624     Test_loss = 0.18243473242218416\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "70 Train_loss = 0.1461998570884248     Test_loss = 0.18236779547594711\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "71 Train_loss = 0.14611660206638352     Test_loss = 0.18230020754613488\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "72 Train_loss = 0.14603346322106875     Test_loss = 0.18223375379909612\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "73 Train_loss = 0.1459503964393815     Test_loss = 0.18216665383538289\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "74 Train_loss = 0.1458674019183212     Test_loss = 0.18209981115943993\n",
            "\n",
            "Accuracy : 0.9503571428571429\n",
            "75 Train_loss = 0.14578447752529286     Test_loss = 0.18203332235259945\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "76 Train_loss = 0.14570157169921374     Test_loss = 0.18196560989390972\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "77 Train_loss = 0.1456187656522479     Test_loss = 0.18189903314015582\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "78 Train_loss = 0.1455360437628515     Test_loss = 0.18183177108976992\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "79 Train_loss = 0.14545339112168484     Test_loss = 0.18176513567400682\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "80 Train_loss = 0.14537078934337264     Test_loss = 0.1816977624397618\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "81 Train_loss = 0.14528828331889124     Test_loss = 0.18163124872349604\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "82 Train_loss = 0.14520587326212436     Test_loss = 0.1815639418607778\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "83 Train_loss = 0.14512353943258752     Test_loss = 0.1814978161226455\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "84 Train_loss = 0.14504131830594363     Test_loss = 0.1814311280046128\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "85 Train_loss = 0.14495914247442168     Test_loss = 0.1813645612189813\n",
            "\n",
            "Accuracy : 0.9504761904761905\n",
            "86 Train_loss = 0.1448770523359652     Test_loss = 0.18129773521749956\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "87 Train_loss = 0.14479500749361351     Test_loss = 0.18123189510159854\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "88 Train_loss = 0.1447130531588301     Test_loss = 0.181165059667344\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "89 Train_loss = 0.14463116753381738     Test_loss = 0.1810988814910602\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "90 Train_loss = 0.14454935009425784     Test_loss = 0.18103206487525753\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "91 Train_loss = 0.1444675602274629     Test_loss = 0.18096588404790406\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "92 Train_loss = 0.14438581161809066     Test_loss = 0.180900020536384\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "93 Train_loss = 0.14430413374096182     Test_loss = 0.18083332261030124\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "94 Train_loss = 0.1442225279020072     Test_loss = 0.18076786304641132\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "95 Train_loss = 0.14414096613665808     Test_loss = 0.18070156812995866\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "96 Train_loss = 0.14405947348867007     Test_loss = 0.18063584049642276\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "97 Train_loss = 0.14397801728341197     Test_loss = 0.1805706190482572\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "98 Train_loss = 0.14389663793321272     Test_loss = 0.18050453536270064\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "99 Train_loss = 0.14381533746280392     Test_loss = 0.18043922440235824\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "100 Train_loss = 0.14373412551096046     Test_loss = 0.18037357723834085\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "101 Train_loss = 0.14365296056755156     Test_loss = 0.18030774269417185\n",
            "\n",
            "Accuracy : 0.950595238095238\n",
            "102 Train_loss = 0.1435718555027299     Test_loss = 0.1802423392601152\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "103 Train_loss = 0.14349081585133902     Test_loss = 0.1801770688727399\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "104 Train_loss = 0.14340984626735898     Test_loss = 0.1801109705811656\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "105 Train_loss = 0.14332894674685467     Test_loss = 0.18004564357110664\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "106 Train_loss = 0.1432481312729744     Test_loss = 0.17998046866127118\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "107 Train_loss = 0.14316737178264569     Test_loss = 0.17991509259774513\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "108 Train_loss = 0.14308671815964397     Test_loss = 0.1798498812441457\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "109 Train_loss = 0.1430061696065931     Test_loss = 0.17978478149338437\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "110 Train_loss = 0.14292566988516747     Test_loss = 0.1797203664876315\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "111 Train_loss = 0.14284518405148192     Test_loss = 0.17965421582195462\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "112 Train_loss = 0.14276476734493762     Test_loss = 0.17959071129706553\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "113 Train_loss = 0.1426844080037359     Test_loss = 0.1795251224567665\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "114 Train_loss = 0.14260413900245356     Test_loss = 0.1794608707184411\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "115 Train_loss = 0.14252402332339298     Test_loss = 0.17939584617555268\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "116 Train_loss = 0.14244404520834444     Test_loss = 0.1793317802547208\n",
            "\n",
            "Accuracy : 0.9507142857142857\n",
            "117 Train_loss = 0.14236412848126953     Test_loss = 0.1792672092041156\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "118 Train_loss = 0.14228431733299624     Test_loss = 0.17920334947122163\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "119 Train_loss = 0.14220457648187973     Test_loss = 0.17913950802021766\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "120 Train_loss = 0.1421248635307306     Test_loss = 0.17907590385462893\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "121 Train_loss = 0.14204523306580202     Test_loss = 0.17901200362387354\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "122 Train_loss = 0.14196566465872434     Test_loss = 0.17894800388085672\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "123 Train_loss = 0.1418861017598187     Test_loss = 0.17888507827487518\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "124 Train_loss = 0.1418065874494917     Test_loss = 0.17882161896055224\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "125 Train_loss = 0.14172717915876493     Test_loss = 0.17875852239877404\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "126 Train_loss = 0.14164781599767381     Test_loss = 0.17869483572978542\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "127 Train_loss = 0.14156845434319645     Test_loss = 0.17863137790229994\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "128 Train_loss = 0.14148910732738038     Test_loss = 0.17856844992977466\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "129 Train_loss = 0.14140978693974227     Test_loss = 0.1785047799033496\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "130 Train_loss = 0.14133047827615916     Test_loss = 0.17844160818670318\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "131 Train_loss = 0.1412512267280494     Test_loss = 0.1783783997061606\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "132 Train_loss = 0.1411719893928778     Test_loss = 0.17831526808255552\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "133 Train_loss = 0.14109280857177392     Test_loss = 0.17825231962687058\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "134 Train_loss = 0.1410136892613345     Test_loss = 0.17818931868418642\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "135 Train_loss = 0.14093458419453553     Test_loss = 0.17812646307146202\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "136 Train_loss = 0.14085552595733014     Test_loss = 0.178064027944909\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "137 Train_loss = 0.14077654202313164     Test_loss = 0.1780015948521736\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "138 Train_loss = 0.14069757827989587     Test_loss = 0.177938545165474\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "139 Train_loss = 0.1406186567232456     Test_loss = 0.17787590558131183\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "140 Train_loss = 0.14053978018634977     Test_loss = 0.17781295447612577\n",
            "\n",
            "Accuracy : 0.9508333333333333\n",
            "141 Train_loss = 0.14046095184963558     Test_loss = 0.17775077014191484\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "142 Train_loss = 0.1403822040444546     Test_loss = 0.1776880829793817\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "143 Train_loss = 0.1403034878933531     Test_loss = 0.17762556502038188\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "144 Train_loss = 0.14022485587203856     Test_loss = 0.17756365821485873\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "145 Train_loss = 0.1401463005187383     Test_loss = 0.17750108413578458\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "146 Train_loss = 0.14006783930714115     Test_loss = 0.17743926609586222\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "147 Train_loss = 0.13998942581125676     Test_loss = 0.17737673929511327\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "148 Train_loss = 0.13991114268661986     Test_loss = 0.17731465468715873\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "149 Train_loss = 0.1398328773071186     Test_loss = 0.1772518598781923\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "150 Train_loss = 0.13975468477520478     Test_loss = 0.17719013703163483\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "151 Train_loss = 0.13967654468019433     Test_loss = 0.17712826092395254\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "152 Train_loss = 0.1395984375536956     Test_loss = 0.17706584448737311\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "153 Train_loss = 0.13952041089627507     Test_loss = 0.1770042631908643\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "154 Train_loss = 0.13944247338376178     Test_loss = 0.1769422215584743\n",
            "\n",
            "Accuracy : 0.950952380952381\n",
            "155 Train_loss = 0.13936463032173116     Test_loss = 0.1768806530350446\n",
            "\n",
            "Accuracy : 0.9510714285714286\n",
            "156 Train_loss = 0.13928680772928967     Test_loss = 0.1768193148462601\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "157 Train_loss = 0.1392090394627184     Test_loss = 0.17675733294275164\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "158 Train_loss = 0.13913130939794768     Test_loss = 0.1766958823448835\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "159 Train_loss = 0.13905358895993675     Test_loss = 0.17663494936402285\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "160 Train_loss = 0.13897594001068933     Test_loss = 0.17657271199508595\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "161 Train_loss = 0.13889836896195065     Test_loss = 0.17651210356264238\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "162 Train_loss = 0.13882080815751005     Test_loss = 0.17645072344781498\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "163 Train_loss = 0.1387432567537685     Test_loss = 0.17638912290182654\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "164 Train_loss = 0.13866574618585914     Test_loss = 0.17632793124803267\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "165 Train_loss = 0.13858828381610855     Test_loss = 0.17626615361241615\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "166 Train_loss = 0.1385108659931518     Test_loss = 0.17620435708141777\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "167 Train_loss = 0.13843349874486519     Test_loss = 0.17614347654672488\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "168 Train_loss = 0.13835622181541546     Test_loss = 0.17608150253405055\n",
            "\n",
            "Accuracy : 0.9510714285714286\n",
            "169 Train_loss = 0.13827902000886352     Test_loss = 0.17602031968630902\n",
            "\n",
            "Accuracy : 0.9510714285714286\n",
            "170 Train_loss = 0.13820191413840593     Test_loss = 0.17595831993625846\n",
            "\n",
            "Accuracy : 0.9510714285714286\n",
            "171 Train_loss = 0.13812491270875782     Test_loss = 0.17589732576857992\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "172 Train_loss = 0.13804793447621674     Test_loss = 0.1758360850590476\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "173 Train_loss = 0.13797099040145797     Test_loss = 0.1757751370165239\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "174 Train_loss = 0.13789408344381954     Test_loss = 0.17571359716763907\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "175 Train_loss = 0.13781724007122556     Test_loss = 0.17565300962612507\n",
            "\n",
            "Accuracy : 0.9511904761904761\n",
            "176 Train_loss = 0.13774044733226806     Test_loss = 0.17559228987980863\n",
            "\n",
            "Accuracy : 0.9513095238095238\n",
            "177 Train_loss = 0.13766366969578792     Test_loss = 0.17553167920851562\n",
            "\n",
            "Accuracy : 0.9513095238095238\n",
            "178 Train_loss = 0.13758687251717605     Test_loss = 0.17547055645329068\n",
            "\n",
            "Accuracy : 0.9513095238095238\n",
            "179 Train_loss = 0.13751013459370476     Test_loss = 0.17541013145933065\n",
            "\n",
            "Accuracy : 0.9513095238095238\n",
            "180 Train_loss = 0.13743352212041532     Test_loss = 0.17534976132403726\n",
            "\n",
            "Accuracy : 0.9514285714285714\n",
            "181 Train_loss = 0.13735698032136268     Test_loss = 0.17528945080892783\n",
            "\n",
            "Accuracy : 0.9514285714285714\n",
            "182 Train_loss = 0.13728054463388287     Test_loss = 0.1752295222757925\n",
            "\n",
            "Accuracy : 0.9514285714285714\n",
            "183 Train_loss = 0.13720418641510884     Test_loss = 0.1751694994462928\n",
            "\n",
            "Accuracy : 0.9514285714285714\n",
            "184 Train_loss = 0.13712787614344665     Test_loss = 0.17510869834940443\n",
            "\n",
            "Accuracy : 0.9514285714285714\n",
            "185 Train_loss = 0.13705163982051735     Test_loss = 0.1750485939288555\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "186 Train_loss = 0.13697554819526603     Test_loss = 0.17498827480123885\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "187 Train_loss = 0.1368995487442669     Test_loss = 0.1749280671888553\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "188 Train_loss = 0.13682363109363893     Test_loss = 0.17486858885340859\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "189 Train_loss = 0.13674780520204616     Test_loss = 0.17480827512394423\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "190 Train_loss = 0.13667202670705003     Test_loss = 0.17474870343364057\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "191 Train_loss = 0.13659631239309045     Test_loss = 0.1746885026887621\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "192 Train_loss = 0.1365206483462052     Test_loss = 0.1746287745036717\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "193 Train_loss = 0.13644507794454877     Test_loss = 0.17456823101043945\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "194 Train_loss = 0.13636951612409867     Test_loss = 0.1745088957450387\n",
            "\n",
            "Accuracy : 0.9515476190476191\n",
            "195 Train_loss = 0.13629398583305138     Test_loss = 0.17444878778662865\n",
            "\n",
            "Accuracy : 0.9516666666666667\n",
            "196 Train_loss = 0.13621852597510611     Test_loss = 0.17438962978704084\n",
            "\n",
            "Accuracy : 0.9516666666666667\n",
            "197 Train_loss = 0.13614313615335485     Test_loss = 0.1743291354836981\n",
            "\n",
            "Accuracy : 0.9516666666666667\n",
            "198 Train_loss = 0.13606782006488452     Test_loss = 0.1742697942126413\n",
            "\n",
            "Accuracy : 0.9516666666666667\n",
            "199 Train_loss = 0.13599258625011768     Test_loss = 0.174209689939576\n",
            "\n",
            "Accuracy : 0.9516666666666667\n",
            "200 Train_loss = 0.135917459669069     Test_loss = 0.1741505797132658\n",
            "\n",
            "Accuracy : 0.9517857142857142\n",
            "201 Train_loss = 0.13584241528906615     Test_loss = 0.17409069929950277\n",
            "\n",
            "Accuracy : 0.9517857142857142\n",
            "202 Train_loss = 0.13576742340295953     Test_loss = 0.17403122937997748\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "203 Train_loss = 0.13569248075200957     Test_loss = 0.1739715397430045\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "204 Train_loss = 0.13561757541622002     Test_loss = 0.17391251155842247\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "205 Train_loss = 0.13554277960111336     Test_loss = 0.17385269467018888\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "206 Train_loss = 0.13546805975330828     Test_loss = 0.17379296058432064\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "207 Train_loss = 0.1353934066818303     Test_loss = 0.17373412446252842\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "208 Train_loss = 0.1353188343299823     Test_loss = 0.17367525030836742\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "209 Train_loss = 0.1352443149950346     Test_loss = 0.17361599001114686\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "210 Train_loss = 0.13516987977518696     Test_loss = 0.17355789520852752\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "211 Train_loss = 0.13509547556504703     Test_loss = 0.17349842199454293\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "212 Train_loss = 0.13502114765251275     Test_loss = 0.17344002302582107\n",
            "\n",
            "Accuracy : 0.9519047619047619\n",
            "213 Train_loss = 0.13494694184944023     Test_loss = 0.17338130252861372\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "214 Train_loss = 0.13487279773765426     Test_loss = 0.17332270594081062\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "215 Train_loss = 0.13479872942382118     Test_loss = 0.17326384273822054\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "216 Train_loss = 0.13472472238816893     Test_loss = 0.17320584658038748\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "217 Train_loss = 0.13465079319217801     Test_loss = 0.17314746606142742\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "218 Train_loss = 0.1345769752119787     Test_loss = 0.17308899200581415\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "219 Train_loss = 0.13450320536605634     Test_loss = 0.1730305581881594\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "220 Train_loss = 0.1344295079880369     Test_loss = 0.17297251104700154\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "221 Train_loss = 0.13435585544028603     Test_loss = 0.17291383475971167\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "222 Train_loss = 0.13428226633598242     Test_loss = 0.17285594979431096\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "223 Train_loss = 0.1342087480384697     Test_loss = 0.17279719512541214\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "224 Train_loss = 0.13413528373448746     Test_loss = 0.1727392978469869\n",
            "\n",
            "Accuracy : 0.9520238095238095\n",
            "225 Train_loss = 0.13406185330961595     Test_loss = 0.17268180988022266\n",
            "\n",
            "Accuracy : 0.9521428571428572\n",
            "226 Train_loss = 0.13398850403468232     Test_loss = 0.17262412295695292\n",
            "\n",
            "Accuracy : 0.9521428571428572\n",
            "227 Train_loss = 0.13391520585227623     Test_loss = 0.1725665557578994\n",
            "\n",
            "Accuracy : 0.9521428571428572\n",
            "228 Train_loss = 0.13384193643412254     Test_loss = 0.17250914972285633\n",
            "\n",
            "Accuracy : 0.9521428571428572\n",
            "229 Train_loss = 0.13376864907097522     Test_loss = 0.17245200662036964\n",
            "\n",
            "Accuracy : 0.9521428571428572\n",
            "230 Train_loss = 0.13369539988003953     Test_loss = 0.17239474559024207\n",
            "\n",
            "Accuracy : 0.9522619047619048\n",
            "231 Train_loss = 0.1336221749309756     Test_loss = 0.17233767499310104\n",
            "\n",
            "Accuracy : 0.9522619047619048\n",
            "232 Train_loss = 0.133548978082925     Test_loss = 0.17228024258560132\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "233 Train_loss = 0.1334758046094303     Test_loss = 0.1722230040282736\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "234 Train_loss = 0.13340268420455154     Test_loss = 0.17216571885299387\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "235 Train_loss = 0.13332966987193232     Test_loss = 0.17210814563075905\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "236 Train_loss = 0.1332567162840237     Test_loss = 0.17205095215552094\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "237 Train_loss = 0.13318382142662505     Test_loss = 0.17199358595415096\n",
            "\n",
            "Accuracy : 0.9525\n",
            "238 Train_loss = 0.13311102980365164     Test_loss = 0.1719370354714448\n",
            "\n",
            "Accuracy : 0.9525\n",
            "239 Train_loss = 0.13303830186889043     Test_loss = 0.17187965281770143\n",
            "\n",
            "Accuracy : 0.9525\n",
            "240 Train_loss = 0.13296561795128228     Test_loss = 0.17182358254607777\n",
            "\n",
            "Accuracy : 0.9525\n",
            "241 Train_loss = 0.13289297577508494     Test_loss = 0.1717668102639579\n",
            "\n",
            "Accuracy : 0.9525\n",
            "242 Train_loss = 0.13282039148610258     Test_loss = 0.17171054325077167\n",
            "\n",
            "Accuracy : 0.9525\n",
            "243 Train_loss = 0.13274786790681103     Test_loss = 0.17165412895362614\n",
            "\n",
            "Accuracy : 0.9525\n",
            "244 Train_loss = 0.13267539240690462     Test_loss = 0.17159725488524136\n",
            "\n",
            "Accuracy : 0.9525\n",
            "245 Train_loss = 0.1326029442422549     Test_loss = 0.17154078209425153\n",
            "\n",
            "Accuracy : 0.9525\n",
            "246 Train_loss = 0.13253054904871248     Test_loss = 0.1714849892135196\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "247 Train_loss = 0.13245816672363256     Test_loss = 0.17142894667641242\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "248 Train_loss = 0.13238584499017395     Test_loss = 0.1713722422185288\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "249 Train_loss = 0.13231358540197985     Test_loss = 0.17131522879863217\n",
            "\n",
            "Accuracy : 0.9522619047619048\n",
            "250 Train_loss = 0.13224139570951518     Test_loss = 0.17125886555468653\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "251 Train_loss = 0.13216927296721923     Test_loss = 0.17120187037627072\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "252 Train_loss = 0.13209724710843498     Test_loss = 0.17114582382880295\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "253 Train_loss = 0.13202528531390564     Test_loss = 0.17108911910481703\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "254 Train_loss = 0.13195335638474473     Test_loss = 0.17103284175359082\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "255 Train_loss = 0.1318814745640274     Test_loss = 0.17097651844797224\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "256 Train_loss = 0.1318096614641006     Test_loss = 0.17092010933582621\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "257 Train_loss = 0.1317379348879878     Test_loss = 0.17086396201320925\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "258 Train_loss = 0.13166624316591166     Test_loss = 0.17080795640449334\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "259 Train_loss = 0.1315945984050188     Test_loss = 0.1707518629785276\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "260 Train_loss = 0.1315229680835187     Test_loss = 0.17069602035730513\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "261 Train_loss = 0.13145138551225635     Test_loss = 0.1706404974927638\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "262 Train_loss = 0.13137986758629494     Test_loss = 0.17058441088989446\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "263 Train_loss = 0.1313084123037067     Test_loss = 0.17052908091459956\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "264 Train_loss = 0.13123705176322786     Test_loss = 0.17047299579743516\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "265 Train_loss = 0.1311657576643804     Test_loss = 0.1704175172351007\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "266 Train_loss = 0.13109452141399047     Test_loss = 0.17036216190686793\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "267 Train_loss = 0.13102335072890378     Test_loss = 0.17030623169745404\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "268 Train_loss = 0.13095225274166006     Test_loss = 0.17025097802380273\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "269 Train_loss = 0.13088116122192317     Test_loss = 0.17019640156298324\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "270 Train_loss = 0.1308100932818893     Test_loss = 0.17014016447448896\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "271 Train_loss = 0.13073908626290268     Test_loss = 0.17008535569993305\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "272 Train_loss = 0.13066814062242288     Test_loss = 0.17002960315231683\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "273 Train_loss = 0.13059727836854823     Test_loss = 0.16997447193852683\n",
            "\n",
            "Accuracy : 0.9523809523809523\n",
            "274 Train_loss = 0.13052648492734603     Test_loss = 0.16991908370536138\n",
            "\n",
            "Accuracy : 0.9525\n",
            "275 Train_loss = 0.1304557527177119     Test_loss = 0.16986431556702844\n",
            "\n",
            "Accuracy : 0.9525\n",
            "276 Train_loss = 0.13038509183790828     Test_loss = 0.16980940951954776\n",
            "\n",
            "Accuracy : 0.9525\n",
            "277 Train_loss = 0.13031446033234487     Test_loss = 0.16975399019240994\n",
            "\n",
            "Accuracy : 0.9525\n",
            "278 Train_loss = 0.1302438565980248     Test_loss = 0.16969970843205978\n",
            "\n",
            "Accuracy : 0.9525\n",
            "279 Train_loss = 0.1301733205250641     Test_loss = 0.1696436922983303\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "280 Train_loss = 0.1301028255855061     Test_loss = 0.1695896042891844\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "281 Train_loss = 0.1300324160270706     Test_loss = 0.16953372978408962\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "282 Train_loss = 0.12996210373983139     Test_loss = 0.16947886132274884\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "283 Train_loss = 0.12989184765228448     Test_loss = 0.16942444594448142\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "284 Train_loss = 0.12982162650303303     Test_loss = 0.16936980905576582\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "285 Train_loss = 0.12975145005105154     Test_loss = 0.16931553994087128\n",
            "\n",
            "Accuracy : 0.9526190476190476\n",
            "286 Train_loss = 0.12968126759674248     Test_loss = 0.1692614084819035\n",
            "\n",
            "Accuracy : 0.9527380952380953\n",
            "287 Train_loss = 0.12961114907205284     Test_loss = 0.16920678677032433\n",
            "\n",
            "Accuracy : 0.9529761904761904\n",
            "288 Train_loss = 0.12954108500791267     Test_loss = 0.16915241551521426\n",
            "\n",
            "Accuracy : 0.9529761904761904\n",
            "289 Train_loss = 0.12947106619154441     Test_loss = 0.16909843183890702\n",
            "\n",
            "Accuracy : 0.9529761904761904\n",
            "290 Train_loss = 0.12940108226797464     Test_loss = 0.16904382772515386\n",
            "\n",
            "Accuracy : 0.9529761904761904\n",
            "291 Train_loss = 0.1293311592804758     Test_loss = 0.16898946411692098\n",
            "\n",
            "Accuracy : 0.9529761904761904\n",
            "292 Train_loss = 0.12926131413892808     Test_loss = 0.1689350541856983\n",
            "\n",
            "Accuracy : 0.9529761904761904\n",
            "293 Train_loss = 0.12919150493433348     Test_loss = 0.16888101754660428\n",
            "\n",
            "Accuracy : 0.9530952380952381\n",
            "294 Train_loss = 0.129121738710706     Test_loss = 0.1688270653470667\n",
            "\n",
            "Accuracy : 0.9530952380952381\n",
            "295 Train_loss = 0.12905204508783033     Test_loss = 0.16877258288931876\n",
            "\n",
            "Accuracy : 0.9530952380952381\n",
            "296 Train_loss = 0.12898243188757635     Test_loss = 0.16871817269794895\n",
            "\n",
            "Accuracy : 0.9530952380952381\n",
            "297 Train_loss = 0.1289129016889096     Test_loss = 0.16866434351108636\n",
            "\n",
            "Accuracy : 0.9530952380952381\n",
            "298 Train_loss = 0.1288434590807311     Test_loss = 0.16861062303248917\n",
            "\n",
            "Accuracy : 0.9530952380952381\n",
            "299 Train_loss = 0.1287740560467073     Test_loss = 0.16855716088341252\n",
            "\n",
            "Accuracy : 0.9532142857142857\n",
            "300 Train_loss = 0.12870468056551518     Test_loss = 0.1685030665086\n",
            "\n",
            "Accuracy : 0.9532142857142857\n",
            "301 Train_loss = 0.12863536444753923     Test_loss = 0.16844922545266164\n",
            "\n",
            "Accuracy : 0.9532142857142857\n",
            "302 Train_loss = 0.12856610489510276     Test_loss = 0.16839552020759804\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "303 Train_loss = 0.12849688928845943     Test_loss = 0.1683415141620007\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "304 Train_loss = 0.12842772570968986     Test_loss = 0.16828793736723746\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "305 Train_loss = 0.12835864110060152     Test_loss = 0.16823362438808537\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "306 Train_loss = 0.12828956979423153     Test_loss = 0.16818015641645417\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "307 Train_loss = 0.12822049746360883     Test_loss = 0.16812685531910992\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "308 Train_loss = 0.12815149745254292     Test_loss = 0.1680722254765731\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "309 Train_loss = 0.12808256257627587     Test_loss = 0.16801964168795144\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "310 Train_loss = 0.12801369342137792     Test_loss = 0.16796592299084576\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "311 Train_loss = 0.1279448798568463     Test_loss = 0.16791285714760637\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "312 Train_loss = 0.12787610918096895     Test_loss = 0.16785974719698407\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "313 Train_loss = 0.12780735313655817     Test_loss = 0.1678069804497344\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "314 Train_loss = 0.12773866903868217     Test_loss = 0.1677539072573869\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "315 Train_loss = 0.12767005813025503     Test_loss = 0.1677011984284795\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "316 Train_loss = 0.1276015206705053     Test_loss = 0.16764785692126347\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "317 Train_loss = 0.12753300970773027     Test_loss = 0.16759518891430486\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "318 Train_loss = 0.12746451784676008     Test_loss = 0.16754273330684055\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "319 Train_loss = 0.12739608541517855     Test_loss = 0.1674890254638848\n",
            "\n",
            "Accuracy : 0.9533333333333334\n",
            "320 Train_loss = 0.12732771076804789     Test_loss = 0.1674365509125913\n",
            "\n",
            "Accuracy : 0.9534523809523809\n",
            "321 Train_loss = 0.12725934932300265     Test_loss = 0.16738423265099966\n",
            "\n",
            "Accuracy : 0.9535714285714285\n",
            "322 Train_loss = 0.1271910772908534     Test_loss = 0.16733179653000313\n",
            "\n",
            "Accuracy : 0.9535714285714285\n",
            "323 Train_loss = 0.12712286091355118     Test_loss = 0.1672792388991689\n",
            "\n",
            "Accuracy : 0.9535714285714285\n",
            "324 Train_loss = 0.12705475410256162     Test_loss = 0.1672266743416375\n",
            "\n",
            "Accuracy : 0.9535714285714285\n",
            "325 Train_loss = 0.1269867152633838     Test_loss = 0.16717437414515282\n",
            "\n",
            "Accuracy : 0.9535714285714285\n",
            "326 Train_loss = 0.12691870628487184     Test_loss = 0.16712192652700347\n",
            "\n",
            "Accuracy : 0.9535714285714285\n",
            "327 Train_loss = 0.12685078704902938     Test_loss = 0.16706977402044276\n",
            "\n",
            "Accuracy : 0.9536904761904762\n",
            "328 Train_loss = 0.12678293305430827     Test_loss = 0.16701752180634213\n",
            "\n",
            "Accuracy : 0.9536904761904762\n",
            "329 Train_loss = 0.12671514638485454     Test_loss = 0.166964929557779\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "330 Train_loss = 0.12664739225210292     Test_loss = 0.16691308460835982\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "331 Train_loss = 0.1265796569994801     Test_loss = 0.1668609468570281\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "332 Train_loss = 0.12651197845674908     Test_loss = 0.1668093154941562\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "333 Train_loss = 0.12644433787776074     Test_loss = 0.16675664519106115\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "334 Train_loss = 0.12637675257254555     Test_loss = 0.16670453410044717\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "335 Train_loss = 0.12630920601326906     Test_loss = 0.16665352438189807\n",
            "\n",
            "Accuracy : 0.9539285714285715\n",
            "336 Train_loss = 0.12624172124751434     Test_loss = 0.16660097099184873\n",
            "\n",
            "Accuracy : 0.9538095238095238\n",
            "337 Train_loss = 0.12617427165600636     Test_loss = 0.1665497414078077\n",
            "\n",
            "Accuracy : 0.9539285714285715\n",
            "338 Train_loss = 0.1261068794541428     Test_loss = 0.16649686754118315\n",
            "\n",
            "Accuracy : 0.9539285714285715\n",
            "339 Train_loss = 0.1260395392613742     Test_loss = 0.1664457926642614\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "340 Train_loss = 0.12597223416581932     Test_loss = 0.1663930527804237\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "341 Train_loss = 0.125904987215712     Test_loss = 0.16634183689165088\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "342 Train_loss = 0.1258378143060506     Test_loss = 0.16628914090483018\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "343 Train_loss = 0.12577069356229156     Test_loss = 0.1662376216923038\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "344 Train_loss = 0.12570356575641553     Test_loss = 0.16618633381259126\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "345 Train_loss = 0.12563649521277215     Test_loss = 0.1661346284953044\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "346 Train_loss = 0.12556946778229616     Test_loss = 0.16608322108201587\n",
            "\n",
            "Accuracy : 0.954047619047619\n",
            "347 Train_loss = 0.12550250734172308     Test_loss = 0.16603161788073945\n",
            "\n",
            "Accuracy : 0.9541666666666667\n",
            "348 Train_loss = 0.12543557083352436     Test_loss = 0.16598053406103194\n",
            "\n",
            "Accuracy : 0.9541666666666667\n",
            "349 Train_loss = 0.12536868271555235     Test_loss = 0.16592852595407712\n",
            "\n",
            "Accuracy : 0.9542857142857143\n",
            "350 Train_loss = 0.12530184204987938     Test_loss = 0.1658783139643109\n",
            "\n",
            "Accuracy : 0.9542857142857143\n",
            "351 Train_loss = 0.12523504689145742     Test_loss = 0.16582689240494647\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "352 Train_loss = 0.12516830231818454     Test_loss = 0.16577592959559487\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "353 Train_loss = 0.12510163758776613     Test_loss = 0.16572512759775826\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "354 Train_loss = 0.12503504415370295     Test_loss = 0.16567508929507668\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "355 Train_loss = 0.12496849248090573     Test_loss = 0.16562381861632103\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "356 Train_loss = 0.12490193773223818     Test_loss = 0.16557343616570355\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "357 Train_loss = 0.12483544791339352     Test_loss = 0.16552245519336123\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "358 Train_loss = 0.12476900416580466     Test_loss = 0.16547178375337407\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "359 Train_loss = 0.12470255716873131     Test_loss = 0.16542134261984992\n",
            "\n",
            "Accuracy : 0.9544047619047619\n",
            "360 Train_loss = 0.12463616111676666     Test_loss = 0.1653709217259813\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "361 Train_loss = 0.12456978842033975     Test_loss = 0.1653203330558493\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "362 Train_loss = 0.12450345870805297     Test_loss = 0.16527027190363475\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "363 Train_loss = 0.12443720160247303     Test_loss = 0.1652197079418131\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "364 Train_loss = 0.12437097304899077     Test_loss = 0.1651696616002967\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "365 Train_loss = 0.12430482499887444     Test_loss = 0.1651199776611914\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "366 Train_loss = 0.1242387288073088     Test_loss = 0.16506974483216888\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "367 Train_loss = 0.12417269168331188     Test_loss = 0.16501931844556708\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "368 Train_loss = 0.12410672684188526     Test_loss = 0.16496992303513944\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "369 Train_loss = 0.12404084841123333     Test_loss = 0.16491969697234538\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "370 Train_loss = 0.12397505316942914     Test_loss = 0.16486956446076942\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "371 Train_loss = 0.12390930406308888     Test_loss = 0.16481946856383908\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "372 Train_loss = 0.12384361381858593     Test_loss = 0.1647697851856621\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "373 Train_loss = 0.12377799347081918     Test_loss = 0.1647197683164362\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "374 Train_loss = 0.12371242856491092     Test_loss = 0.16466949194328828\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "375 Train_loss = 0.12364694022667774     Test_loss = 0.16462032986310773\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "376 Train_loss = 0.12358149514345615     Test_loss = 0.1645698865665052\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "377 Train_loss = 0.12351611931681383     Test_loss = 0.16452000042778592\n",
            "\n",
            "Accuracy : 0.9545238095238096\n",
            "378 Train_loss = 0.1234508168312462     Test_loss = 0.16447098656716816\n",
            "\n",
            "Accuracy : 0.9545238095238096\n",
            "379 Train_loss = 0.12338554576961298     Test_loss = 0.16442069085372255\n",
            "\n",
            "Accuracy : 0.9545238095238096\n",
            "380 Train_loss = 0.12332030860725013     Test_loss = 0.16437160444379045\n",
            "\n",
            "Accuracy : 0.9545238095238096\n",
            "381 Train_loss = 0.12325513502897092     Test_loss = 0.16432090618580378\n",
            "\n",
            "Accuracy : 0.9545238095238096\n",
            "382 Train_loss = 0.12319002568516015     Test_loss = 0.1642718138458546\n",
            "\n",
            "Accuracy : 0.9545238095238096\n",
            "383 Train_loss = 0.12312496458478019     Test_loss = 0.1642221474347927\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "384 Train_loss = 0.12305996154609256     Test_loss = 0.16417214024534535\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "385 Train_loss = 0.1229949845095672     Test_loss = 0.16412267947617792\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "386 Train_loss = 0.12293007786086982     Test_loss = 0.16407249805778115\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "387 Train_loss = 0.12286523524199086     Test_loss = 0.16402325347895907\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "388 Train_loss = 0.1228004724512222     Test_loss = 0.16397342154248024\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "389 Train_loss = 0.12273577114220595     Test_loss = 0.16392405672077573\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "390 Train_loss = 0.122671136448743     Test_loss = 0.16387466737065104\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "391 Train_loss = 0.12260654831432814     Test_loss = 0.1638247064141398\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "392 Train_loss = 0.12254201082761126     Test_loss = 0.1637755658715332\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "393 Train_loss = 0.12247752231598732     Test_loss = 0.1637258221351925\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "394 Train_loss = 0.12241312803915867     Test_loss = 0.1636769918888896\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "395 Train_loss = 0.12234877506792721     Test_loss = 0.16362770263579263\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "396 Train_loss = 0.12228443781538864     Test_loss = 0.1635793232811248\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "397 Train_loss = 0.12222016516347664     Test_loss = 0.1635303600483215\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "398 Train_loss = 0.12215593805617513     Test_loss = 0.16348079622480272\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "399 Train_loss = 0.12209179604028929     Test_loss = 0.16343258465701269\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "400 Train_loss = 0.12202771298323745     Test_loss = 0.16338383539871001\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "401 Train_loss = 0.12196367122146796     Test_loss = 0.16333514259981025\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "402 Train_loss = 0.12189967230024144     Test_loss = 0.16328595291693992\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "403 Train_loss = 0.12183571411890143     Test_loss = 0.16323707705921645\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "404 Train_loss = 0.12177179925583191     Test_loss = 0.16318856869154913\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "405 Train_loss = 0.12170790541590489     Test_loss = 0.16313901610110676\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "406 Train_loss = 0.12164406287674184     Test_loss = 0.16309002940476602\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "407 Train_loss = 0.12158025272331832     Test_loss = 0.16304174067642413\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "408 Train_loss = 0.12151648932764145     Test_loss = 0.16299343451001355\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "409 Train_loss = 0.12145274320831236     Test_loss = 0.16294494067549434\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "410 Train_loss = 0.12138899226875804     Test_loss = 0.1628954722766239\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "411 Train_loss = 0.12132525685758308     Test_loss = 0.16284751337637937\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "412 Train_loss = 0.12126153822662541     Test_loss = 0.16279832377988682\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "413 Train_loss = 0.12119786086390473     Test_loss = 0.1627494296901456\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "414 Train_loss = 0.12113422432883067     Test_loss = 0.16270099328995363\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "415 Train_loss = 0.12107062719122726     Test_loss = 0.16265195563756937\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "416 Train_loss = 0.12100709331576338     Test_loss = 0.16260380753948825\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "417 Train_loss = 0.12094361063810176     Test_loss = 0.16255450526621198\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "418 Train_loss = 0.12088018830794559     Test_loss = 0.16250684027199191\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "419 Train_loss = 0.12081684266340842     Test_loss = 0.16245725203443254\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "420 Train_loss = 0.12075357802109704     Test_loss = 0.16241015656330338\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "421 Train_loss = 0.12069035407915671     Test_loss = 0.16236144138380457\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "422 Train_loss = 0.12062718398832378     Test_loss = 0.16231317360995098\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "423 Train_loss = 0.12056406548360571     Test_loss = 0.1622652205060499\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "424 Train_loss = 0.12050102358581394     Test_loss = 0.16221724989501377\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "425 Train_loss = 0.12043801852191943     Test_loss = 0.16216830934082738\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "426 Train_loss = 0.12037503543781983     Test_loss = 0.16212076207190135\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "427 Train_loss = 0.1203120958185463     Test_loss = 0.1620723320570424\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "428 Train_loss = 0.12024919405507345     Test_loss = 0.16202479080145638\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "429 Train_loss = 0.1201863505571911     Test_loss = 0.16197580850939558\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "430 Train_loss = 0.12012356896111237     Test_loss = 0.1619285654217679\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "431 Train_loss = 0.12006082551226191     Test_loss = 0.16188015868358052\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "432 Train_loss = 0.11999813287196537     Test_loss = 0.16183225792544273\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "433 Train_loss = 0.11993548009713918     Test_loss = 0.16178437052661732\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "434 Train_loss = 0.11987288966476953     Test_loss = 0.1617364511960722\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "435 Train_loss = 0.1198103297085996     Test_loss = 0.16168900982606982\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "436 Train_loss = 0.11974778368729565     Test_loss = 0.16164146282407255\n",
            "\n",
            "Accuracy : 0.9546428571428571\n",
            "437 Train_loss = 0.11968529005855329     Test_loss = 0.1615935400555487\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "438 Train_loss = 0.11962283955233202     Test_loss = 0.16154581200951315\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "439 Train_loss = 0.1195604290809018     Test_loss = 0.1614981541658886\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "440 Train_loss = 0.11949809619519058     Test_loss = 0.16145086079310791\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "441 Train_loss = 0.11943580580608945     Test_loss = 0.16140262900190216\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "442 Train_loss = 0.11937354340170822     Test_loss = 0.16135572443523544\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "443 Train_loss = 0.11931133459074143     Test_loss = 0.16130836364359608\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "444 Train_loss = 0.11924919411852018     Test_loss = 0.16126072249854712\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "445 Train_loss = 0.11918711470749313     Test_loss = 0.16121345916041058\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "446 Train_loss = 0.11912507812590768     Test_loss = 0.1611660500721726\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "447 Train_loss = 0.11906306309801777     Test_loss = 0.1611192259124259\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "448 Train_loss = 0.11900113114257492     Test_loss = 0.16107117395109574\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "449 Train_loss = 0.11893923228897298     Test_loss = 0.16102475749202974\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "450 Train_loss = 0.11887737158396404     Test_loss = 0.16097691749021345\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "451 Train_loss = 0.11881553453694912     Test_loss = 0.16093008518975352\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "452 Train_loss = 0.11875374106471875     Test_loss = 0.16088261789974417\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "453 Train_loss = 0.1186919571665134     Test_loss = 0.16083515417978028\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "454 Train_loss = 0.1186301899628981     Test_loss = 0.16078816744198973\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "455 Train_loss = 0.11856848150283841     Test_loss = 0.16074093863342975\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "456 Train_loss = 0.11850680391372645     Test_loss = 0.16069457346985688\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "457 Train_loss = 0.11844517899249692     Test_loss = 0.1606476153407067\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "458 Train_loss = 0.11838358187180681     Test_loss = 0.160599671081528\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "459 Train_loss = 0.11832201367615452     Test_loss = 0.16055300993041677\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "460 Train_loss = 0.11826048424036659     Test_loss = 0.16050615966468879\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "461 Train_loss = 0.11819900971539612     Test_loss = 0.16045894103512345\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "462 Train_loss = 0.11813758571032824     Test_loss = 0.16041176613568045\n",
            "\n",
            "Accuracy : 0.9547619047619048\n",
            "463 Train_loss = 0.11807622750614301     Test_loss = 0.16036454539799871\n",
            "\n",
            "Accuracy : 0.9548809523809524\n",
            "464 Train_loss = 0.11801493155443274     Test_loss = 0.16031863223571455\n",
            "\n",
            "Accuracy : 0.9548809523809524\n",
            "465 Train_loss = 0.11795369888991464     Test_loss = 0.1602711540311441\n",
            "\n",
            "Accuracy : 0.9548809523809524\n",
            "466 Train_loss = 0.11789246822208022     Test_loss = 0.16022485726444474\n",
            "\n",
            "Accuracy : 0.9548809523809524\n",
            "467 Train_loss = 0.11783128281345208     Test_loss = 0.16017761807408798\n",
            "\n",
            "Accuracy : 0.9548809523809524\n",
            "468 Train_loss = 0.11777018291354456     Test_loss = 0.16013092311630409\n",
            "\n",
            "Accuracy : 0.955\n",
            "469 Train_loss = 0.11770914785462011     Test_loss = 0.1600842509543728\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "470 Train_loss = 0.1176481827837089     Test_loss = 0.16003801879785778\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "471 Train_loss = 0.11758728405738793     Test_loss = 0.15999196414305691\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "472 Train_loss = 0.11752643289815042     Test_loss = 0.15994542900208286\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "473 Train_loss = 0.11746559797432067     Test_loss = 0.15989907182520946\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "474 Train_loss = 0.11740481042991033     Test_loss = 0.15985344917292713\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "475 Train_loss = 0.11734406800482229     Test_loss = 0.15980697131330157\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "476 Train_loss = 0.11728337968382596     Test_loss = 0.15976020549262113\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "477 Train_loss = 0.11722271370907499     Test_loss = 0.15971402507538032\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "478 Train_loss = 0.11716211011432018     Test_loss = 0.1596682707047771\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "479 Train_loss = 0.1171015266534345     Test_loss = 0.15962143949271107\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "480 Train_loss = 0.1170409866231869     Test_loss = 0.15957538397942495\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "481 Train_loss = 0.11698051495573544     Test_loss = 0.15952973149463046\n",
            "\n",
            "Accuracy : 0.9551190476190476\n",
            "482 Train_loss = 0.11692012256607939     Test_loss = 0.15948424793255744\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "483 Train_loss = 0.11685975221683353     Test_loss = 0.1594379983008625\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "484 Train_loss = 0.11679944592996998     Test_loss = 0.15939307913902867\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "485 Train_loss = 0.11673917066485537     Test_loss = 0.15934661396955493\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "486 Train_loss = 0.11667897415759747     Test_loss = 0.1593019579593573\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "487 Train_loss = 0.1166188614124757     Test_loss = 0.15925587719998008\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "488 Train_loss = 0.11655877749653425     Test_loss = 0.1592105941176501\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "489 Train_loss = 0.11649871920753653     Test_loss = 0.1591649466388953\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "490 Train_loss = 0.11643870895268674     Test_loss = 0.15911942659957737\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "491 Train_loss = 0.11637872393864797     Test_loss = 0.15907359231568735\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "492 Train_loss = 0.11631875220988842     Test_loss = 0.15902809032570128\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "493 Train_loss = 0.11625883554277679     Test_loss = 0.1589831304185772\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "494 Train_loss = 0.11619898584262929     Test_loss = 0.15893738668974294\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "495 Train_loss = 0.1161391780838505     Test_loss = 0.15889278479870952\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "496 Train_loss = 0.1160794190377498     Test_loss = 0.1588471913345954\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "497 Train_loss = 0.11601972440620442     Test_loss = 0.15880225949045967\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "498 Train_loss = 0.11596009831968165     Test_loss = 0.15875756389036863\n",
            "\n",
            "Accuracy : 0.9553571428571429\n",
            "499 Train_loss = 0.11590053495046532     Test_loss = 0.15871157181414827\n",
            "\n",
            "Accuracy : 0.9554761904761905\n",
            "500 Train_loss = 0.1158410426399794     Test_loss = 0.1586671681080114\n",
            "\n",
            "Accuracy : 0.9554761904761905\n",
            "501 Train_loss = 0.11578160241647195     Test_loss = 0.15862208902226266\n",
            "\n",
            "Accuracy : 0.9554761904761905\n",
            "502 Train_loss = 0.11572220883433185     Test_loss = 0.1585774382732634\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "503 Train_loss = 0.11566283997811475     Test_loss = 0.15853209377908734\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "504 Train_loss = 0.11560353748498957     Test_loss = 0.1584885709571166\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "505 Train_loss = 0.11554427969031668     Test_loss = 0.1584441459227153\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "506 Train_loss = 0.11548506878931343     Test_loss = 0.15839860730028177\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "507 Train_loss = 0.115425845281241     Test_loss = 0.15835387967646306\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "508 Train_loss = 0.11536663511506118     Test_loss = 0.1583092762608072\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "509 Train_loss = 0.11530745534234528     Test_loss = 0.1582640416981114\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "510 Train_loss = 0.11524832823715284     Test_loss = 0.15821880305228442\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "511 Train_loss = 0.11518923444220328     Test_loss = 0.15817383319394318\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "512 Train_loss = 0.11513019268091713     Test_loss = 0.1581292342791655\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "513 Train_loss = 0.11507122881306318     Test_loss = 0.1580851108736415\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "514 Train_loss = 0.11501230404746976     Test_loss = 0.15804011703219994\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "515 Train_loss = 0.11495344248049487     Test_loss = 0.15799675279018047\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "516 Train_loss = 0.11489460999270217     Test_loss = 0.15795190921433896\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "517 Train_loss = 0.1148358007143943     Test_loss = 0.15790821084806123\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "518 Train_loss = 0.11477701898999201     Test_loss = 0.15786287320487513\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "519 Train_loss = 0.11471825422093482     Test_loss = 0.15781840309797227\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "520 Train_loss = 0.11465954458521466     Test_loss = 0.15777364899418633\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "521 Train_loss = 0.11460090319883319     Test_loss = 0.1577301254084938\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "522 Train_loss = 0.11454228580914642     Test_loss = 0.15768515321533333\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "523 Train_loss = 0.1144837498459879     Test_loss = 0.15764075758678708\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "524 Train_loss = 0.11442526828479717     Test_loss = 0.1575969837639162\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "525 Train_loss = 0.11436681101004446     Test_loss = 0.15755192793723538\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "526 Train_loss = 0.11430841615474208     Test_loss = 0.1575080581911262\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "527 Train_loss = 0.1142500854657727     Test_loss = 0.1574632331937839\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "528 Train_loss = 0.11419181887248818     Test_loss = 0.15741918072492175\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "529 Train_loss = 0.11413357922713276     Test_loss = 0.15737543103820997\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "530 Train_loss = 0.11407536414653624     Test_loss = 0.15733066943689827\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "531 Train_loss = 0.11401716298178215     Test_loss = 0.157286054546249\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "532 Train_loss = 0.11395900412258478     Test_loss = 0.15724196840715898\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "533 Train_loss = 0.11390087404631913     Test_loss = 0.15719753038703974\n",
            "\n",
            "Accuracy : 0.955595238095238\n",
            "534 Train_loss = 0.11384281171830131     Test_loss = 0.15715395252269776\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "535 Train_loss = 0.11378479142563254     Test_loss = 0.15710933888330098\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "536 Train_loss = 0.11372684810709417     Test_loss = 0.15706529047206533\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "537 Train_loss = 0.11366898008823753     Test_loss = 0.15702150693828862\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "538 Train_loss = 0.11361116493357344     Test_loss = 0.15697786115835993\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "539 Train_loss = 0.11355340150092623     Test_loss = 0.15693417803952636\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "540 Train_loss = 0.11349570585613182     Test_loss = 0.15689036137790413\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "541 Train_loss = 0.1134380791809838     Test_loss = 0.15684678724518417\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "542 Train_loss = 0.11338050588172997     Test_loss = 0.15680314803896123\n",
            "\n",
            "Accuracy : 0.9557142857142857\n",
            "543 Train_loss = 0.11332299503553359     Test_loss = 0.15675940315071818\n",
            "\n",
            "Accuracy : 0.9558333333333333\n",
            "544 Train_loss = 0.11326553831875232     Test_loss = 0.15671576614046967\n",
            "\n",
            "Accuracy : 0.955952380952381\n",
            "545 Train_loss = 0.1132081433538891     Test_loss = 0.1566721718217896\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "546 Train_loss = 0.11315079237381062     Test_loss = 0.15662980737887933\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "547 Train_loss = 0.11309349969248732     Test_loss = 0.15658620782228858\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "548 Train_loss = 0.11303627580315836     Test_loss = 0.1565428331767733\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "549 Train_loss = 0.11297908933928727     Test_loss = 0.15649900144913212\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "550 Train_loss = 0.11292196604710936     Test_loss = 0.15645630382602496\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "551 Train_loss = 0.11286490213322127     Test_loss = 0.15641253914400638\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "552 Train_loss = 0.1128078693022861     Test_loss = 0.15636951102398997\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "553 Train_loss = 0.11275084861199369     Test_loss = 0.15632660021026665\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "554 Train_loss = 0.11269388398489516     Test_loss = 0.15628299958348368\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "555 Train_loss = 0.11263696668619562     Test_loss = 0.15624000011720882\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "556 Train_loss = 0.11258009150117176     Test_loss = 0.1561968822217997\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "557 Train_loss = 0.11252324101226541     Test_loss = 0.15615426414801428\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "558 Train_loss = 0.11246642442355952     Test_loss = 0.15611174619444712\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "559 Train_loss = 0.1124096397898665     Test_loss = 0.15606859083088095\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "560 Train_loss = 0.11235290937483815     Test_loss = 0.1560256269610828\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "561 Train_loss = 0.11229624010222417     Test_loss = 0.15598392364987185\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "562 Train_loss = 0.11223960469617032     Test_loss = 0.15594050236084395\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "563 Train_loss = 0.11218300571121267     Test_loss = 0.1558982959560372\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "564 Train_loss = 0.11212644392640299     Test_loss = 0.15585590042728376\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "565 Train_loss = 0.11206992837490468     Test_loss = 0.15581314226070866\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "566 Train_loss = 0.11201345622687657     Test_loss = 0.155770438210046\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "567 Train_loss = 0.1119570236882938     Test_loss = 0.1557286717336774\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "568 Train_loss = 0.1119006313643728     Test_loss = 0.15568602764189585\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "569 Train_loss = 0.11184429215395265     Test_loss = 0.15564291655082005\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "570 Train_loss = 0.1117880139668696     Test_loss = 0.15560143884955824\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "571 Train_loss = 0.11173179356465604     Test_loss = 0.15555809192895365\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "572 Train_loss = 0.11167562074988967     Test_loss = 0.15551591932607625\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "573 Train_loss = 0.11161949760092602     Test_loss = 0.15547352800241576\n",
            "\n",
            "Accuracy : 0.9560714285714286\n",
            "574 Train_loss = 0.11156341850007706     Test_loss = 0.15543163141242958\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "575 Train_loss = 0.11150737343469386     Test_loss = 0.15538934140688887\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "576 Train_loss = 0.11145137016990687     Test_loss = 0.1553467342964457\n",
            "\n",
            "Accuracy : 0.9561904761904761\n",
            "577 Train_loss = 0.1113954116317438     Test_loss = 0.1553041561838177\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "578 Train_loss = 0.11133948957300646     Test_loss = 0.15526236055577222\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "579 Train_loss = 0.11128359257076853     Test_loss = 0.15522029951697314\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "580 Train_loss = 0.1112277134301797     Test_loss = 0.15517900341019752\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "581 Train_loss = 0.11117185888650967     Test_loss = 0.15513665662220255\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "582 Train_loss = 0.1111160347888489     Test_loss = 0.15509407284863083\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "583 Train_loss = 0.11106024710422044     Test_loss = 0.1550517317644654\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "584 Train_loss = 0.11100449059056099     Test_loss = 0.1550098071715002\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "585 Train_loss = 0.11094879624001015     Test_loss = 0.15496847853815346\n",
            "\n",
            "Accuracy : 0.9563095238095238\n",
            "586 Train_loss = 0.11089314300945086     Test_loss = 0.15492535779866717\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "587 Train_loss = 0.11083753027318037     Test_loss = 0.1548833951550496\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "588 Train_loss = 0.11078195698979625     Test_loss = 0.15484195008383944\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "589 Train_loss = 0.11072642057251729     Test_loss = 0.15479976439992105\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "590 Train_loss = 0.11067088983338469     Test_loss = 0.15475737328242253\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "591 Train_loss = 0.11061542831399604     Test_loss = 0.1547157078049402\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "592 Train_loss = 0.11056002602665384     Test_loss = 0.15467397863832946\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "593 Train_loss = 0.1105046694841402     Test_loss = 0.15463233280219313\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "594 Train_loss = 0.11044933501928292     Test_loss = 0.15459029904431518\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "595 Train_loss = 0.11039403494697628     Test_loss = 0.1545487628323765\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "596 Train_loss = 0.11033877562975716     Test_loss = 0.15450636002023752\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "597 Train_loss = 0.11028358179986883     Test_loss = 0.15446471097705827\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "598 Train_loss = 0.1102284264012755     Test_loss = 0.15442303905939816\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "599 Train_loss = 0.11017329926149069     Test_loss = 0.15438126988897602\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "600 Train_loss = 0.1101182227126645     Test_loss = 0.15433935863197573\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "601 Train_loss = 0.11006316831284049     Test_loss = 0.15429729647110219\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "602 Train_loss = 0.11000814942778972     Test_loss = 0.1542556002137152\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "603 Train_loss = 0.10995317451367125     Test_loss = 0.1542141232497092\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "604 Train_loss = 0.10989825327115818     Test_loss = 0.15417247083849347\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "605 Train_loss = 0.10984335206021927     Test_loss = 0.1541305492653552\n",
            "\n",
            "Accuracy : 0.9564285714285714\n",
            "606 Train_loss = 0.10978851017906369     Test_loss = 0.15408885142964832\n",
            "\n",
            "Accuracy : 0.9565476190476191\n",
            "607 Train_loss = 0.10973370366832924     Test_loss = 0.15404733157294098\n",
            "\n",
            "Accuracy : 0.9565476190476191\n",
            "608 Train_loss = 0.10967891840258197     Test_loss = 0.15400489984333623\n",
            "\n",
            "Accuracy : 0.9565476190476191\n",
            "609 Train_loss = 0.10962419919131229     Test_loss = 0.15396367192791446\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "610 Train_loss = 0.10956951903831652     Test_loss = 0.15392099136860615\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "611 Train_loss = 0.10951488938816215     Test_loss = 0.1538796110977613\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "612 Train_loss = 0.10946030495768777     Test_loss = 0.1538383339883929\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "613 Train_loss = 0.10940576242508823     Test_loss = 0.15379574946587554\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "614 Train_loss = 0.10935125489923538     Test_loss = 0.15375434603005708\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "615 Train_loss = 0.10929679577180958     Test_loss = 0.1537135156112814\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "616 Train_loss = 0.10924238131618416     Test_loss = 0.15367164189603405\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "617 Train_loss = 0.10918802857883736     Test_loss = 0.15363015415952075\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "618 Train_loss = 0.10913371926505212     Test_loss = 0.15358892856102033\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "619 Train_loss = 0.10907945156763507     Test_loss = 0.15354820960688617\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "620 Train_loss = 0.1090252219487396     Test_loss = 0.15350662840224202\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "621 Train_loss = 0.10897104424380735     Test_loss = 0.15346617361925693\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "622 Train_loss = 0.10891689341186343     Test_loss = 0.15342489208404364\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "623 Train_loss = 0.10886277336463808     Test_loss = 0.15338363512591782\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "624 Train_loss = 0.10880869916667532     Test_loss = 0.1533432783313126\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "625 Train_loss = 0.1087546639043276     Test_loss = 0.1533030022691781\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "626 Train_loss = 0.10870067942618857     Test_loss = 0.153261441564528\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "627 Train_loss = 0.10864670941010772     Test_loss = 0.1532211468550318\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "628 Train_loss = 0.10859278351342784     Test_loss = 0.15318066341719902\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "629 Train_loss = 0.10853888171591104     Test_loss = 0.15313977960389769\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "630 Train_loss = 0.10848500762481303     Test_loss = 0.15309904868278917\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "631 Train_loss = 0.10843119480592914     Test_loss = 0.15305811540044073\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "632 Train_loss = 0.10837742400279411     Test_loss = 0.1530182232966685\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "633 Train_loss = 0.10832369018119116     Test_loss = 0.15297702258696397\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "634 Train_loss = 0.10826992680957875     Test_loss = 0.1529363742427567\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "635 Train_loss = 0.10821620277412347     Test_loss = 0.15289532666269232\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "636 Train_loss = 0.10816251532436234     Test_loss = 0.1528545752101061\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "637 Train_loss = 0.10810887600788688     Test_loss = 0.15281338774423295\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "638 Train_loss = 0.10805527481016651     Test_loss = 0.1527729454887614\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "639 Train_loss = 0.1080017196830538     Test_loss = 0.15273268105975732\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "640 Train_loss = 0.10794818901419245     Test_loss = 0.15269220880039425\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "641 Train_loss = 0.10789468904403195     Test_loss = 0.1526516396658024\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "642 Train_loss = 0.10784121076636752     Test_loss = 0.15261116625615279\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "643 Train_loss = 0.10778776351948419     Test_loss = 0.15257038989000868\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "644 Train_loss = 0.10773434016635985     Test_loss = 0.1525299330868468\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "645 Train_loss = 0.1076808918568841     Test_loss = 0.15249049693584035\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "646 Train_loss = 0.10762749529201869     Test_loss = 0.15245015991421637\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "647 Train_loss = 0.1075741249567781     Test_loss = 0.15241107277399757\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "648 Train_loss = 0.107520799353829     Test_loss = 0.15237081527264526\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "649 Train_loss = 0.10746751829555502     Test_loss = 0.152330796041226\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "650 Train_loss = 0.1074142688147197     Test_loss = 0.15229094928278247\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "651 Train_loss = 0.1073610830671822     Test_loss = 0.15225136303239592\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "652 Train_loss = 0.10730795257141297     Test_loss = 0.15221185050010178\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "653 Train_loss = 0.10725486096463195     Test_loss = 0.15217181438248548\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "654 Train_loss = 0.10720178950109098     Test_loss = 0.15213196879480653\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "655 Train_loss = 0.1071487327809873     Test_loss = 0.1520930460576205\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "656 Train_loss = 0.10709572574115842     Test_loss = 0.15205345021694353\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "657 Train_loss = 0.10704275855026847     Test_loss = 0.15201374454363298\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "658 Train_loss = 0.10698982574753013     Test_loss = 0.15197431679449297\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "659 Train_loss = 0.10693694079408245     Test_loss = 0.15193471776130182\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "660 Train_loss = 0.1068841039165489     Test_loss = 0.15189466005319474\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "661 Train_loss = 0.10683133472628112     Test_loss = 0.15185599738194547\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "662 Train_loss = 0.10677859296732704     Test_loss = 0.1518162797700253\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "663 Train_loss = 0.10672588083420652     Test_loss = 0.15177698116908253\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "664 Train_loss = 0.10667322228286116     Test_loss = 0.15173744417327129\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "665 Train_loss = 0.10662059208377271     Test_loss = 0.1516986193598996\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "666 Train_loss = 0.1065679751726354     Test_loss = 0.15165915696919327\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "667 Train_loss = 0.10651538383232774     Test_loss = 0.15162099713062532\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "668 Train_loss = 0.10646282512263945     Test_loss = 0.15158126460736723\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "669 Train_loss = 0.10641031771273572     Test_loss = 0.1515426080648902\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "670 Train_loss = 0.106357838752206     Test_loss = 0.15150371128644272\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "671 Train_loss = 0.10630540874014734     Test_loss = 0.15146478354939943\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "672 Train_loss = 0.10625302682989266     Test_loss = 0.15142585770336398\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "673 Train_loss = 0.10620066515481894     Test_loss = 0.151387183756162\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "674 Train_loss = 0.10614834378382504     Test_loss = 0.15134824241227302\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "675 Train_loss = 0.10609604918903842     Test_loss = 0.15130891429287333\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "676 Train_loss = 0.10604378384964971     Test_loss = 0.15127050420078875\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "677 Train_loss = 0.10599155371862805     Test_loss = 0.15123153109223803\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "678 Train_loss = 0.10593936489272256     Test_loss = 0.1511931510561045\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "679 Train_loss = 0.10588722166870435     Test_loss = 0.1511548360922439\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "680 Train_loss = 0.10583513457215461     Test_loss = 0.15111551908575657\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "681 Train_loss = 0.10578308877265029     Test_loss = 0.1510772810147919\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "682 Train_loss = 0.10573108739278034     Test_loss = 0.15103868237594484\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "683 Train_loss = 0.10567910141702129     Test_loss = 0.15100103278848823\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "684 Train_loss = 0.1056271519838706     Test_loss = 0.15096281979737908\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "685 Train_loss = 0.10557519810315896     Test_loss = 0.15092396735688937\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "686 Train_loss = 0.10552328945240247     Test_loss = 0.1508856915000379\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "687 Train_loss = 0.10547143640136429     Test_loss = 0.15084839794657393\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "688 Train_loss = 0.1054196255386572     Test_loss = 0.15080937671649333\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "689 Train_loss = 0.10536785546469139     Test_loss = 0.1507715244178187\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "690 Train_loss = 0.10531613271009103     Test_loss = 0.15073340645369152\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "691 Train_loss = 0.10526445140012368     Test_loss = 0.15069617178303804\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "692 Train_loss = 0.10521280826900403     Test_loss = 0.15065721402189497\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "693 Train_loss = 0.10516121623798007     Test_loss = 0.15061897517465858\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "694 Train_loss = 0.10510965683717939     Test_loss = 0.15058046759367666\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "695 Train_loss = 0.10505816799810246     Test_loss = 0.1505428529648794\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "696 Train_loss = 0.10500670432991949     Test_loss = 0.15050553740095113\n",
            "\n",
            "Accuracy : 0.9566666666666667\n",
            "697 Train_loss = 0.10495529635654344     Test_loss = 0.15046718795914343\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "698 Train_loss = 0.10490393260177563     Test_loss = 0.15042923372603326\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "699 Train_loss = 0.10485260339473565     Test_loss = 0.15039173941781184\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "700 Train_loss = 0.10480130934167485     Test_loss = 0.150354218414177\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "701 Train_loss = 0.10475003268155929     Test_loss = 0.15031598773221072\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "702 Train_loss = 0.10469881808520844     Test_loss = 0.15027856283118446\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "703 Train_loss = 0.10464764584389508     Test_loss = 0.15024149621644192\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "704 Train_loss = 0.10459649219621575     Test_loss = 0.1502033430043795\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "705 Train_loss = 0.10454536435006365     Test_loss = 0.15016638388081763\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "706 Train_loss = 0.10449428822822138     Test_loss = 0.15012809412045977\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "707 Train_loss = 0.10444325569122773     Test_loss = 0.15009145505682106\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "708 Train_loss = 0.10439226040453099     Test_loss = 0.15005395549664402\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "709 Train_loss = 0.10434135246830084     Test_loss = 0.15001675145827273\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "710 Train_loss = 0.10429048685158702     Test_loss = 0.14997858149435017\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "711 Train_loss = 0.10423967704152509     Test_loss = 0.14994229752264418\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "712 Train_loss = 0.10418891285502824     Test_loss = 0.14990503090675736\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "713 Train_loss = 0.1041382088804895     Test_loss = 0.14986881748855604\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "714 Train_loss = 0.1040875365722118     Test_loss = 0.1498301785582238\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "715 Train_loss = 0.10403690456079519     Test_loss = 0.1497935082954264\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "716 Train_loss = 0.10398633576248699     Test_loss = 0.14975644809823055\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "717 Train_loss = 0.10393580813484952     Test_loss = 0.1497199167211098\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "718 Train_loss = 0.10388532568580493     Test_loss = 0.1496819888484411\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "719 Train_loss = 0.10383489175966339     Test_loss = 0.14964589825159114\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "720 Train_loss = 0.10378452596623436     Test_loss = 0.1496075863690796\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "721 Train_loss = 0.10373420172628887     Test_loss = 0.14957192804175543\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "722 Train_loss = 0.10368391825021886     Test_loss = 0.14953442059403446\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "723 Train_loss = 0.10363366152140722     Test_loss = 0.14949728640307708\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "724 Train_loss = 0.10358341814840695     Test_loss = 0.14945996509577172\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "725 Train_loss = 0.10353319869419492     Test_loss = 0.14942400581942772\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "726 Train_loss = 0.10348301583074074     Test_loss = 0.149386294989198\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "727 Train_loss = 0.10343286485304717     Test_loss = 0.1493501919887423\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "728 Train_loss = 0.10338273367039018     Test_loss = 0.1493128958738273\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "729 Train_loss = 0.10333264780146606     Test_loss = 0.1492763811046855\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "730 Train_loss = 0.10328260578651145     Test_loss = 0.14923989269125187\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "731 Train_loss = 0.10323259883361388     Test_loss = 0.149202870676185\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "732 Train_loss = 0.10318262228353084     Test_loss = 0.14916606118970083\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "733 Train_loss = 0.10313268390052181     Test_loss = 0.14912965333154118\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "734 Train_loss = 0.10308279572027745     Test_loss = 0.14909299709640658\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "735 Train_loss = 0.10303296941412847     Test_loss = 0.14905715085111576\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "736 Train_loss = 0.10298315861659402     Test_loss = 0.14901898245710676\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "737 Train_loss = 0.10293339395525233     Test_loss = 0.1489832478675136\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "738 Train_loss = 0.10288363480144397     Test_loss = 0.14894634432300935\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "739 Train_loss = 0.1028339277714866     Test_loss = 0.1489099696091342\n",
            "\n",
            "Accuracy : 0.9567857142857142\n",
            "740 Train_loss = 0.10278428901534921     Test_loss = 0.14887339396264038\n",
            "\n",
            "Accuracy : 0.9569047619047619\n",
            "741 Train_loss = 0.10273467142526271     Test_loss = 0.14883716541286732\n",
            "\n",
            "Accuracy : 0.9570238095238095\n",
            "742 Train_loss = 0.10268511764277446     Test_loss = 0.14880113998582978\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "743 Train_loss = 0.10263556950019621     Test_loss = 0.14876473173722146\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "744 Train_loss = 0.10258604696938092     Test_loss = 0.1487294181678549\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "745 Train_loss = 0.10253656407381925     Test_loss = 0.1486919791329799\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "746 Train_loss = 0.10248711257861763     Test_loss = 0.14865644989424304\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "747 Train_loss = 0.10243767018908399     Test_loss = 0.14861957343895782\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "748 Train_loss = 0.10238828986195488     Test_loss = 0.1485842069767883\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "749 Train_loss = 0.10233892189671492     Test_loss = 0.14854636665063584\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "750 Train_loss = 0.10228960132365042     Test_loss = 0.14851124023103993\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "751 Train_loss = 0.10224027906581885     Test_loss = 0.1484746047682267\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "752 Train_loss = 0.102190995505184     Test_loss = 0.14843776926568417\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "753 Train_loss = 0.10214176065723543     Test_loss = 0.14840209973217286\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "754 Train_loss = 0.10209256350658397     Test_loss = 0.14836466259516248\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "755 Train_loss = 0.10204338505218136     Test_loss = 0.1483285661286547\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "756 Train_loss = 0.10199426034662203     Test_loss = 0.14829258962366204\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "757 Train_loss = 0.10194518925195005     Test_loss = 0.1482547883523534\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "758 Train_loss = 0.10189614938485705     Test_loss = 0.14822000398628424\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "759 Train_loss = 0.10184716576924754     Test_loss = 0.1481830748670928\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "760 Train_loss = 0.10179824396849008     Test_loss = 0.14814607509443947\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "761 Train_loss = 0.10174935612979331     Test_loss = 0.14811054806866167\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "762 Train_loss = 0.10170051790189939     Test_loss = 0.14807322187131988\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "763 Train_loss = 0.10165170993287412     Test_loss = 0.1480375962744061\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "764 Train_loss = 0.10160295361085082     Test_loss = 0.1480012982042669\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "765 Train_loss = 0.10155422968456981     Test_loss = 0.14796504174210026\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "766 Train_loss = 0.10150556632574496     Test_loss = 0.14792829615737968\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "767 Train_loss = 0.10145693274269867     Test_loss = 0.14789332574652655\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "768 Train_loss = 0.10140832378102395     Test_loss = 0.14785633878078658\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "769 Train_loss = 0.10135969877828556     Test_loss = 0.14782143977695741\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "770 Train_loss = 0.10131110813681185     Test_loss = 0.14778482437276186\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "771 Train_loss = 0.10126254115893342     Test_loss = 0.14774914849053317\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "772 Train_loss = 0.10121399071480512     Test_loss = 0.1477131057420502\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "773 Train_loss = 0.10116545324239959     Test_loss = 0.14767721990506485\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "774 Train_loss = 0.10111692688291242     Test_loss = 0.14764094177350814\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "775 Train_loss = 0.10106841313859807     Test_loss = 0.14760526603513138\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "776 Train_loss = 0.10101995385948252     Test_loss = 0.14756948172537585\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "777 Train_loss = 0.10097152529268193     Test_loss = 0.14753393247778415\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "778 Train_loss = 0.10092312492815833     Test_loss = 0.14749785267174292\n",
            "\n",
            "Accuracy : 0.9571428571428572\n",
            "779 Train_loss = 0.10087473550439921     Test_loss = 0.14746192545066353\n",
            "\n",
            "Accuracy : 0.9572619047619048\n",
            "780 Train_loss = 0.10082637326700827     Test_loss = 0.1474262870014332\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "781 Train_loss = 0.10077806671649579     Test_loss = 0.14739034448774133\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "782 Train_loss = 0.10072978808524166     Test_loss = 0.14735533743146914\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "783 Train_loss = 0.1006815479468113     Test_loss = 0.1473198214430385\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "784 Train_loss = 0.10063333641841421     Test_loss = 0.14728367602818004\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "785 Train_loss = 0.1005851759355182     Test_loss = 0.1472489860055847\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "786 Train_loss = 0.10053703557679848     Test_loss = 0.14721301209071733\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "787 Train_loss = 0.10048895470476728     Test_loss = 0.14717744059491664\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "788 Train_loss = 0.10044090021420854     Test_loss = 0.14714315639852377\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "789 Train_loss = 0.10039288827546684     Test_loss = 0.14710590539175744\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "790 Train_loss = 0.10034489921098778     Test_loss = 0.1470726178497136\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "791 Train_loss = 0.10029693963740123     Test_loss = 0.14703595112284026\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "792 Train_loss = 0.10024903369389221     Test_loss = 0.14700197948276886\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "793 Train_loss = 0.10020115307363273     Test_loss = 0.1469662381543907\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "794 Train_loss = 0.10015332124368814     Test_loss = 0.1469308520454071\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "795 Train_loss = 0.10010553621456995     Test_loss = 0.14689604124178693\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "796 Train_loss = 0.10005776220747933     Test_loss = 0.14686143788015438\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "797 Train_loss = 0.10001002214990207     Test_loss = 0.14682605180020758\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "798 Train_loss = 0.09996231264167497     Test_loss = 0.14679134156958143\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "799 Train_loss = 0.09991461184455937     Test_loss = 0.1467551918926346\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "800 Train_loss = 0.09986694862793703     Test_loss = 0.14672107770814444\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "801 Train_loss = 0.09981934031560236     Test_loss = 0.14668562464521268\n",
            "\n",
            "Accuracy : 0.9573809523809523\n",
            "802 Train_loss = 0.09977172485688372     Test_loss = 0.14665090123821894\n",
            "\n",
            "Accuracy : 0.9575\n",
            "803 Train_loss = 0.09972416107914293     Test_loss = 0.14661471817791713\n",
            "\n",
            "Accuracy : 0.9575\n",
            "804 Train_loss = 0.09967663463685722     Test_loss = 0.14658074829153706\n",
            "\n",
            "Accuracy : 0.9575\n",
            "805 Train_loss = 0.09962913935400727     Test_loss = 0.1465445923574703\n",
            "\n",
            "Accuracy : 0.9575\n",
            "806 Train_loss = 0.09958165135940918     Test_loss = 0.14650966641538068\n",
            "\n",
            "Accuracy : 0.9575\n",
            "807 Train_loss = 0.09953420627732587     Test_loss = 0.14647464635286359\n",
            "\n",
            "Accuracy : 0.9575\n",
            "808 Train_loss = 0.0994867811241795     Test_loss = 0.14643864389890734\n",
            "\n",
            "Accuracy : 0.9575\n",
            "809 Train_loss = 0.09943939092574132     Test_loss = 0.14640534390689358\n",
            "\n",
            "Accuracy : 0.9575\n",
            "810 Train_loss = 0.09939201838932647     Test_loss = 0.14636904757236982\n",
            "\n",
            "Accuracy : 0.9575\n",
            "811 Train_loss = 0.0993446757230647     Test_loss = 0.14633512799159862\n",
            "\n",
            "Accuracy : 0.9575\n",
            "812 Train_loss = 0.0992973616925341     Test_loss = 0.1462995990739399\n",
            "\n",
            "Accuracy : 0.9575\n",
            "813 Train_loss = 0.09925009327319315     Test_loss = 0.14626523801272265\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "814 Train_loss = 0.09920281860174708     Test_loss = 0.14622977399168693\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "815 Train_loss = 0.09915559439497261     Test_loss = 0.14619579773297736\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "816 Train_loss = 0.09910839363222629     Test_loss = 0.14616060567707964\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "817 Train_loss = 0.0990612150279497     Test_loss = 0.146126127708064\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "818 Train_loss = 0.09901405982949757     Test_loss = 0.14609083277051246\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "819 Train_loss = 0.09896695027311309     Test_loss = 0.14605649968566492\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "820 Train_loss = 0.09891987439023223     Test_loss = 0.14602286439992906\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "821 Train_loss = 0.09887285825542359     Test_loss = 0.14598815685339708\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "822 Train_loss = 0.09882586913841336     Test_loss = 0.14595389181638763\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "823 Train_loss = 0.09877889669605647     Test_loss = 0.14591866125209838\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "824 Train_loss = 0.09873195554861096     Test_loss = 0.14588474246669325\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "825 Train_loss = 0.09868504239538652     Test_loss = 0.1458497977043558\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "826 Train_loss = 0.09863816862975198     Test_loss = 0.14581587127535323\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "827 Train_loss = 0.09859131379504152     Test_loss = 0.145780982532139\n",
            "\n",
            "Accuracy : 0.9577380952380953\n",
            "828 Train_loss = 0.09854449339118362     Test_loss = 0.1457475755815344\n",
            "\n",
            "Accuracy : 0.9576190476190476\n",
            "829 Train_loss = 0.09849771227117321     Test_loss = 0.14571200986500413\n",
            "\n",
            "Accuracy : 0.9577380952380953\n",
            "830 Train_loss = 0.09845097776713761     Test_loss = 0.1456787897952059\n",
            "\n",
            "Accuracy : 0.9577380952380953\n",
            "831 Train_loss = 0.09840425743059537     Test_loss = 0.1456439145278581\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "832 Train_loss = 0.09835757714032817     Test_loss = 0.14560923973451181\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "833 Train_loss = 0.09831091132669881     Test_loss = 0.14557606486089916\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "834 Train_loss = 0.09826429948085422     Test_loss = 0.14554156477972086\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "835 Train_loss = 0.0982177319321748     Test_loss = 0.1455076818159238\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "836 Train_loss = 0.09817117421479148     Test_loss = 0.1454740006657374\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "837 Train_loss = 0.09812465846181896     Test_loss = 0.14544036393736318\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "838 Train_loss = 0.09807818610815007     Test_loss = 0.14540548673528952\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "839 Train_loss = 0.09803173447005963     Test_loss = 0.14537288690379693\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "840 Train_loss = 0.09798530104859735     Test_loss = 0.14533849392666792\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "841 Train_loss = 0.0979389042631237     Test_loss = 0.1453049120977695\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "842 Train_loss = 0.09789252297564617     Test_loss = 0.14527086791784288\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "843 Train_loss = 0.09784617051501442     Test_loss = 0.145237984179338\n",
            "\n",
            "Accuracy : 0.9578571428571429\n",
            "844 Train_loss = 0.09779985481431133     Test_loss = 0.14520418205712976\n",
            "\n",
            "Accuracy : 0.9579761904761904\n",
            "845 Train_loss = 0.09775357267662244     Test_loss = 0.14517069495373433\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "846 Train_loss = 0.09770732811018173     Test_loss = 0.14513748220469525\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "847 Train_loss = 0.09766115180687636     Test_loss = 0.14510484851367453\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "848 Train_loss = 0.0976150043619838     Test_loss = 0.14507159205053863\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "849 Train_loss = 0.09756888924236044     Test_loss = 0.1450378389301141\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "850 Train_loss = 0.09752280196509885     Test_loss = 0.14500485249491224\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "851 Train_loss = 0.09747672509457242     Test_loss = 0.1449720231446973\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "852 Train_loss = 0.0974306787874966     Test_loss = 0.14493844034736525\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "853 Train_loss = 0.09738468056024478     Test_loss = 0.1449060841466654\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "854 Train_loss = 0.09733871589489845     Test_loss = 0.14487292108250807\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "855 Train_loss = 0.09729277581931038     Test_loss = 0.14484000683875028\n",
            "\n",
            "Accuracy : 0.9580952380952381\n",
            "856 Train_loss = 0.09724689679973618     Test_loss = 0.14480644889327476\n",
            "\n",
            "Accuracy : 0.9582142857142857\n",
            "857 Train_loss = 0.09720101886170825     Test_loss = 0.14477403850206974\n",
            "\n",
            "Accuracy : 0.9582142857142857\n",
            "858 Train_loss = 0.09715519053064667     Test_loss = 0.14474161251549178\n",
            "\n",
            "Accuracy : 0.9582142857142857\n",
            "859 Train_loss = 0.09710938349594528     Test_loss = 0.1447084330002371\n",
            "\n",
            "Accuracy : 0.9582142857142857\n",
            "860 Train_loss = 0.09706359992155991     Test_loss = 0.14467577030109577\n",
            "\n",
            "Accuracy : 0.9582142857142857\n",
            "861 Train_loss = 0.0970178519135125     Test_loss = 0.14464318235290813\n",
            "\n",
            "Accuracy : 0.9583333333333334\n",
            "862 Train_loss = 0.09697213074374583     Test_loss = 0.14461129274689435\n",
            "\n",
            "Accuracy : 0.9583333333333334\n",
            "863 Train_loss = 0.09692643497800586     Test_loss = 0.14457701504012874\n",
            "\n",
            "Accuracy : 0.9583333333333334\n",
            "864 Train_loss = 0.09688077781467129     Test_loss = 0.14454567384014444\n",
            "\n",
            "Accuracy : 0.958452380952381\n",
            "865 Train_loss = 0.09683514061062096     Test_loss = 0.1445126960215997\n",
            "\n",
            "Accuracy : 0.958452380952381\n",
            "866 Train_loss = 0.09678953308328599     Test_loss = 0.14447946678260315\n",
            "\n",
            "Accuracy : 0.958452380952381\n",
            "867 Train_loss = 0.0967439798623642     Test_loss = 0.1444469319695434\n",
            "\n",
            "Accuracy : 0.958452380952381\n",
            "868 Train_loss = 0.09669846692384135     Test_loss = 0.14441359014695693\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "869 Train_loss = 0.09665296334789618     Test_loss = 0.14438166774156314\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "870 Train_loss = 0.09660748387194334     Test_loss = 0.14434791305267228\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "871 Train_loss = 0.0965620344493088     Test_loss = 0.14431597222448134\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "872 Train_loss = 0.09651662307030351     Test_loss = 0.14428235418424043\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "873 Train_loss = 0.09647124363302306     Test_loss = 0.14425090696237763\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "874 Train_loss = 0.09642589349718911     Test_loss = 0.14421752540749783\n",
            "\n",
            "Accuracy : 0.9585714285714286\n",
            "875 Train_loss = 0.0963805712633243     Test_loss = 0.14418610873440801\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "876 Train_loss = 0.09633527153071528     Test_loss = 0.14415254982658443\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "877 Train_loss = 0.09628998842508166     Test_loss = 0.14412082170818913\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "878 Train_loss = 0.09624473436490943     Test_loss = 0.14408708649461907\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "879 Train_loss = 0.09619949712111314     Test_loss = 0.14405579438303817\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "880 Train_loss = 0.09615430149017604     Test_loss = 0.14402217442763973\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "881 Train_loss = 0.09610913981790795     Test_loss = 0.14398965810429612\n",
            "\n",
            "Accuracy : 0.9586904761904762\n",
            "882 Train_loss = 0.09606398148878255     Test_loss = 0.14395649090005377\n",
            "\n",
            "Accuracy : 0.9588095238095238\n",
            "883 Train_loss = 0.09601884513485782     Test_loss = 0.14392404428813102\n",
            "\n",
            "Accuracy : 0.9588095238095238\n",
            "884 Train_loss = 0.09597375891950802     Test_loss = 0.14389114539585873\n",
            "\n",
            "Accuracy : 0.9589285714285715\n",
            "885 Train_loss = 0.09592870156697592     Test_loss = 0.14385799757093395\n",
            "\n",
            "Accuracy : 0.9589285714285715\n",
            "886 Train_loss = 0.09588364458440017     Test_loss = 0.14382543438628567\n",
            "\n",
            "Accuracy : 0.9588095238095238\n",
            "887 Train_loss = 0.09583864113093198     Test_loss = 0.14379248091687644\n",
            "\n",
            "Accuracy : 0.9588095238095238\n",
            "888 Train_loss = 0.0957936580377751     Test_loss = 0.14375914699566883\n",
            "\n",
            "Accuracy : 0.9588095238095238\n",
            "889 Train_loss = 0.09574869836975938     Test_loss = 0.14372696716758304\n",
            "\n",
            "Accuracy : 0.9588095238095238\n",
            "890 Train_loss = 0.09570377792718068     Test_loss = 0.14369309682616196\n",
            "\n",
            "Accuracy : 0.959047619047619\n",
            "891 Train_loss = 0.09565888296616439     Test_loss = 0.1436611131378039\n",
            "\n",
            "Accuracy : 0.959047619047619\n",
            "892 Train_loss = 0.09561402292334797     Test_loss = 0.1436282631961433\n",
            "\n",
            "Accuracy : 0.959047619047619\n",
            "893 Train_loss = 0.09556920114582317     Test_loss = 0.14359567055639721\n",
            "\n",
            "Accuracy : 0.959047619047619\n",
            "894 Train_loss = 0.09552438965988067     Test_loss = 0.14356348758260845\n",
            "\n",
            "Accuracy : 0.959047619047619\n",
            "895 Train_loss = 0.09547964329481438     Test_loss = 0.14353094594710836\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "896 Train_loss = 0.0954349188905226     Test_loss = 0.14349940188078247\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "897 Train_loss = 0.09539024177513782     Test_loss = 0.14346602554663107\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "898 Train_loss = 0.09534557368693536     Test_loss = 0.14343443560120478\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "899 Train_loss = 0.09530091215413412     Test_loss = 0.1434014533955067\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "900 Train_loss = 0.09525625177141228     Test_loss = 0.14336956675120643\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "901 Train_loss = 0.09521163162904193     Test_loss = 0.14333608804675058\n",
            "\n",
            "Accuracy : 0.9591666666666667\n",
            "902 Train_loss = 0.09516705480678854     Test_loss = 0.14330421031018206\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "903 Train_loss = 0.09512251577301112     Test_loss = 0.14327096972207942\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "904 Train_loss = 0.09507799715237517     Test_loss = 0.14324013482014394\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "905 Train_loss = 0.09503351171404796     Test_loss = 0.14320702702047153\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "906 Train_loss = 0.09498906246643554     Test_loss = 0.14317578466319658\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "907 Train_loss = 0.09494464776963996     Test_loss = 0.14314244144665986\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "908 Train_loss = 0.09490027459460867     Test_loss = 0.14311246036470762\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "909 Train_loss = 0.09485590922023669     Test_loss = 0.14307870195332606\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "910 Train_loss = 0.09481160381299306     Test_loss = 0.14304737989614066\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "911 Train_loss = 0.09476732859938862     Test_loss = 0.1430148918065462\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "912 Train_loss = 0.09472308871571714     Test_loss = 0.1429840243245592\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "913 Train_loss = 0.09467888734621845     Test_loss = 0.14295087261436726\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "914 Train_loss = 0.09463470869368555     Test_loss = 0.14292016268481142\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "915 Train_loss = 0.09459055457411168     Test_loss = 0.14288766978395784\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "916 Train_loss = 0.09454642075207163     Test_loss = 0.14285604559747528\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "917 Train_loss = 0.09450233052650693     Test_loss = 0.14282376816808393\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "918 Train_loss = 0.09445828704488966     Test_loss = 0.14279202417067585\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "919 Train_loss = 0.09441426036386062     Test_loss = 0.14276107768602797\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "920 Train_loss = 0.09437023589034653     Test_loss = 0.14272943800946641\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "921 Train_loss = 0.09432626195351733     Test_loss = 0.14269793969062763\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "922 Train_loss = 0.09428230138905495     Test_loss = 0.14266636340246885\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "923 Train_loss = 0.09423834961785454     Test_loss = 0.14263500926030373\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "924 Train_loss = 0.09419445639980425     Test_loss = 0.14260237048902036\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "925 Train_loss = 0.09415058857131     Test_loss = 0.14257241975665552\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "926 Train_loss = 0.09410672678285248     Test_loss = 0.1425395273081089\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "927 Train_loss = 0.0940629061824812     Test_loss = 0.14250912725562\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "928 Train_loss = 0.09401908687451796     Test_loss = 0.1424764449224333\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "929 Train_loss = 0.09397532374358093     Test_loss = 0.14244464514309643\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "930 Train_loss = 0.09393159316349124     Test_loss = 0.14241424377532158\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "931 Train_loss = 0.09388788367294026     Test_loss = 0.1423810198130967\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "932 Train_loss = 0.09384420488765728     Test_loss = 0.14234932279938362\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "933 Train_loss = 0.09380055699336246     Test_loss = 0.14231886720152082\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "934 Train_loss = 0.09375694588692973     Test_loss = 0.14228689219662494\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "935 Train_loss = 0.09371336307073651     Test_loss = 0.14225586255840889\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "936 Train_loss = 0.0936698038161828     Test_loss = 0.1422234293435486\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "937 Train_loss = 0.09362629718621054     Test_loss = 0.1421932763368948\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "938 Train_loss = 0.09358279718055948     Test_loss = 0.1421613889118633\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "939 Train_loss = 0.0935393534601696     Test_loss = 0.1421302074772076\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "940 Train_loss = 0.09349594334027156     Test_loss = 0.1420992625602033\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "941 Train_loss = 0.093452551622058     Test_loss = 0.142068075302186\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "942 Train_loss = 0.09340922719269433     Test_loss = 0.1420370379858022\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "943 Train_loss = 0.09336592586518078     Test_loss = 0.14200629539989643\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "944 Train_loss = 0.09332267059950082     Test_loss = 0.14197587773414763\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "945 Train_loss = 0.09327942979574212     Test_loss = 0.14194517227076006\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "946 Train_loss = 0.09323624906371272     Test_loss = 0.141915002602605\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "947 Train_loss = 0.09319306024494366     Test_loss = 0.1418834746308495\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "948 Train_loss = 0.09314994429528418     Test_loss = 0.14185232297968184\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "949 Train_loss = 0.09310684188430292     Test_loss = 0.14182213048603495\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "950 Train_loss = 0.09306375486173239     Test_loss = 0.1417908759194161\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "951 Train_loss = 0.09302071529942023     Test_loss = 0.1417599899067407\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "952 Train_loss = 0.09297767187617427     Test_loss = 0.14172909551248147\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "953 Train_loss = 0.09293466812545946     Test_loss = 0.14169832411728947\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "954 Train_loss = 0.09289168968402099     Test_loss = 0.14166736243065142\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "955 Train_loss = 0.09284875745061665     Test_loss = 0.14163675001337758\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "956 Train_loss = 0.09280583849335668     Test_loss = 0.1416049112718996\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "957 Train_loss = 0.09276299167964608     Test_loss = 0.14157392771638205\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "958 Train_loss = 0.09272015777660393     Test_loss = 0.14154325219367625\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "959 Train_loss = 0.09267736854210361     Test_loss = 0.14151295866751396\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "960 Train_loss = 0.09263460423180653     Test_loss = 0.14148218040556593\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "961 Train_loss = 0.09259187844248354     Test_loss = 0.1414519674240272\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "962 Train_loss = 0.0925491624563786     Test_loss = 0.14142107872939813\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "963 Train_loss = 0.09250651021272423     Test_loss = 0.1413907021636265\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "964 Train_loss = 0.09246387176574038     Test_loss = 0.14135968669493107\n",
            "\n",
            "Accuracy : 0.9592857142857143\n",
            "965 Train_loss = 0.09242127559235241     Test_loss = 0.1413306811335688\n",
            "\n",
            "Accuracy : 0.9594047619047619\n",
            "966 Train_loss = 0.0923787135409455     Test_loss = 0.14129897530369784\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "967 Train_loss = 0.09233619068588841     Test_loss = 0.14126919439944488\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "968 Train_loss = 0.09229369390451335     Test_loss = 0.14123856206020574\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "969 Train_loss = 0.0922512491882862     Test_loss = 0.1412089226598579\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "970 Train_loss = 0.09220882760470983     Test_loss = 0.14117906346110257\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "971 Train_loss = 0.09216645193594898     Test_loss = 0.1411483289019545\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "972 Train_loss = 0.09212410568741741     Test_loss = 0.14111842350096757\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "973 Train_loss = 0.09208181563335653     Test_loss = 0.1410885490012405\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "974 Train_loss = 0.09203954930022164     Test_loss = 0.14105820478602152\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "975 Train_loss = 0.09199729187225439     Test_loss = 0.14102818793505725\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "976 Train_loss = 0.09195508391245921     Test_loss = 0.14099861467528096\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "977 Train_loss = 0.09191289593638949     Test_loss = 0.1409683432720784\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "978 Train_loss = 0.09187073716465534     Test_loss = 0.14093764810177803\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "979 Train_loss = 0.09182861484344573     Test_loss = 0.14090899388247494\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "980 Train_loss = 0.09178652649636401     Test_loss = 0.14087771823635892\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "981 Train_loss = 0.09174445893881045     Test_loss = 0.1408480100432709\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "982 Train_loss = 0.09170241518843263     Test_loss = 0.14081704440703774\n",
            "\n",
            "Accuracy : 0.9595238095238096\n",
            "983 Train_loss = 0.09166041248515283     Test_loss = 0.14078756826707126\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "984 Train_loss = 0.09161845522176527     Test_loss = 0.14075745970499878\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "985 Train_loss = 0.09157649061209887     Test_loss = 0.1407276914925487\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "986 Train_loss = 0.09153457103248812     Test_loss = 0.14069772372079395\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "987 Train_loss = 0.09149269677856803     Test_loss = 0.14066823316591023\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "988 Train_loss = 0.0914508611494791     Test_loss = 0.14063803126277902\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "989 Train_loss = 0.09140905044299126     Test_loss = 0.1406095686536965\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "990 Train_loss = 0.09136728575718428     Test_loss = 0.1405783852602965\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "991 Train_loss = 0.09132554591727053     Test_loss = 0.1405489161089314\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "992 Train_loss = 0.09128383541377681     Test_loss = 0.14051897139311287\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "993 Train_loss = 0.09124212237146284     Test_loss = 0.14048936024698902\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "994 Train_loss = 0.09120046031520122     Test_loss = 0.1404609926519763\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "995 Train_loss = 0.09115879854004265     Test_loss = 0.14042984030048986\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "996 Train_loss = 0.0911171469934668     Test_loss = 0.140400963793973\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "997 Train_loss = 0.09107553952181396     Test_loss = 0.14037115491425306\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "998 Train_loss = 0.09103395957669387     Test_loss = 0.14034163383097809\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "999 Train_loss = 0.09099239500359456     Test_loss = 0.14031211209287636\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses = [] \n",
        "test_losses = []\n",
        "NUM_ITERS = 1000\n",
        "\n",
        "finy_test = y_test\n",
        "finyhat_test = 0\n",
        "\n",
        "for _ in range(NUM_ITERS):\n",
        "    yhat = model.predict(X_train)\n",
        "    train_loss = model.categorical_cross_entropy_loss(y_train, yhat)\n",
        "    yhat_test = model.predict(X_test)\n",
        "    test_loss = model.categorical_cross_entropy_loss(y_test, yhat_test)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    model.fit_once(X_train, y_train, 0.1)\n",
        "    if(len(test_losses) >= 6 and (test_losses[-1] > test_losses[-6])):\n",
        "      # print(\"Test loss[-1]\", test_losses[-1], \" Test loss[-6]\", test_losses[-6])\n",
        "      print(\"Early Stopping\")\n",
        "      break\n",
        "\n",
        "    print(\"Accuracy : \" + str(1 - (yhat_test.argmax(axis=1) != y_test).sum()/len(y_test)) )\n",
        "    print(_, \"Train_loss = \" + str(train_loss) + \"     Test_loss = \" + str(test_loss))\n",
        "    print(\"\")\n",
        "    \n",
        "    if( _ == NUM_ITERS-1):\n",
        "       finyhat_test = yhat_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(NUM_ITERS):\n",
        "    yhat = model.predict(X_train)\n",
        "    train_loss = model.categorical_cross_entropy_loss(y_train, yhat)\n",
        "    yhat_test = model.predict(X_test)\n",
        "    test_loss = model.categorical_cross_entropy_loss(y_test, yhat_test)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    model.fit_once(X_train, y_train, 0.1)\n",
        "    if(len(test_losses) >= 6 and (test_losses[-1] > test_losses[-6])):\n",
        "      # print(\"Test loss[-1]\", test_losses[-1], \" Test loss[-6]\", test_losses[-6])\n",
        "      print(\"Early Stopping\")\n",
        "      break\n",
        "\n",
        "    print(\"Accuracy : \" + str(1 - (yhat_test.argmax(axis=1) != y_test).sum()/len(y_test)) )\n",
        "    print(_, \"Train_loss = \" + str(train_loss) + \"     Test_loss = \" + str(test_loss))\n",
        "    print(\"\")\n",
        "    \n",
        "    if( _ == NUM_ITERS-1):\n",
        "       finyhat_test = yhat_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cnGffem-luB",
        "outputId": "d426e01d-1d78-4890-e2a8-f3d41f6d112f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9596428571428571\n",
            "0 Train_loss = 0.09095083894257946     Test_loss = 0.14028314127796568\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "1 Train_loss = 0.09090933809056378     Test_loss = 0.14025308574993067\n",
            "\n",
            "Accuracy : 0.9596428571428571\n",
            "2 Train_loss = 0.09086786276951722     Test_loss = 0.14022468416199152\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "3 Train_loss = 0.09082643011246654     Test_loss = 0.14019501319242625\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "4 Train_loss = 0.09078498884070875     Test_loss = 0.14016528965436995\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "5 Train_loss = 0.0907436098892806     Test_loss = 0.14013677206522449\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "6 Train_loss = 0.09070224765332029     Test_loss = 0.1401067710679355\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "7 Train_loss = 0.09066094534445096     Test_loss = 0.14007806502964104\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "8 Train_loss = 0.09061964560007511     Test_loss = 0.14004837628273933\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "9 Train_loss = 0.09057840508316113     Test_loss = 0.14001794494997213\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "10 Train_loss = 0.09053713408346906     Test_loss = 0.1399892320105723\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "11 Train_loss = 0.09049591527522802     Test_loss = 0.13995951708921528\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "12 Train_loss = 0.09045473200104981     Test_loss = 0.139930863635057\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "13 Train_loss = 0.090413588006086     Test_loss = 0.1399012314738769\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "14 Train_loss = 0.090372494367633     Test_loss = 0.13987351827237618\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "15 Train_loss = 0.09033141624611868     Test_loss = 0.13984204361055347\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "16 Train_loss = 0.09029033491111638     Test_loss = 0.13981431535814348\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "17 Train_loss = 0.09024929935638043     Test_loss = 0.13978573796782842\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "18 Train_loss = 0.09020829615638716     Test_loss = 0.13975613033099882\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "19 Train_loss = 0.0901673295108992     Test_loss = 0.1397280392786266\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "20 Train_loss = 0.090126369672687     Test_loss = 0.13969791651808797\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "21 Train_loss = 0.09008546037452106     Test_loss = 0.13966933691949363\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "22 Train_loss = 0.09004453785606785     Test_loss = 0.13964069321788258\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "23 Train_loss = 0.09000365220612548     Test_loss = 0.13961141693381335\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "24 Train_loss = 0.08996280541801845     Test_loss = 0.13958271440288603\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "25 Train_loss = 0.08992202542196939     Test_loss = 0.1395529564561489\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "26 Train_loss = 0.08988125412378258     Test_loss = 0.13952490717304428\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "27 Train_loss = 0.08984052023881758     Test_loss = 0.13949557799755666\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "28 Train_loss = 0.08979979981670125     Test_loss = 0.13946658886227992\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "29 Train_loss = 0.08975912866038765     Test_loss = 0.1394375785486373\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "30 Train_loss = 0.08971843877516887     Test_loss = 0.1394088816594135\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "31 Train_loss = 0.0896777977436075     Test_loss = 0.13938057716640018\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "32 Train_loss = 0.08963716086512903     Test_loss = 0.13935211173731699\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "33 Train_loss = 0.08959655346981082     Test_loss = 0.13932285715795428\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "34 Train_loss = 0.08955597133862192     Test_loss = 0.13929478890325414\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "35 Train_loss = 0.08951540126231518     Test_loss = 0.13926558166345268\n",
            "\n",
            "Accuracy : 0.96\n",
            "36 Train_loss = 0.08947481393156348     Test_loss = 0.1392379776822518\n",
            "\n",
            "Accuracy : 0.96\n",
            "37 Train_loss = 0.08943426914703266     Test_loss = 0.13920893178935118\n",
            "\n",
            "Accuracy : 0.96\n",
            "38 Train_loss = 0.08939376744570543     Test_loss = 0.13918049400745205\n",
            "\n",
            "Accuracy : 0.96\n",
            "39 Train_loss = 0.08935327402849048     Test_loss = 0.13915204374328938\n",
            "\n",
            "Accuracy : 0.96\n",
            "40 Train_loss = 0.08931282559537129     Test_loss = 0.1391234457851069\n",
            "\n",
            "Accuracy : 0.96\n",
            "41 Train_loss = 0.08927240200001037     Test_loss = 0.139093788497873\n",
            "\n",
            "Accuracy : 0.96\n",
            "42 Train_loss = 0.0892319761478012     Test_loss = 0.13906628127497783\n",
            "\n",
            "Accuracy : 0.96\n",
            "43 Train_loss = 0.08919160445140302     Test_loss = 0.1390369232741655\n",
            "\n",
            "Accuracy : 0.96\n",
            "44 Train_loss = 0.08915126550690099     Test_loss = 0.13900990670759883\n",
            "\n",
            "Accuracy : 0.96\n",
            "45 Train_loss = 0.08911093794890879     Test_loss = 0.13898048261254559\n",
            "\n",
            "Accuracy : 0.96\n",
            "46 Train_loss = 0.0890706623753999     Test_loss = 0.13895139395608844\n",
            "\n",
            "Accuracy : 0.96\n",
            "47 Train_loss = 0.08903036864473875     Test_loss = 0.13892282726506605\n",
            "\n",
            "Accuracy : 0.96\n",
            "48 Train_loss = 0.08899011849783572     Test_loss = 0.13889536985846918\n",
            "\n",
            "Accuracy : 0.96\n",
            "49 Train_loss = 0.08894988996365137     Test_loss = 0.13886616727676498\n",
            "\n",
            "Accuracy : 0.96\n",
            "50 Train_loss = 0.08890966559276987     Test_loss = 0.13883855748630627\n",
            "\n",
            "Accuracy : 0.96\n",
            "51 Train_loss = 0.08886947549603197     Test_loss = 0.1388094115974346\n",
            "\n",
            "Accuracy : 0.96\n",
            "52 Train_loss = 0.08882928140804973     Test_loss = 0.1387806088837506\n",
            "\n",
            "Accuracy : 0.96\n",
            "53 Train_loss = 0.08878908819377306     Test_loss = 0.13875290999943676\n",
            "\n",
            "Accuracy : 0.96\n",
            "54 Train_loss = 0.08874892991994893     Test_loss = 0.13872499371283745\n",
            "\n",
            "Accuracy : 0.96\n",
            "55 Train_loss = 0.08870876329592757     Test_loss = 0.13869626277824415\n",
            "\n",
            "Accuracy : 0.96\n",
            "56 Train_loss = 0.08866859907188553     Test_loss = 0.13866870571126066\n",
            "\n",
            "Accuracy : 0.96\n",
            "57 Train_loss = 0.0886284599552945     Test_loss = 0.13864084758416836\n",
            "\n",
            "Accuracy : 0.96\n",
            "58 Train_loss = 0.08858834564981283     Test_loss = 0.13861259720945335\n",
            "\n",
            "Accuracy : 0.96\n",
            "59 Train_loss = 0.08854825449293033     Test_loss = 0.1385834827530267\n",
            "\n",
            "Accuracy : 0.96\n",
            "60 Train_loss = 0.08850818228302489     Test_loss = 0.1385564644996667\n",
            "\n",
            "Accuracy : 0.96\n",
            "61 Train_loss = 0.08846817895378503     Test_loss = 0.1385276747169987\n",
            "\n",
            "Accuracy : 0.96\n",
            "62 Train_loss = 0.08842816224146613     Test_loss = 0.13849966528883279\n",
            "\n",
            "Accuracy : 0.96\n",
            "63 Train_loss = 0.08838817252551222     Test_loss = 0.13847139008823034\n",
            "\n",
            "Accuracy : 0.96\n",
            "64 Train_loss = 0.08834822429963947     Test_loss = 0.13844293678304442\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "65 Train_loss = 0.0883083143953937     Test_loss = 0.1384158729974053\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "66 Train_loss = 0.08826841875404785     Test_loss = 0.1383868855151077\n",
            "\n",
            "Accuracy : 0.9602380952380952\n",
            "67 Train_loss = 0.08822856427420162     Test_loss = 0.13835949564346584\n",
            "\n",
            "Accuracy : 0.9602380952380952\n",
            "68 Train_loss = 0.08818874671134817     Test_loss = 0.13833072988911668\n",
            "\n",
            "Accuracy : 0.9602380952380952\n",
            "69 Train_loss = 0.08814893742492082     Test_loss = 0.13830351840751\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "70 Train_loss = 0.08810916836059332     Test_loss = 0.13827583618564357\n",
            "\n",
            "Accuracy : 0.9602380952380952\n",
            "71 Train_loss = 0.08806940571070174     Test_loss = 0.1382477798708338\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "72 Train_loss = 0.08802967746259202     Test_loss = 0.13822006908091417\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "73 Train_loss = 0.08798998557094648     Test_loss = 0.13819163740580034\n",
            "\n",
            "Accuracy : 0.96\n",
            "74 Train_loss = 0.08795030127542175     Test_loss = 0.13816471657010426\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "75 Train_loss = 0.08791063844450465     Test_loss = 0.13813690456232683\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "76 Train_loss = 0.08787100404654401     Test_loss = 0.13810881574064945\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "77 Train_loss = 0.08783140020402834     Test_loss = 0.1380814670361519\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "78 Train_loss = 0.08779181291554242     Test_loss = 0.13805435860760581\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "79 Train_loss = 0.08775226384160258     Test_loss = 0.13802647136977647\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "80 Train_loss = 0.08771271855289402     Test_loss = 0.13799887157355867\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "81 Train_loss = 0.08767323595467312     Test_loss = 0.13797137393963763\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "82 Train_loss = 0.08763373894645618     Test_loss = 0.13794367685312928\n",
            "\n",
            "Accuracy : 0.9597619047619048\n",
            "83 Train_loss = 0.0875942541181646     Test_loss = 0.1379166398171106\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "84 Train_loss = 0.08755478494632124     Test_loss = 0.13788941275795938\n",
            "\n",
            "Accuracy : 0.9598809523809524\n",
            "85 Train_loss = 0.08751534892036797     Test_loss = 0.13786191304663095\n",
            "\n",
            "Accuracy : 0.96\n",
            "86 Train_loss = 0.08747593695442529     Test_loss = 0.1378348185165749\n",
            "\n",
            "Accuracy : 0.96\n",
            "87 Train_loss = 0.08743652438417526     Test_loss = 0.13780649128013736\n",
            "\n",
            "Accuracy : 0.96\n",
            "88 Train_loss = 0.08739714257893508     Test_loss = 0.13777984926545067\n",
            "\n",
            "Accuracy : 0.96\n",
            "89 Train_loss = 0.08735779729972581     Test_loss = 0.13775263277366454\n",
            "\n",
            "Accuracy : 0.96\n",
            "90 Train_loss = 0.08731847515219718     Test_loss = 0.1377246499038222\n",
            "\n",
            "Accuracy : 0.96\n",
            "91 Train_loss = 0.0872791956220825     Test_loss = 0.13769735931803886\n",
            "\n",
            "Accuracy : 0.96\n",
            "92 Train_loss = 0.08723990099505013     Test_loss = 0.1376708313075897\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "93 Train_loss = 0.08720064501125592     Test_loss = 0.13764376359569275\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "94 Train_loss = 0.08716144243911171     Test_loss = 0.1376160465554946\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "95 Train_loss = 0.08712223275601644     Test_loss = 0.13758858001539445\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "96 Train_loss = 0.08708306142451255     Test_loss = 0.13756212853972408\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "97 Train_loss = 0.08704392571046839     Test_loss = 0.1375349146546691\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "98 Train_loss = 0.08700482239285957     Test_loss = 0.13750692005165405\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "99 Train_loss = 0.08696570451905825     Test_loss = 0.1374807767352508\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "100 Train_loss = 0.08692661680403409     Test_loss = 0.13745288467368577\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "101 Train_loss = 0.08688757265648492     Test_loss = 0.13742656143690377\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "102 Train_loss = 0.08684854678132023     Test_loss = 0.13739892636792916\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "103 Train_loss = 0.08680954361160767     Test_loss = 0.13737123704352536\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "104 Train_loss = 0.08677055171091712     Test_loss = 0.13734431004540865\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "105 Train_loss = 0.08673157512056016     Test_loss = 0.13731724549356378\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "106 Train_loss = 0.08669261855024124     Test_loss = 0.1372904682139698\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "107 Train_loss = 0.08665368539029893     Test_loss = 0.13726389442449063\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "108 Train_loss = 0.08661476987213597     Test_loss = 0.13723692110124613\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "109 Train_loss = 0.08657587069497187     Test_loss = 0.13720991797829601\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "110 Train_loss = 0.08653699222183114     Test_loss = 0.13718276792835343\n",
            "\n",
            "Accuracy : 0.9601190476190476\n",
            "111 Train_loss = 0.08649814282927075     Test_loss = 0.13715705883540524\n",
            "\n",
            "Accuracy : 0.9602380952380952\n",
            "112 Train_loss = 0.08645930917163773     Test_loss = 0.1371297737919786\n",
            "\n",
            "Accuracy : 0.9602380952380952\n",
            "113 Train_loss = 0.0864204966245088     Test_loss = 0.13710272738798243\n",
            "\n",
            "Accuracy : 0.9603571428571429\n",
            "114 Train_loss = 0.08638170301817012     Test_loss = 0.13707610750037372\n",
            "\n",
            "Accuracy : 0.9603571428571429\n",
            "115 Train_loss = 0.08634294691214872     Test_loss = 0.1370503721290926\n",
            "\n",
            "Accuracy : 0.9603571428571429\n",
            "116 Train_loss = 0.08630420729920482     Test_loss = 0.13702245395298146\n",
            "\n",
            "Accuracy : 0.9604761904761905\n",
            "117 Train_loss = 0.08626545854719085     Test_loss = 0.13699560244322254\n",
            "\n",
            "Accuracy : 0.9604761904761905\n",
            "118 Train_loss = 0.08622677167928049     Test_loss = 0.13696907823338464\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "119 Train_loss = 0.0861881008728902     Test_loss = 0.13694233235887482\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "120 Train_loss = 0.08614944521794794     Test_loss = 0.13691545131961338\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "121 Train_loss = 0.08611082198167058     Test_loss = 0.13688914298766686\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "122 Train_loss = 0.08607220741365075     Test_loss = 0.13686167708686847\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "123 Train_loss = 0.08603361589277783     Test_loss = 0.13683490694015327\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "124 Train_loss = 0.08599505649632974     Test_loss = 0.13680797374224699\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "125 Train_loss = 0.08595653673764402     Test_loss = 0.1367819322114371\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "126 Train_loss = 0.08591803761529652     Test_loss = 0.13675467801516142\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "127 Train_loss = 0.08587953557863658     Test_loss = 0.13672919010969317\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "128 Train_loss = 0.08584103994202902     Test_loss = 0.13670134212244509\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "129 Train_loss = 0.08580258885700813     Test_loss = 0.13667502764030165\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "130 Train_loss = 0.08576418974305938     Test_loss = 0.13664860973220413\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "131 Train_loss = 0.08572578461917314     Test_loss = 0.13662236768468872\n",
            "\n",
            "Accuracy : 0.9605952380952381\n",
            "132 Train_loss = 0.08568741761885193     Test_loss = 0.13659504180682047\n",
            "\n",
            "Accuracy : 0.9607142857142857\n",
            "133 Train_loss = 0.0856490668968598     Test_loss = 0.13656837246456172\n",
            "\n",
            "Accuracy : 0.9607142857142857\n",
            "134 Train_loss = 0.08561074079998858     Test_loss = 0.13654177640452844\n",
            "\n",
            "Accuracy : 0.9607142857142857\n",
            "135 Train_loss = 0.08557241999416727     Test_loss = 0.13651566823307704\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "136 Train_loss = 0.08553412817391835     Test_loss = 0.13648779473554293\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "137 Train_loss = 0.08549586712859625     Test_loss = 0.1364616368178179\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "138 Train_loss = 0.08545762124476078     Test_loss = 0.13643495401505218\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "139 Train_loss = 0.08541937814653806     Test_loss = 0.136408360571592\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "140 Train_loss = 0.0853811893248567     Test_loss = 0.13638201396756913\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "141 Train_loss = 0.08534302068396749     Test_loss = 0.13635557596592288\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "142 Train_loss = 0.08530486007977348     Test_loss = 0.13632854607194542\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "143 Train_loss = 0.08526671156781733     Test_loss = 0.13630190127321587\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "144 Train_loss = 0.08522858473205012     Test_loss = 0.1362754542507278\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "145 Train_loss = 0.08519046733601554     Test_loss = 0.1362487018824759\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "146 Train_loss = 0.08515241078352062     Test_loss = 0.1362213481611235\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "147 Train_loss = 0.08511436752582799     Test_loss = 0.13619569797582376\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "148 Train_loss = 0.0850763478271065     Test_loss = 0.1361680947203884\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "149 Train_loss = 0.08503836375850955     Test_loss = 0.13614238858174021\n",
            "\n",
            "Accuracy : 0.9608333333333333\n",
            "150 Train_loss = 0.0850003666055711     Test_loss = 0.1361162267110757\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "151 Train_loss = 0.08496239149605986     Test_loss = 0.1360886654429528\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "152 Train_loss = 0.08492447358929366     Test_loss = 0.136062451828194\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "153 Train_loss = 0.08488654351316212     Test_loss = 0.13603642604289537\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "154 Train_loss = 0.08484865638350841     Test_loss = 0.13601038996341452\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "155 Train_loss = 0.08481077042845146     Test_loss = 0.13598354485739297\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "156 Train_loss = 0.08477291702523261     Test_loss = 0.13595740331625003\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "157 Train_loss = 0.08473511399463003     Test_loss = 0.13593157033245384\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "158 Train_loss = 0.08469734014398123     Test_loss = 0.13590558050998328\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "159 Train_loss = 0.08465955664380458     Test_loss = 0.1358788532917306\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "160 Train_loss = 0.08462178598495754     Test_loss = 0.13585292862409898\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "161 Train_loss = 0.08458403541111609     Test_loss = 0.13582641495031353\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "162 Train_loss = 0.08454627843719688     Test_loss = 0.1358008885056827\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "163 Train_loss = 0.08450856664881845     Test_loss = 0.1357734079584157\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "164 Train_loss = 0.08447086514528768     Test_loss = 0.13574828925392254\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "165 Train_loss = 0.08443316578843436     Test_loss = 0.13572259793841596\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "166 Train_loss = 0.08439550939654883     Test_loss = 0.13569587391800209\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "167 Train_loss = 0.08435787755845349     Test_loss = 0.1356697164057605\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "168 Train_loss = 0.08432028630753073     Test_loss = 0.13564365017663\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "169 Train_loss = 0.0842827120001862     Test_loss = 0.13561815035049873\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "170 Train_loss = 0.08424515486488293     Test_loss = 0.13559126853379727\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "171 Train_loss = 0.08420763750515516     Test_loss = 0.1355650771323587\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "172 Train_loss = 0.08417014150167143     Test_loss = 0.13553883416020698\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "173 Train_loss = 0.08413268292404091     Test_loss = 0.13551370625958276\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "174 Train_loss = 0.08409524578259517     Test_loss = 0.13548688893340569\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "175 Train_loss = 0.0840578272270176     Test_loss = 0.1354602701713339\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "176 Train_loss = 0.08402042889382867     Test_loss = 0.13543549784418818\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "177 Train_loss = 0.08398303942633051     Test_loss = 0.135408865526647\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "178 Train_loss = 0.08394567144228758     Test_loss = 0.13538317087685278\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "179 Train_loss = 0.08390834308034396     Test_loss = 0.1353569324382711\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "180 Train_loss = 0.08387103336867695     Test_loss = 0.13533123630746755\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "181 Train_loss = 0.08383374173086948     Test_loss = 0.13530566022744026\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "182 Train_loss = 0.08379648345794677     Test_loss = 0.13528103612500036\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "183 Train_loss = 0.08375923747323384     Test_loss = 0.13525360059925606\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "184 Train_loss = 0.08372204725484156     Test_loss = 0.1352284662687162\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "185 Train_loss = 0.08368491895979381     Test_loss = 0.1352026817222659\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "186 Train_loss = 0.083647771739906     Test_loss = 0.13517587043491033\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "187 Train_loss = 0.08361067169019111     Test_loss = 0.13515009292711255\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "188 Train_loss = 0.0835736170181181     Test_loss = 0.13512559758367815\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "189 Train_loss = 0.08353657456344214     Test_loss = 0.13509892756689187\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "190 Train_loss = 0.08349957132026294     Test_loss = 0.1350736312929361\n",
            "\n",
            "Accuracy : 0.960952380952381\n",
            "191 Train_loss = 0.08346259895838028     Test_loss = 0.1350472500070263\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "192 Train_loss = 0.083425659730983     Test_loss = 0.13502194767933431\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "193 Train_loss = 0.08338873564144011     Test_loss = 0.13499757060129133\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "194 Train_loss = 0.08335182676073483     Test_loss = 0.13497097309569062\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "195 Train_loss = 0.08331495454882715     Test_loss = 0.13494545894296073\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "196 Train_loss = 0.08327812340562792     Test_loss = 0.134919164495914\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "197 Train_loss = 0.08324127334104035     Test_loss = 0.13489386126424144\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "198 Train_loss = 0.08320445097726853     Test_loss = 0.13486882314668777\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "199 Train_loss = 0.0831676734641645     Test_loss = 0.13484406991959966\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "200 Train_loss = 0.08313091292204354     Test_loss = 0.1348167245694458\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "201 Train_loss = 0.0830941767130801     Test_loss = 0.13479301302507582\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "202 Train_loss = 0.08305744252608666     Test_loss = 0.13476697703547205\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "203 Train_loss = 0.08302074708104597     Test_loss = 0.13474235621776662\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "204 Train_loss = 0.08298406352466654     Test_loss = 0.1347153322198045\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "205 Train_loss = 0.08294740379373261     Test_loss = 0.13469103443753797\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "206 Train_loss = 0.08291079621429132     Test_loss = 0.13466621152987335\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "207 Train_loss = 0.08287420499856366     Test_loss = 0.13463905099160453\n",
            "\n",
            "Accuracy : 0.9610714285714286\n",
            "208 Train_loss = 0.0828376184299691     Test_loss = 0.13461507575195625\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "209 Train_loss = 0.0828010367303594     Test_loss = 0.13458907495385253\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "210 Train_loss = 0.08276449780894868     Test_loss = 0.13456374180900638\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "211 Train_loss = 0.08272796195810558     Test_loss = 0.1345384802149942\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "212 Train_loss = 0.08269145698832493     Test_loss = 0.13451327609917857\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "213 Train_loss = 0.08265497642694863     Test_loss = 0.13448769872235752\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "214 Train_loss = 0.0826185026380996     Test_loss = 0.1344629788264393\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "215 Train_loss = 0.08258206863080708     Test_loss = 0.13443689961322108\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "216 Train_loss = 0.08254568205362277     Test_loss = 0.1344130663255312\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "217 Train_loss = 0.0825092877629887     Test_loss = 0.1343869881634111\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "218 Train_loss = 0.08247294772554867     Test_loss = 0.13436126363599746\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "219 Train_loss = 0.08243660106318676     Test_loss = 0.13433717907489878\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "220 Train_loss = 0.0824002418721071     Test_loss = 0.13431130648519352\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "221 Train_loss = 0.08236388919752055     Test_loss = 0.13428621154877107\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "222 Train_loss = 0.0823275777734105     Test_loss = 0.13426135437734543\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "223 Train_loss = 0.08229127050373199     Test_loss = 0.13423599915514287\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "224 Train_loss = 0.0822549861070362     Test_loss = 0.13420949193608653\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "225 Train_loss = 0.08221871169987971     Test_loss = 0.13418520314733037\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "226 Train_loss = 0.08218249307222826     Test_loss = 0.13416006566940586\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "227 Train_loss = 0.08214627852332967     Test_loss = 0.134136256682034\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "228 Train_loss = 0.08211007894437013     Test_loss = 0.13410945885954595\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "229 Train_loss = 0.08207393315113741     Test_loss = 0.1340843540602512\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "230 Train_loss = 0.08203779110497536     Test_loss = 0.13405896092251723\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "231 Train_loss = 0.08200170276465248     Test_loss = 0.13403466449299978\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "232 Train_loss = 0.08196559886100711     Test_loss = 0.1340102753126587\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "233 Train_loss = 0.08192951222268322     Test_loss = 0.13398411833011997\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "234 Train_loss = 0.08189344325269611     Test_loss = 0.13396013489043632\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "235 Train_loss = 0.08185741592406082     Test_loss = 0.13393444149516173\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "236 Train_loss = 0.08182140579485042     Test_loss = 0.13391042823507493\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "237 Train_loss = 0.08178539367543615     Test_loss = 0.13388533233697494\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "238 Train_loss = 0.08174939920078815     Test_loss = 0.13386085930778202\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "239 Train_loss = 0.08171342488591327     Test_loss = 0.1338357229528272\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "240 Train_loss = 0.08167750045802394     Test_loss = 0.13381141206961406\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "241 Train_loss = 0.08164158399335349     Test_loss = 0.13378504976877229\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "242 Train_loss = 0.08160568673758567     Test_loss = 0.13376163977940161\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "243 Train_loss = 0.08156980851307895     Test_loss = 0.13373616539804875\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "244 Train_loss = 0.08153395752961605     Test_loss = 0.1337119662915149\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "245 Train_loss = 0.08149815301438161     Test_loss = 0.13368698831422318\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "246 Train_loss = 0.08146234453845225     Test_loss = 0.13366306051464905\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "247 Train_loss = 0.08142655288405364     Test_loss = 0.13363807343986359\n",
            "\n",
            "Accuracy : 0.9611904761904762\n",
            "248 Train_loss = 0.08139078524163997     Test_loss = 0.13361361845856928\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "249 Train_loss = 0.08135503598483368     Test_loss = 0.13358977146668177\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "250 Train_loss = 0.08131929730529652     Test_loss = 0.13356513934499742\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "251 Train_loss = 0.0812835872286425     Test_loss = 0.13353994989596446\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "252 Train_loss = 0.08124790042728085     Test_loss = 0.13351652510207238\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "253 Train_loss = 0.08121223893366135     Test_loss = 0.1334915102967877\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "254 Train_loss = 0.08117659571471433     Test_loss = 0.13346844311609227\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "255 Train_loss = 0.0811409769824733     Test_loss = 0.1334433909668188\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "256 Train_loss = 0.08110536824331092     Test_loss = 0.13341836600017498\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "257 Train_loss = 0.08106976828656554     Test_loss = 0.13339429027179234\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "258 Train_loss = 0.08103417480977343     Test_loss = 0.13336950482039808\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "259 Train_loss = 0.08099856247311514     Test_loss = 0.13334658024544507\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "260 Train_loss = 0.08096300120274727     Test_loss = 0.13332129508229726\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "261 Train_loss = 0.08092745970003853     Test_loss = 0.1332972497410641\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "262 Train_loss = 0.08089194553459701     Test_loss = 0.1332723224822196\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "263 Train_loss = 0.08085645313994834     Test_loss = 0.1332489431700077\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "264 Train_loss = 0.08082097908089464     Test_loss = 0.13322393237133726\n",
            "\n",
            "Accuracy : 0.9613095238095238\n",
            "265 Train_loss = 0.08078554420136481     Test_loss = 0.1331998233683426\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "266 Train_loss = 0.08075015076954091     Test_loss = 0.1331759238947316\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "267 Train_loss = 0.08071477524478328     Test_loss = 0.13315068377335998\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "268 Train_loss = 0.08067940664389608     Test_loss = 0.1331278114702308\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "269 Train_loss = 0.0806440760161206     Test_loss = 0.13310322300463062\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "270 Train_loss = 0.08060875187677426     Test_loss = 0.13307977978508728\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "271 Train_loss = 0.08057343914073534     Test_loss = 0.13305409899643775\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "272 Train_loss = 0.0805381598486892     Test_loss = 0.13303213644008322\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "273 Train_loss = 0.08050288545222066     Test_loss = 0.1330063358862758\n",
            "\n",
            "Accuracy : 0.9614285714285714\n",
            "274 Train_loss = 0.08046763200950065     Test_loss = 0.1329833237057027\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "275 Train_loss = 0.08043240485229172     Test_loss = 0.13295921884755657\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "276 Train_loss = 0.08039718836942304     Test_loss = 0.13293535282756516\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "277 Train_loss = 0.08036199302146112     Test_loss = 0.1329115941615919\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "278 Train_loss = 0.08032683879843304     Test_loss = 0.13288772543586921\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "279 Train_loss = 0.08029169341915261     Test_loss = 0.1328626861632533\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "280 Train_loss = 0.08025658903252893     Test_loss = 0.13283937189678963\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "281 Train_loss = 0.0802215412627669     Test_loss = 0.13281587664336847\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "282 Train_loss = 0.0801864586250945     Test_loss = 0.13279272339572554\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "283 Train_loss = 0.08015140988283251     Test_loss = 0.1327668845081479\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "284 Train_loss = 0.08011635602235746     Test_loss = 0.13274435456201614\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "285 Train_loss = 0.08008133396415613     Test_loss = 0.1327201541914476\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "286 Train_loss = 0.08004634801900615     Test_loss = 0.13269637985170793\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "287 Train_loss = 0.08001138224153118     Test_loss = 0.13267155076623569\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "288 Train_loss = 0.07997644206060187     Test_loss = 0.1326485654102572\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "289 Train_loss = 0.07994151502171595     Test_loss = 0.13262506548911104\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "290 Train_loss = 0.07990661283412616     Test_loss = 0.1326014327475135\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "291 Train_loss = 0.07987173104028604     Test_loss = 0.13257679861859936\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "292 Train_loss = 0.0798368530549224     Test_loss = 0.13255516963932545\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "293 Train_loss = 0.07980201480789155     Test_loss = 0.13253111970423978\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "294 Train_loss = 0.07976716809613829     Test_loss = 0.13250747316929143\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "295 Train_loss = 0.07973237237634624     Test_loss = 0.13248446837371067\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "296 Train_loss = 0.07969758775055599     Test_loss = 0.1324609856105098\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "297 Train_loss = 0.07966282514452518     Test_loss = 0.13243798293918657\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "298 Train_loss = 0.07962808932769568     Test_loss = 0.13241527947442006\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "299 Train_loss = 0.07959335156738097     Test_loss = 0.13239084936969697\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "300 Train_loss = 0.0795586394714154     Test_loss = 0.13236794136763777\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "301 Train_loss = 0.0795239345245675     Test_loss = 0.13234537288900672\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "302 Train_loss = 0.07948927975611601     Test_loss = 0.13232163938915154\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "303 Train_loss = 0.07945461246517095     Test_loss = 0.13229901743111688\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "304 Train_loss = 0.07941998760170148     Test_loss = 0.1322750453778685\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "305 Train_loss = 0.07938539741650677     Test_loss = 0.13225177854120634\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "306 Train_loss = 0.0793508396004966     Test_loss = 0.13222841873769142\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "307 Train_loss = 0.07931629768330749     Test_loss = 0.13220460533431583\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "308 Train_loss = 0.0792817552426358     Test_loss = 0.13218276208237154\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "309 Train_loss = 0.07924723008148289     Test_loss = 0.13215790911509434\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "310 Train_loss = 0.07921273020095572     Test_loss = 0.1321351500411043\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "311 Train_loss = 0.07917825412931835     Test_loss = 0.13211231773498736\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "312 Train_loss = 0.07914379976672492     Test_loss = 0.13208891304150083\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "313 Train_loss = 0.07910935539138737     Test_loss = 0.1320665177142219\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "314 Train_loss = 0.07907493152542218     Test_loss = 0.13204269555422635\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "315 Train_loss = 0.07904053238402478     Test_loss = 0.13201979939157693\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "316 Train_loss = 0.07900613415317939     Test_loss = 0.13199676289082785\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "317 Train_loss = 0.07897178023139188     Test_loss = 0.13197308777617955\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "318 Train_loss = 0.07893743498572466     Test_loss = 0.13195028054289082\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "319 Train_loss = 0.07890312320219349     Test_loss = 0.13192739369230033\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "320 Train_loss = 0.07886882522904774     Test_loss = 0.1319040834052369\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "321 Train_loss = 0.07883456230093291     Test_loss = 0.1318803042744035\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "322 Train_loss = 0.0788003190314857     Test_loss = 0.13185856924240594\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "323 Train_loss = 0.0787661334674555     Test_loss = 0.13183446823912046\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "324 Train_loss = 0.07873198923358753     Test_loss = 0.1318128244397624\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "325 Train_loss = 0.07869784825955983     Test_loss = 0.13178767266248728\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "326 Train_loss = 0.07866369959082364     Test_loss = 0.13176694790655308\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "327 Train_loss = 0.078629570548228     Test_loss = 0.13174334332561155\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "328 Train_loss = 0.07859544401602854     Test_loss = 0.13172116731203753\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "329 Train_loss = 0.07856131663524693     Test_loss = 0.13169833307677647\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "330 Train_loss = 0.07852720825873197     Test_loss = 0.1316766333201834\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "331 Train_loss = 0.07849312699403924     Test_loss = 0.1316536412377333\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "332 Train_loss = 0.07845907739974808     Test_loss = 0.13163162832986192\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "333 Train_loss = 0.07842501318016228     Test_loss = 0.13160868678155715\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "334 Train_loss = 0.07839097507676268     Test_loss = 0.13158668191532316\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "335 Train_loss = 0.07835693289992017     Test_loss = 0.13156513735885994\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "336 Train_loss = 0.0783229311311847     Test_loss = 0.1315406079000255\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "337 Train_loss = 0.07828893309776205     Test_loss = 0.13151884180080833\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "338 Train_loss = 0.07825495940186565     Test_loss = 0.13149649432193114\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "339 Train_loss = 0.07822100681597466     Test_loss = 0.13147312656560656\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "340 Train_loss = 0.07818708083256247     Test_loss = 0.131449972111063\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "341 Train_loss = 0.07815317775112711     Test_loss = 0.13142733898807993\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "342 Train_loss = 0.07811932330990497     Test_loss = 0.13140562175907758\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "343 Train_loss = 0.07808547418860694     Test_loss = 0.13138243677124906\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "344 Train_loss = 0.07805165080772035     Test_loss = 0.13136021262264355\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "345 Train_loss = 0.07801785080833903     Test_loss = 0.13133614445766262\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "346 Train_loss = 0.07798406854215002     Test_loss = 0.13131563589714898\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "347 Train_loss = 0.07795031775309777     Test_loss = 0.13129211418449832\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "348 Train_loss = 0.07791659233363277     Test_loss = 0.13126861640732887\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "349 Train_loss = 0.07788289354268259     Test_loss = 0.13124719197844764\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "350 Train_loss = 0.07784921209834435     Test_loss = 0.13122277655988873\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "351 Train_loss = 0.07781552337643846     Test_loss = 0.1312013684645912\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "352 Train_loss = 0.07778187177246237     Test_loss = 0.13117808227503716\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "353 Train_loss = 0.07774822592815686     Test_loss = 0.13115427306358893\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "354 Train_loss = 0.07771461812946766     Test_loss = 0.13113152432074004\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "355 Train_loss = 0.07768099768199854     Test_loss = 0.13110925128498094\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "356 Train_loss = 0.07764741024180158     Test_loss = 0.13108701763483174\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "357 Train_loss = 0.07761382912348307     Test_loss = 0.13106255943666065\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "358 Train_loss = 0.07758024295963266     Test_loss = 0.1310411445895727\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "359 Train_loss = 0.07754669447887245     Test_loss = 0.1310181934903246\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "360 Train_loss = 0.07751318141055547     Test_loss = 0.13099518631178844\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "361 Train_loss = 0.07747967402636739     Test_loss = 0.13097203084679582\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "362 Train_loss = 0.0774462240504533     Test_loss = 0.13095039703891356\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "363 Train_loss = 0.07741275933557726     Test_loss = 0.1309267025165148\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "364 Train_loss = 0.07737931458335921     Test_loss = 0.1309046116764046\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "365 Train_loss = 0.07734590818661416     Test_loss = 0.13088142446119694\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "366 Train_loss = 0.0773124935406314     Test_loss = 0.13085883166787374\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "367 Train_loss = 0.07727908489406173     Test_loss = 0.13083656320767903\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "368 Train_loss = 0.07724571373024144     Test_loss = 0.1308136848774323\n",
            "\n",
            "Accuracy : 0.9615476190476191\n",
            "369 Train_loss = 0.07721237716139363     Test_loss = 0.1307924108068458\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "370 Train_loss = 0.07717909286791497     Test_loss = 0.13076872734875036\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "371 Train_loss = 0.07714576869269543     Test_loss = 0.13074675868713073\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "372 Train_loss = 0.07711248287200481     Test_loss = 0.1307235432118365\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "373 Train_loss = 0.07707926579280656     Test_loss = 0.13070250069591263\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "374 Train_loss = 0.07704600597790566     Test_loss = 0.13067867479078463\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "375 Train_loss = 0.07701279677602937     Test_loss = 0.1306562340180161\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "376 Train_loss = 0.0769795872334303     Test_loss = 0.13063440731728057\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "377 Train_loss = 0.07694643425325959     Test_loss = 0.13061053825109278\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "378 Train_loss = 0.07691325768351091     Test_loss = 0.1305905907000971\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "379 Train_loss = 0.0768801008956695     Test_loss = 0.1305662310126803\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "380 Train_loss = 0.07684698336146398     Test_loss = 0.13054522273836686\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "381 Train_loss = 0.07681387146085218     Test_loss = 0.130522438545486\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "382 Train_loss = 0.07678078607274477     Test_loss = 0.13050081502932603\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "383 Train_loss = 0.07674772891392384     Test_loss = 0.1304781660934778\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "384 Train_loss = 0.07671469488691542     Test_loss = 0.13045584482327505\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "385 Train_loss = 0.07668169900671244     Test_loss = 0.13043416095446228\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "386 Train_loss = 0.07664867726683716     Test_loss = 0.1304117729814622\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "387 Train_loss = 0.07661570801356796     Test_loss = 0.13039014495353482\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "388 Train_loss = 0.07658275277659099     Test_loss = 0.13036764472526727\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "389 Train_loss = 0.07654977865278464     Test_loss = 0.13034563244576322\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "390 Train_loss = 0.07651684171741203     Test_loss = 0.13032373333540218\n",
            "\n",
            "Accuracy : 0.9616666666666667\n",
            "391 Train_loss = 0.07648392123632326     Test_loss = 0.13030034649371589\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "392 Train_loss = 0.07645103949154035     Test_loss = 0.13028072979266841\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "393 Train_loss = 0.07641817600863038     Test_loss = 0.1302564275728623\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "394 Train_loss = 0.07638532098576947     Test_loss = 0.13023619724477642\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "395 Train_loss = 0.07635245811357755     Test_loss = 0.13021203783663857\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "396 Train_loss = 0.07631963791005864     Test_loss = 0.1301909498667769\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "397 Train_loss = 0.07628679965794752     Test_loss = 0.13016803837398802\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "398 Train_loss = 0.07625397176792682     Test_loss = 0.130146411447944\n",
            "\n",
            "Accuracy : 0.9617857142857142\n",
            "399 Train_loss = 0.07622120275285806     Test_loss = 0.13012368347463288\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "400 Train_loss = 0.07618845672223336     Test_loss = 0.13010034673372228\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "401 Train_loss = 0.07615576163794681     Test_loss = 0.13007828297927496\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "402 Train_loss = 0.07612302307586259     Test_loss = 0.1300579475564747\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "403 Train_loss = 0.07609033536451154     Test_loss = 0.13003425315338865\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "404 Train_loss = 0.07605768685226921     Test_loss = 0.1300129147671824\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "405 Train_loss = 0.07602508396580784     Test_loss = 0.12998982353788446\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "406 Train_loss = 0.07599241702964513     Test_loss = 0.12996881717535586\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "407 Train_loss = 0.07595980817704802     Test_loss = 0.12994658007104007\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "408 Train_loss = 0.07592722867988014     Test_loss = 0.12992425709771468\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "409 Train_loss = 0.07589466773488715     Test_loss = 0.1299020782540571\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "410 Train_loss = 0.07586212255495707     Test_loss = 0.1298798420511368\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "411 Train_loss = 0.07582962004902453     Test_loss = 0.1298589905129828\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "412 Train_loss = 0.07579715058856752     Test_loss = 0.12983623886020196\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "413 Train_loss = 0.07576464839995613     Test_loss = 0.1298151439465269\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "414 Train_loss = 0.07573221986103774     Test_loss = 0.12979244286487476\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "415 Train_loss = 0.07569975887266917     Test_loss = 0.12977123972795732\n",
            "\n",
            "Accuracy : 0.9619047619047619\n",
            "416 Train_loss = 0.07566736710135688     Test_loss = 0.12974890401112854\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "417 Train_loss = 0.07563496264443562     Test_loss = 0.1297264495957718\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "418 Train_loss = 0.07560261247913594     Test_loss = 0.1297065481019171\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "419 Train_loss = 0.07557025587792333     Test_loss = 0.12968272732840147\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "420 Train_loss = 0.07553793004587832     Test_loss = 0.12966149636147006\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "421 Train_loss = 0.07550563262180374     Test_loss = 0.12964046725164113\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "422 Train_loss = 0.0754733637626825     Test_loss = 0.12961771751557363\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "423 Train_loss = 0.07544109505501374     Test_loss = 0.12959675799336584\n",
            "\n",
            "Accuracy : 0.9621428571428572\n",
            "424 Train_loss = 0.07540882687559271     Test_loss = 0.12957509045048313\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "425 Train_loss = 0.07537660695483078     Test_loss = 0.1295531154582591\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "426 Train_loss = 0.07534435075963056     Test_loss = 0.12953131595556633\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "427 Train_loss = 0.07531215676193614     Test_loss = 0.1295111249721347\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "428 Train_loss = 0.07527997562249432     Test_loss = 0.1294882077670921\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "429 Train_loss = 0.07524780484756093     Test_loss = 0.12946780133031704\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "430 Train_loss = 0.07521565371758497     Test_loss = 0.12944375360077806\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "431 Train_loss = 0.07518350025165248     Test_loss = 0.1294242069801654\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "432 Train_loss = 0.0751513700241057     Test_loss = 0.12940216229387494\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "433 Train_loss = 0.0751192406367532     Test_loss = 0.12938144917499236\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "434 Train_loss = 0.07508711994950078     Test_loss = 0.12935947478100895\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "435 Train_loss = 0.07505502691552199     Test_loss = 0.12933762399705293\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "436 Train_loss = 0.07502293589917079     Test_loss = 0.1293168548937866\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "437 Train_loss = 0.07499088495454068     Test_loss = 0.1292965633739657\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "438 Train_loss = 0.07495887889637749     Test_loss = 0.12927418794277615\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "439 Train_loss = 0.07492684952184715     Test_loss = 0.12925363743050955\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "440 Train_loss = 0.07489488480574827     Test_loss = 0.1292319509283003\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "441 Train_loss = 0.07486293080112513     Test_loss = 0.12921164948187733\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "442 Train_loss = 0.07483099826550857     Test_loss = 0.1291886873685467\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "443 Train_loss = 0.07479906430869442     Test_loss = 0.1291706785562162\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "444 Train_loss = 0.0747671354994833     Test_loss = 0.1291474626294811\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "445 Train_loss = 0.0747352620240843     Test_loss = 0.12912751363198\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "446 Train_loss = 0.07470340617031769     Test_loss = 0.12910564832569815\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "447 Train_loss = 0.0746715575354161     Test_loss = 0.12908534003914404\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "448 Train_loss = 0.07463975825932889     Test_loss = 0.1290642448265088\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "449 Train_loss = 0.07460794524270929     Test_loss = 0.12904335686266694\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "450 Train_loss = 0.07457611656806708     Test_loss = 0.12902326394261174\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "451 Train_loss = 0.07454433017820095     Test_loss = 0.12900053737219389\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "452 Train_loss = 0.07451260269528218     Test_loss = 0.12898135067110209\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "453 Train_loss = 0.07448085946925732     Test_loss = 0.12895882937010272\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "454 Train_loss = 0.07444911968391307     Test_loss = 0.12893971491429806\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "455 Train_loss = 0.07441741730114075     Test_loss = 0.12891766504872149\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "456 Train_loss = 0.0743857431410701     Test_loss = 0.12889771153079016\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "457 Train_loss = 0.07435409779420304     Test_loss = 0.1288753487218615\n",
            "\n",
            "Accuracy : 0.9622619047619048\n",
            "458 Train_loss = 0.07432245071936548     Test_loss = 0.12885583269893097\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "459 Train_loss = 0.07429081152785547     Test_loss = 0.12883347537062115\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "460 Train_loss = 0.07425914094445334     Test_loss = 0.12881346994668655\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "461 Train_loss = 0.07422754398685957     Test_loss = 0.12879139992262198\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "462 Train_loss = 0.07419595756546633     Test_loss = 0.12877106350692719\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "463 Train_loss = 0.07416440900696913     Test_loss = 0.12875032104971865\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "464 Train_loss = 0.07413282983649465     Test_loss = 0.12872890425840589\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "465 Train_loss = 0.0741012814429528     Test_loss = 0.1287081592807222\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "466 Train_loss = 0.07406976898548547     Test_loss = 0.12868705519974263\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "467 Train_loss = 0.07403825120301097     Test_loss = 0.12866535925541844\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "468 Train_loss = 0.07400678230799729     Test_loss = 0.12864482966770538\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "469 Train_loss = 0.07397529726134008     Test_loss = 0.1286220272659439\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "470 Train_loss = 0.07394383821086702     Test_loss = 0.128603174674497\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "471 Train_loss = 0.07391239786495987     Test_loss = 0.12858117406864977\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "472 Train_loss = 0.0738810039084761     Test_loss = 0.1285610075282924\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "473 Train_loss = 0.07384964107814625     Test_loss = 0.12853941763689625\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "474 Train_loss = 0.07381827746198694     Test_loss = 0.128519024779597\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "475 Train_loss = 0.07378695840692255     Test_loss = 0.12849561916174995\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "476 Train_loss = 0.07375562280614437     Test_loss = 0.12847670945308354\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "477 Train_loss = 0.07372433620359069     Test_loss = 0.12845499824023632\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "478 Train_loss = 0.07369306442108021     Test_loss = 0.12843475127741474\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "479 Train_loss = 0.07366180770733262     Test_loss = 0.12841376209123354\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "480 Train_loss = 0.0736305792019889     Test_loss = 0.12839253575216633\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "481 Train_loss = 0.07359935476329943     Test_loss = 0.1283716903492993\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "482 Train_loss = 0.07356815104321668     Test_loss = 0.12835114187732707\n",
            "\n",
            "Accuracy : 0.9623809523809523\n",
            "483 Train_loss = 0.07353697900962695     Test_loss = 0.12833147180129822\n",
            "\n",
            "Accuracy : 0.9625\n",
            "484 Train_loss = 0.07350584033142257     Test_loss = 0.1283083603341541\n",
            "\n",
            "Accuracy : 0.9625\n",
            "485 Train_loss = 0.07347469650547404     Test_loss = 0.12828978861096613\n",
            "\n",
            "Accuracy : 0.9625\n",
            "486 Train_loss = 0.07344361406614246     Test_loss = 0.12826662761852892\n",
            "\n",
            "Accuracy : 0.9625\n",
            "487 Train_loss = 0.07341252840415298     Test_loss = 0.12824891972169514\n",
            "\n",
            "Accuracy : 0.9625\n",
            "488 Train_loss = 0.07338146273801822     Test_loss = 0.1282272976990299\n",
            "\n",
            "Accuracy : 0.9625\n",
            "489 Train_loss = 0.07335040871154795     Test_loss = 0.12820647064670757\n",
            "\n",
            "Accuracy : 0.9625\n",
            "490 Train_loss = 0.07331936863254004     Test_loss = 0.1281861831827807\n",
            "\n",
            "Accuracy : 0.9625\n",
            "491 Train_loss = 0.07328831275526808     Test_loss = 0.12816658349098153\n",
            "\n",
            "Accuracy : 0.9625\n",
            "492 Train_loss = 0.07325727802105614     Test_loss = 0.1281448508385136\n",
            "\n",
            "Accuracy : 0.9625\n",
            "493 Train_loss = 0.07322625355560436     Test_loss = 0.12812554394883402\n",
            "\n",
            "Accuracy : 0.9625\n",
            "494 Train_loss = 0.07319526766136118     Test_loss = 0.12810376673247795\n",
            "\n",
            "Accuracy : 0.9625\n",
            "495 Train_loss = 0.07316429466599055     Test_loss = 0.1280835834769137\n",
            "\n",
            "Accuracy : 0.9625\n",
            "496 Train_loss = 0.07313334186321839     Test_loss = 0.128064299656336\n",
            "\n",
            "Accuracy : 0.9625\n",
            "497 Train_loss = 0.07310240917703857     Test_loss = 0.12804165247501226\n",
            "\n",
            "Accuracy : 0.9625\n",
            "498 Train_loss = 0.07307148072310934     Test_loss = 0.12802209832823674\n",
            "\n",
            "Accuracy : 0.9625\n",
            "499 Train_loss = 0.07304057678042303     Test_loss = 0.1280017252911837\n",
            "\n",
            "Accuracy : 0.9625\n",
            "500 Train_loss = 0.07300971367659555     Test_loss = 0.12798083893105397\n",
            "\n",
            "Accuracy : 0.9625\n",
            "501 Train_loss = 0.07297882560192255     Test_loss = 0.12796004063537844\n",
            "\n",
            "Accuracy : 0.9625\n",
            "502 Train_loss = 0.07294796284293549     Test_loss = 0.1279395628518626\n",
            "\n",
            "Accuracy : 0.9625\n",
            "503 Train_loss = 0.07291714833817764     Test_loss = 0.1279197005991878\n",
            "\n",
            "Accuracy : 0.9625\n",
            "504 Train_loss = 0.0728863252985024     Test_loss = 0.1278990073644424\n",
            "\n",
            "Accuracy : 0.9625\n",
            "505 Train_loss = 0.07285554113831338     Test_loss = 0.1278785625617405\n",
            "\n",
            "Accuracy : 0.9625\n",
            "506 Train_loss = 0.07282474542062203     Test_loss = 0.1278583902114718\n",
            "\n",
            "Accuracy : 0.9625\n",
            "507 Train_loss = 0.07279400303368702     Test_loss = 0.12783683026292514\n",
            "\n",
            "Accuracy : 0.9625\n",
            "508 Train_loss = 0.07276322083518712     Test_loss = 0.12781903985667792\n",
            "\n",
            "Accuracy : 0.9625\n",
            "509 Train_loss = 0.0727324689227606     Test_loss = 0.12779664779380345\n",
            "\n",
            "Accuracy : 0.9625\n",
            "510 Train_loss = 0.07270173690905474     Test_loss = 0.1277775326761259\n",
            "\n",
            "Accuracy : 0.9625\n",
            "511 Train_loss = 0.07267107509513183     Test_loss = 0.12775715325934683\n",
            "\n",
            "Accuracy : 0.9625\n",
            "512 Train_loss = 0.07264032644919295     Test_loss = 0.12773529205640838\n",
            "\n",
            "Accuracy : 0.9625\n",
            "513 Train_loss = 0.07260963700392813     Test_loss = 0.12771592997003964\n",
            "\n",
            "Accuracy : 0.9625\n",
            "514 Train_loss = 0.07257896587592479     Test_loss = 0.12769607753921117\n",
            "\n",
            "Accuracy : 0.9625\n",
            "515 Train_loss = 0.07254831575360121     Test_loss = 0.12767443606793524\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "516 Train_loss = 0.07251766575878753     Test_loss = 0.12765527317342362\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "517 Train_loss = 0.07248707046590469     Test_loss = 0.12763492964407205\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "518 Train_loss = 0.07245646417930568     Test_loss = 0.1276159440307141\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "519 Train_loss = 0.07242587916079696     Test_loss = 0.12759469743660748\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "520 Train_loss = 0.07239529682131508     Test_loss = 0.127575472996049\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "521 Train_loss = 0.07236474865752225     Test_loss = 0.12755353049125068\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "522 Train_loss = 0.07233420174103505     Test_loss = 0.12753642431952872\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "523 Train_loss = 0.07230370019430464     Test_loss = 0.1275140616695079\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "524 Train_loss = 0.07227316882556639     Test_loss = 0.12749654108712047\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "525 Train_loss = 0.07224269486455746     Test_loss = 0.1274745824903988\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "526 Train_loss = 0.07221221545831437     Test_loss = 0.12745478303071467\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "527 Train_loss = 0.07218175210439748     Test_loss = 0.1274357886564132\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "528 Train_loss = 0.07215132741477923     Test_loss = 0.12741562411793256\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "529 Train_loss = 0.07212091581000202     Test_loss = 0.12739566385066417\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "530 Train_loss = 0.07209054716423985     Test_loss = 0.12737631705813915\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "531 Train_loss = 0.07206015248163503     Test_loss = 0.1273556785489375\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "532 Train_loss = 0.07202979149882847     Test_loss = 0.12733720924131656\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "533 Train_loss = 0.07199947171639871     Test_loss = 0.12731561501954816\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "534 Train_loss = 0.07196913684562697     Test_loss = 0.1272974240743454\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "535 Train_loss = 0.07193883059921166     Test_loss = 0.12727679995926225\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "536 Train_loss = 0.07190857738473337     Test_loss = 0.12725750193455404\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "537 Train_loss = 0.07187831434667508     Test_loss = 0.12723710679926234\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "538 Train_loss = 0.07184806928948193     Test_loss = 0.12721894182134058\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "539 Train_loss = 0.07181782111657628     Test_loss = 0.12719684103768175\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "540 Train_loss = 0.07178759079790478     Test_loss = 0.12717919041267225\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "541 Train_loss = 0.07175735121779067     Test_loss = 0.12715804816156673\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "542 Train_loss = 0.07172713041291709     Test_loss = 0.12713986608546038\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "543 Train_loss = 0.07169693125476644     Test_loss = 0.12711948176773125\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "544 Train_loss = 0.07166675366029311     Test_loss = 0.12709951174964174\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "545 Train_loss = 0.07163661364647958     Test_loss = 0.12708077442725732\n",
            "\n",
            "Accuracy : 0.9626190476190476\n",
            "546 Train_loss = 0.07160649442921808     Test_loss = 0.12706067564699117\n",
            "\n",
            "Accuracy : 0.9627380952380953\n",
            "547 Train_loss = 0.07157636754549293     Test_loss = 0.127041266942334\n",
            "\n",
            "Accuracy : 0.9627380952380953\n",
            "548 Train_loss = 0.07154627638738555     Test_loss = 0.12702192878718369\n",
            "\n",
            "Accuracy : 0.9627380952380953\n",
            "549 Train_loss = 0.0715161736041433     Test_loss = 0.12700102060374044\n",
            "\n",
            "Accuracy : 0.9627380952380953\n",
            "550 Train_loss = 0.07148610216375431     Test_loss = 0.12698233298677877\n",
            "\n",
            "Accuracy : 0.9627380952380953\n",
            "551 Train_loss = 0.0714560520795955     Test_loss = 0.1269621702039731\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "552 Train_loss = 0.07142602035389706     Test_loss = 0.12694196296922589\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "553 Train_loss = 0.07139597259010722     Test_loss = 0.12692348185230412\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "554 Train_loss = 0.07136598491512676     Test_loss = 0.1269018241943949\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "555 Train_loss = 0.07133597628224855     Test_loss = 0.12688495359364838\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "556 Train_loss = 0.07130603262130022     Test_loss = 0.12686315980529528\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "557 Train_loss = 0.07127606735726927     Test_loss = 0.12684598589132548\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "558 Train_loss = 0.07124613410509294     Test_loss = 0.12682422504616603\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "559 Train_loss = 0.07121620229990999     Test_loss = 0.12680718858470863\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "560 Train_loss = 0.07118629163890891     Test_loss = 0.1267861736082631\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "561 Train_loss = 0.07115640153597527     Test_loss = 0.12676757768776445\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "562 Train_loss = 0.07112654865849663     Test_loss = 0.12674755204558807\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "563 Train_loss = 0.07109669943418417     Test_loss = 0.1267290986758034\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "564 Train_loss = 0.0710668707610376     Test_loss = 0.12670947030854793\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "565 Train_loss = 0.07103703506853842     Test_loss = 0.12669013907016907\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "566 Train_loss = 0.07100722609549753     Test_loss = 0.12667088319277042\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "567 Train_loss = 0.07097744853646774     Test_loss = 0.12665049458095765\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "568 Train_loss = 0.0709476895114535     Test_loss = 0.12663315959017274\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "569 Train_loss = 0.07091791720135618     Test_loss = 0.12661246613552152\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "570 Train_loss = 0.07088818118980743     Test_loss = 0.12659467239909716\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "571 Train_loss = 0.07085841555016371     Test_loss = 0.12657311115030048\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "572 Train_loss = 0.07082869728446411     Test_loss = 0.126556264623819\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "573 Train_loss = 0.07079899259811691     Test_loss = 0.12653582046758138\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "574 Train_loss = 0.07076929538264422     Test_loss = 0.1265171582532178\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "575 Train_loss = 0.07073963975351458     Test_loss = 0.12649640815976676\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "576 Train_loss = 0.07071000414745005     Test_loss = 0.1264793118450873\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "577 Train_loss = 0.07068035108420286     Test_loss = 0.12645979586110712\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "578 Train_loss = 0.0706507610431224     Test_loss = 0.12644101578221686\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "579 Train_loss = 0.07062113700369389     Test_loss = 0.12642210163015027\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "580 Train_loss = 0.07059158554079961     Test_loss = 0.12640231690976736\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "581 Train_loss = 0.07056200741755946     Test_loss = 0.12638598629002626\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "582 Train_loss = 0.07053243040694844     Test_loss = 0.1263641469613183\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "583 Train_loss = 0.07050286487921917     Test_loss = 0.1263475623195094\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "584 Train_loss = 0.07047336933555107     Test_loss = 0.12632654429975776\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "585 Train_loss = 0.07044383356029695     Test_loss = 0.12631012374560613\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "586 Train_loss = 0.07041433512461304     Test_loss = 0.12628910285857617\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "587 Train_loss = 0.07038483639867006     Test_loss = 0.1262719466129183\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "588 Train_loss = 0.07035535117581532     Test_loss = 0.12625030766784626\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "589 Train_loss = 0.07032586973843497     Test_loss = 0.12623457272173383\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "590 Train_loss = 0.0702964468392626     Test_loss = 0.12621406073328192\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "591 Train_loss = 0.07026703852077061     Test_loss = 0.12619664617441223\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "592 Train_loss = 0.07023763862927415     Test_loss = 0.1261753415046074\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "593 Train_loss = 0.07020828218162259     Test_loss = 0.12615830347975712\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "594 Train_loss = 0.07017889232640553     Test_loss = 0.12613846264436984\n",
            "\n",
            "Accuracy : 0.9628571428571429\n",
            "595 Train_loss = 0.07014954912355184     Test_loss = 0.12612090991956618\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "596 Train_loss = 0.07012024623197026     Test_loss = 0.12610158653167397\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "597 Train_loss = 0.07009091113631487     Test_loss = 0.12608361922522318\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "598 Train_loss = 0.0700616102714806     Test_loss = 0.12606587886003168\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "599 Train_loss = 0.07003233897358219     Test_loss = 0.12604646315181775\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "600 Train_loss = 0.07000305936428691     Test_loss = 0.12602853218188773\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "601 Train_loss = 0.06997379619137059     Test_loss = 0.12600899387142292\n",
            "\n",
            "Accuracy : 0.9629761904761904\n",
            "602 Train_loss = 0.06994459300062883     Test_loss = 0.12599175843715693\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "603 Train_loss = 0.06991538617333537     Test_loss = 0.1259723064753684\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "604 Train_loss = 0.0698861862357804     Test_loss = 0.12595511889244235\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "605 Train_loss = 0.06985704033699645     Test_loss = 0.12593544469775725\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "606 Train_loss = 0.06982785641617623     Test_loss = 0.12591831113062107\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "607 Train_loss = 0.06979874136074432     Test_loss = 0.1258980100023625\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "608 Train_loss = 0.06976962203080274     Test_loss = 0.1258816827929893\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "609 Train_loss = 0.06974051238104176     Test_loss = 0.12586224204186713\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "610 Train_loss = 0.06971141831791773     Test_loss = 0.12584436241759253\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "611 Train_loss = 0.06968235331830597     Test_loss = 0.1258244785287464\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "612 Train_loss = 0.06965331478022949     Test_loss = 0.12580822391552848\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "613 Train_loss = 0.06962427709486384     Test_loss = 0.12578762909284313\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "614 Train_loss = 0.06959525869781767     Test_loss = 0.12577118246275437\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "615 Train_loss = 0.06956623459197642     Test_loss = 0.12575161949316674\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "616 Train_loss = 0.0695372535350343     Test_loss = 0.1257341965107473\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "617 Train_loss = 0.0695082975808945     Test_loss = 0.12571542737701646\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "618 Train_loss = 0.06947937281064874     Test_loss = 0.12569776817244485\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "619 Train_loss = 0.06945045227807063     Test_loss = 0.12567865598179614\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "620 Train_loss = 0.06942152864013827     Test_loss = 0.1256612181281097\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "621 Train_loss = 0.06939269034965792     Test_loss = 0.12564167036814586\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "622 Train_loss = 0.0693638257255936     Test_loss = 0.1256252169588541\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "623 Train_loss = 0.0693349650480286     Test_loss = 0.1256059331308952\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "624 Train_loss = 0.0693061109395511     Test_loss = 0.1255876300286711\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "625 Train_loss = 0.06927730153024306     Test_loss = 0.12556915742888816\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "626 Train_loss = 0.06924854283557977     Test_loss = 0.12555202330828139\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "627 Train_loss = 0.0692197332620392     Test_loss = 0.125533066752548\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "628 Train_loss = 0.06919093630430237     Test_loss = 0.12551488010310044\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "629 Train_loss = 0.06916219413401643     Test_loss = 0.12549611649478193\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "630 Train_loss = 0.06913345961487148     Test_loss = 0.1254792081895528\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "631 Train_loss = 0.06910472269827402     Test_loss = 0.12545881850919724\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "632 Train_loss = 0.06907601575631807     Test_loss = 0.1254420921127578\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "633 Train_loss = 0.06904733888173696     Test_loss = 0.1254228853939709\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "634 Train_loss = 0.06901868216107454     Test_loss = 0.12540527267798118\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "635 Train_loss = 0.0689900714505083     Test_loss = 0.12538694075968876\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "636 Train_loss = 0.06896144668363118     Test_loss = 0.1253692634210433\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "637 Train_loss = 0.06893285738116442     Test_loss = 0.12534885260135814\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "638 Train_loss = 0.06890425628505967     Test_loss = 0.12533444706988622\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "639 Train_loss = 0.06887572302957568     Test_loss = 0.12531288173667268\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "640 Train_loss = 0.0688471667254809     Test_loss = 0.12529804427104388\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "641 Train_loss = 0.06881863192327682     Test_loss = 0.12527749617678086\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "642 Train_loss = 0.06879010008663958     Test_loss = 0.1252610939732568\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "643 Train_loss = 0.0687616246212847     Test_loss = 0.12524290448645536\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "644 Train_loss = 0.06873319886932015     Test_loss = 0.12522608519822437\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "645 Train_loss = 0.06870473655808605     Test_loss = 0.12520680532464873\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "646 Train_loss = 0.06867629268368955     Test_loss = 0.12518985449215891\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "647 Train_loss = 0.0686478841719926     Test_loss = 0.1251702563385901\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "648 Train_loss = 0.06861950302097786     Test_loss = 0.12515403466755187\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "649 Train_loss = 0.06859110377186561     Test_loss = 0.12513590124055365\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "650 Train_loss = 0.06856271006391426     Test_loss = 0.12511723192534993\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "651 Train_loss = 0.06853437955142358     Test_loss = 0.12509886429361872\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "652 Train_loss = 0.0685060172360718     Test_loss = 0.12508335346343585\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "653 Train_loss = 0.06847764899082265     Test_loss = 0.1250623344092082\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "654 Train_loss = 0.06844932165435742     Test_loss = 0.12504674600761187\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "655 Train_loss = 0.06842100531375563     Test_loss = 0.12502632116265291\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "656 Train_loss = 0.06839273314951186     Test_loss = 0.12501162922435616\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "657 Train_loss = 0.06836449118246313     Test_loss = 0.12499087795680967\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "658 Train_loss = 0.06833623194427438     Test_loss = 0.12497443773445384\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "659 Train_loss = 0.06830796973632275     Test_loss = 0.12495554165468126\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "660 Train_loss = 0.06827974163685621     Test_loss = 0.12493916020432215\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "661 Train_loss = 0.06825155685813797     Test_loss = 0.12492017594294931\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "662 Train_loss = 0.06822338185724877     Test_loss = 0.12490355385013337\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "663 Train_loss = 0.06819521266019206     Test_loss = 0.12488425100638624\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "664 Train_loss = 0.06816705758332021     Test_loss = 0.12486830623929467\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "665 Train_loss = 0.06813891462683666     Test_loss = 0.12484849450850785\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "666 Train_loss = 0.06811081328751521     Test_loss = 0.12483299938910031\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "667 Train_loss = 0.06808271561465898     Test_loss = 0.12481359296537792\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "668 Train_loss = 0.06805468294730738     Test_loss = 0.1247964181433696\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "669 Train_loss = 0.06802662578953228     Test_loss = 0.12477846916834326\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "670 Train_loss = 0.06799856894232993     Test_loss = 0.12476145946169473\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "671 Train_loss = 0.06797054869422621     Test_loss = 0.1247437413891585\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "672 Train_loss = 0.06794252963471062     Test_loss = 0.12472589622529524\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "673 Train_loss = 0.06791451643552468     Test_loss = 0.12470837813519173\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "674 Train_loss = 0.06788655021442999     Test_loss = 0.12469080365209728\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "675 Train_loss = 0.06785858047640629     Test_loss = 0.1246730485694934\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "676 Train_loss = 0.06783063976144946     Test_loss = 0.12465551259665593\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "677 Train_loss = 0.06780272837419442     Test_loss = 0.12463687137667266\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "678 Train_loss = 0.06777480774309448     Test_loss = 0.12461893935605227\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "679 Train_loss = 0.0677469101094209     Test_loss = 0.12460273650870539\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "680 Train_loss = 0.06771903166999024     Test_loss = 0.12458527682776199\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "681 Train_loss = 0.06769116177486063     Test_loss = 0.1245669450322689\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "682 Train_loss = 0.06766330307959953     Test_loss = 0.12454973423861447\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "683 Train_loss = 0.06763544320113421     Test_loss = 0.12453144525797015\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "684 Train_loss = 0.06760763349961216     Test_loss = 0.12451471193379172\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "685 Train_loss = 0.06757981145216686     Test_loss = 0.12449630574241956\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "686 Train_loss = 0.06755198155361575     Test_loss = 0.12447878896821783\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "687 Train_loss = 0.06752419466921998     Test_loss = 0.1244628331285294\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "688 Train_loss = 0.06749639969890259     Test_loss = 0.12444503584192156\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "689 Train_loss = 0.06746865199845385     Test_loss = 0.1244267620169003\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "690 Train_loss = 0.0674408568655907     Test_loss = 0.12440960769657279\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "691 Train_loss = 0.06741313892410157     Test_loss = 0.12439299215165787\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "692 Train_loss = 0.06738541850793861     Test_loss = 0.1243737077784341\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "693 Train_loss = 0.06735771688007652     Test_loss = 0.12435753073001644\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "694 Train_loss = 0.0673300290768567     Test_loss = 0.12434037492927151\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "695 Train_loss = 0.06730236385008725     Test_loss = 0.12432252546601127\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "696 Train_loss = 0.06727472424057489     Test_loss = 0.12430532568536189\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "697 Train_loss = 0.06724708962482064     Test_loss = 0.1242893583772311\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "698 Train_loss = 0.0672194809432951     Test_loss = 0.12427063365123678\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "699 Train_loss = 0.06719187533736437     Test_loss = 0.12425502292080555\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "700 Train_loss = 0.06716429795303426     Test_loss = 0.12423629867777436\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "701 Train_loss = 0.06713671903935546     Test_loss = 0.12421967758733954\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "702 Train_loss = 0.06710915250223633     Test_loss = 0.12420326178496725\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "703 Train_loss = 0.06708162433204216     Test_loss = 0.12418652201215531\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "704 Train_loss = 0.06705410175944969     Test_loss = 0.12417000156142302\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "705 Train_loss = 0.06702656248644119     Test_loss = 0.12415217035632728\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "706 Train_loss = 0.06699906126174549     Test_loss = 0.12413545922189902\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "707 Train_loss = 0.06697157552783493     Test_loss = 0.12411857745560377\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "708 Train_loss = 0.06694408948543834     Test_loss = 0.12410206812089257\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "709 Train_loss = 0.0669166584456993     Test_loss = 0.12408497724965666\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "710 Train_loss = 0.06688922594772359     Test_loss = 0.12406662137929014\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "711 Train_loss = 0.06686181607529852     Test_loss = 0.12405001523908703\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "712 Train_loss = 0.06683443520516642     Test_loss = 0.12403286066168821\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "713 Train_loss = 0.06680706815617186     Test_loss = 0.12401650365470292\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "714 Train_loss = 0.06677972906949999     Test_loss = 0.12399950840766107\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "715 Train_loss = 0.06675236517060042     Test_loss = 0.12398230973384639\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "716 Train_loss = 0.06672497038535592     Test_loss = 0.12396536801108855\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "717 Train_loss = 0.06669762328302463     Test_loss = 0.12394891741512824\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "718 Train_loss = 0.06667029059703573     Test_loss = 0.12393200754519877\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "719 Train_loss = 0.06664298260039953     Test_loss = 0.1239143353401427\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "720 Train_loss = 0.06661564474098666     Test_loss = 0.12389743763970852\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "721 Train_loss = 0.06658834675081908     Test_loss = 0.12388099445347031\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "722 Train_loss = 0.06656103094093842     Test_loss = 0.12386549509130358\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "723 Train_loss = 0.06653374112105663     Test_loss = 0.12384760925253087\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "724 Train_loss = 0.06650647266173322     Test_loss = 0.12383160115614243\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "725 Train_loss = 0.0664792141276747     Test_loss = 0.12381404950019027\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "726 Train_loss = 0.06645201760655056     Test_loss = 0.12379803620448261\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "727 Train_loss = 0.06642480327750351     Test_loss = 0.12377978843501228\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "728 Train_loss = 0.06639764749489188     Test_loss = 0.12376428139550723\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "729 Train_loss = 0.066370446399682     Test_loss = 0.12374562470097125\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "730 Train_loss = 0.06634333443597382     Test_loss = 0.12372926422547266\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "731 Train_loss = 0.06631618012633361     Test_loss = 0.12371392950401476\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "732 Train_loss = 0.06628905712146546     Test_loss = 0.12369543784563464\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "733 Train_loss = 0.06626196161328667     Test_loss = 0.12367915887474572\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "734 Train_loss = 0.06623487832404337     Test_loss = 0.12366140976680987\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "735 Train_loss = 0.06620783138598642     Test_loss = 0.1236460385843975\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "736 Train_loss = 0.06618077824560226     Test_loss = 0.12362724166849283\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "737 Train_loss = 0.06615371986915289     Test_loss = 0.12361176303852725\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "738 Train_loss = 0.06612669350960912     Test_loss = 0.12359357580649771\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "739 Train_loss = 0.06609968604445765     Test_loss = 0.12357839883376803\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "740 Train_loss = 0.0660726712523875     Test_loss = 0.12356018128426564\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "741 Train_loss = 0.06604568397449254     Test_loss = 0.12354409202482824\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "742 Train_loss = 0.06601875550525983     Test_loss = 0.12352720878639359\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "743 Train_loss = 0.06599182999051938     Test_loss = 0.12351026125915358\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "744 Train_loss = 0.06596485398873751     Test_loss = 0.12349208838780447\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "745 Train_loss = 0.06593788932383107     Test_loss = 0.12347603871619199\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "746 Train_loss = 0.0659109661213696     Test_loss = 0.12346029916680216\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "747 Train_loss = 0.06588406570046304     Test_loss = 0.12344271210261336\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "748 Train_loss = 0.06585716415729322     Test_loss = 0.1234252828480885\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "749 Train_loss = 0.065830289690223     Test_loss = 0.12340974035016637\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "750 Train_loss = 0.06580342299748757     Test_loss = 0.12339170569963788\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "751 Train_loss = 0.06577656808320885     Test_loss = 0.12337741149673223\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "752 Train_loss = 0.06574977498728377     Test_loss = 0.1233590766041319\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "753 Train_loss = 0.0657229445796405     Test_loss = 0.12334243951947742\n",
            "\n",
            "Accuracy : 0.9630952380952381\n",
            "754 Train_loss = 0.0656961256946522     Test_loss = 0.12332587689401746\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "755 Train_loss = 0.06566932118727017     Test_loss = 0.1233097470446758\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "756 Train_loss = 0.06564254458734413     Test_loss = 0.12329241594969127\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "757 Train_loss = 0.06561577556393552     Test_loss = 0.12327562728334493\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "758 Train_loss = 0.06558905536719048     Test_loss = 0.12325947281189414\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "759 Train_loss = 0.06556229928944617     Test_loss = 0.12324202443429594\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "760 Train_loss = 0.06553558140837887     Test_loss = 0.12322656273041811\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "761 Train_loss = 0.06550887714320427     Test_loss = 0.1232091298719724\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "762 Train_loss = 0.06548212578916071     Test_loss = 0.12319193450476865\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "763 Train_loss = 0.06545542013643646     Test_loss = 0.12317519954185746\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "764 Train_loss = 0.0654287262533809     Test_loss = 0.12315844394246973\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "765 Train_loss = 0.06540206015168305     Test_loss = 0.12314208056991648\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "766 Train_loss = 0.06537539394247016     Test_loss = 0.12312355475495744\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "767 Train_loss = 0.06534874105764968     Test_loss = 0.12310721730319645\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "768 Train_loss = 0.06532209747034919     Test_loss = 0.1230914484894918\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "769 Train_loss = 0.0652954890272976     Test_loss = 0.12307482581139176\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "770 Train_loss = 0.06526888376932308     Test_loss = 0.12305726905536918\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "771 Train_loss = 0.06524228048268604     Test_loss = 0.12304007776154295\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "772 Train_loss = 0.06521569699397461     Test_loss = 0.12302364488441908\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "773 Train_loss = 0.06518910683052394     Test_loss = 0.12300745993689531\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "774 Train_loss = 0.06516254599785785     Test_loss = 0.12298961037449212\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "775 Train_loss = 0.06513599810099883     Test_loss = 0.12297341345295348\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "776 Train_loss = 0.06510943805013218     Test_loss = 0.12295565974083615\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "777 Train_loss = 0.0650828962781501     Test_loss = 0.12294036080052569\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "778 Train_loss = 0.06505634740100776     Test_loss = 0.12292375085792631\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "779 Train_loss = 0.06502987064463393     Test_loss = 0.12290575640399425\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "780 Train_loss = 0.0650033636066862     Test_loss = 0.12289075325176087\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "781 Train_loss = 0.06497685429210276     Test_loss = 0.12287413734405263\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "782 Train_loss = 0.06495039045148097     Test_loss = 0.12285634462209351\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "783 Train_loss = 0.06492392941618887     Test_loss = 0.12283933211433352\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "784 Train_loss = 0.064897489992361     Test_loss = 0.12282372605491636\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "785 Train_loss = 0.0648710454391692     Test_loss = 0.12280638640140742\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "786 Train_loss = 0.06484462598621887     Test_loss = 0.12279047816106299\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "787 Train_loss = 0.06481820638288685     Test_loss = 0.12277239563444092\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "788 Train_loss = 0.06479180413701306     Test_loss = 0.12275659942501661\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "789 Train_loss = 0.06476542060499867     Test_loss = 0.12274011323039945\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "790 Train_loss = 0.06473907350889613     Test_loss = 0.12272211135891263\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "791 Train_loss = 0.06471271239887713     Test_loss = 0.12270620814891578\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "792 Train_loss = 0.06468635738583069     Test_loss = 0.12268927855136355\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "793 Train_loss = 0.06466002997214922     Test_loss = 0.12267381477942035\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "794 Train_loss = 0.06463372420861162     Test_loss = 0.12265551694986881\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "795 Train_loss = 0.06460744914710258     Test_loss = 0.12263880561631121\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "796 Train_loss = 0.06458115802379781     Test_loss = 0.12262310015718897\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "797 Train_loss = 0.06455490887517056     Test_loss = 0.12260685806159835\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "798 Train_loss = 0.06452867806348232     Test_loss = 0.12259004072762886\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "799 Train_loss = 0.06450244757647286     Test_loss = 0.12257539318715498\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "800 Train_loss = 0.06447618521482747     Test_loss = 0.12255759088880452\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "801 Train_loss = 0.06444995780205372     Test_loss = 0.12254243789518222\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "802 Train_loss = 0.0644237515973716     Test_loss = 0.12252503278414154\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "803 Train_loss = 0.06439756368675272     Test_loss = 0.12251001729222383\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "804 Train_loss = 0.06437137405081181     Test_loss = 0.12249234508353449\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "805 Train_loss = 0.06434518575542195     Test_loss = 0.12247722821704872\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "806 Train_loss = 0.06431904071574997     Test_loss = 0.12246032657588841\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "807 Train_loss = 0.06429289225111817     Test_loss = 0.122444122829728\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "808 Train_loss = 0.06426676468318225     Test_loss = 0.12242762610029816\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "809 Train_loss = 0.06424062877589377     Test_loss = 0.12241166300254357\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "810 Train_loss = 0.06421449979542793     Test_loss = 0.12239590634035467\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "811 Train_loss = 0.06418837273103443     Test_loss = 0.12237877025276554\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "812 Train_loss = 0.0641622912243287     Test_loss = 0.12236378133744105\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "813 Train_loss = 0.0641362120907507     Test_loss = 0.12234726081050477\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "814 Train_loss = 0.06411013893611461     Test_loss = 0.12232964223485789\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "815 Train_loss = 0.06408407477286981     Test_loss = 0.1223135289595619\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "816 Train_loss = 0.06405801457085476     Test_loss = 0.12229890683816991\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "817 Train_loss = 0.0640319772191327     Test_loss = 0.12228247744766069\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "818 Train_loss = 0.06400594968328659     Test_loss = 0.12226535891228522\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "819 Train_loss = 0.06397993450059852     Test_loss = 0.12224949736463825\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "820 Train_loss = 0.063953918760559     Test_loss = 0.12223350465305077\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "821 Train_loss = 0.06392791717995039     Test_loss = 0.12221854548923873\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "822 Train_loss = 0.06390195035041525     Test_loss = 0.12220038138970586\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "823 Train_loss = 0.06387597543708574     Test_loss = 0.12218538448912354\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "824 Train_loss = 0.06385003520820069     Test_loss = 0.12216798024325685\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "825 Train_loss = 0.06382407404529301     Test_loss = 0.1221530109595141\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "826 Train_loss = 0.06379815537093213     Test_loss = 0.12213577232283664\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "827 Train_loss = 0.06377225459389631     Test_loss = 0.12211971065781416\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "828 Train_loss = 0.06374636814153373     Test_loss = 0.12210403340461196\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "829 Train_loss = 0.06372042065593002     Test_loss = 0.12208676271370669\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "830 Train_loss = 0.06369453907103281     Test_loss = 0.12207229763683612\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "831 Train_loss = 0.06366863237085829     Test_loss = 0.12205443465367748\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "832 Train_loss = 0.06364277032170156     Test_loss = 0.12203977221612003\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "833 Train_loss = 0.06361685288996781     Test_loss = 0.12202075524864224\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "834 Train_loss = 0.06359099460327372     Test_loss = 0.12200664420969823\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "835 Train_loss = 0.06356513349395085     Test_loss = 0.12198927108472106\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "836 Train_loss = 0.06353929213018462     Test_loss = 0.12197348562255253\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "837 Train_loss = 0.0635134827648761     Test_loss = 0.1219560268789675\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "838 Train_loss = 0.06348765131324763     Test_loss = 0.12194266941198748\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "839 Train_loss = 0.06346188417854158     Test_loss = 0.12192439376770664\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "840 Train_loss = 0.06343607547165436     Test_loss = 0.12190937787925915\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "841 Train_loss = 0.06341032253002878     Test_loss = 0.12189319212822071\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "842 Train_loss = 0.06338457011207378     Test_loss = 0.12187611302279541\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "843 Train_loss = 0.06335881314613472     Test_loss = 0.12186089417445263\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "844 Train_loss = 0.06333309250266636     Test_loss = 0.12184380557311653\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "845 Train_loss = 0.06330739468137579     Test_loss = 0.12182731764462595\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "846 Train_loss = 0.06328170514452128     Test_loss = 0.12181134240836179\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "847 Train_loss = 0.06325601217256496     Test_loss = 0.12179495057410798\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "848 Train_loss = 0.06323033684056313     Test_loss = 0.12178017616132793\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "849 Train_loss = 0.06320470557275941     Test_loss = 0.12176335151640104\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "850 Train_loss = 0.0631790410151159     Test_loss = 0.12174715750092688\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "851 Train_loss = 0.06315345693663664     Test_loss = 0.12173161519112481\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "852 Train_loss = 0.06312782004502572     Test_loss = 0.12171529449582935\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "853 Train_loss = 0.06310221054299735     Test_loss = 0.12169903504330781\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "854 Train_loss = 0.06307665329762253     Test_loss = 0.12168347840591807\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "855 Train_loss = 0.06305107501045801     Test_loss = 0.1216671734829078\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "856 Train_loss = 0.06302553477181896     Test_loss = 0.12165258824117467\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "857 Train_loss = 0.06299999642659684     Test_loss = 0.1216355289754234\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "858 Train_loss = 0.06297447696708278     Test_loss = 0.12162004656720188\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "859 Train_loss = 0.06294899230570565     Test_loss = 0.12160496989464831\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "860 Train_loss = 0.06292348064164426     Test_loss = 0.12158807545059962\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "861 Train_loss = 0.06289802412113193     Test_loss = 0.12157332108628274\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "862 Train_loss = 0.06287255873982517     Test_loss = 0.1215570451414448\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "863 Train_loss = 0.06284711724517987     Test_loss = 0.12154153749000352\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "864 Train_loss = 0.06282167680218076     Test_loss = 0.12152632416118236\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "865 Train_loss = 0.06279627212116985     Test_loss = 0.12150845664654511\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "866 Train_loss = 0.06277084375549871     Test_loss = 0.12149402635551561\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "867 Train_loss = 0.06274544070746207     Test_loss = 0.12147840313025218\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "868 Train_loss = 0.06272006830304903     Test_loss = 0.12146281297773685\n",
            "\n",
            "Accuracy : 0.9632142857142857\n",
            "869 Train_loss = 0.06269468645317407     Test_loss = 0.12144621770839807\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "870 Train_loss = 0.0626693622154134     Test_loss = 0.12143102067566207\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "871 Train_loss = 0.06264403657923463     Test_loss = 0.12141499514886588\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "872 Train_loss = 0.06261871176214229     Test_loss = 0.12139915286608517\n",
            "\n",
            "Accuracy : 0.9633333333333334\n",
            "873 Train_loss = 0.06259339635105908     Test_loss = 0.12138177481416422\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "874 Train_loss = 0.06256812157730181     Test_loss = 0.12136719295499926\n",
            "\n",
            "Accuracy : 0.963452380952381\n",
            "875 Train_loss = 0.06254284921303675     Test_loss = 0.12135001408802654\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "876 Train_loss = 0.06251758804074546     Test_loss = 0.12133756446961502\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "877 Train_loss = 0.06249234125432175     Test_loss = 0.12131814272716657\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "878 Train_loss = 0.06246710008019937     Test_loss = 0.12130422911919832\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "879 Train_loss = 0.0624418587256359     Test_loss = 0.12128672080657697\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "880 Train_loss = 0.062416649897082926     Test_loss = 0.12127237437305327\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "881 Train_loss = 0.06239140877283181     Test_loss = 0.12125741753601722\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "882 Train_loss = 0.06236624822592929     Test_loss = 0.12123986314235179\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "883 Train_loss = 0.062341028482429124     Test_loss = 0.12122521307121137\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "884 Train_loss = 0.062315872770493975     Test_loss = 0.12120908240588435\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "885 Train_loss = 0.062290713586481854     Test_loss = 0.12119354410651653\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "886 Train_loss = 0.062265575543553886     Test_loss = 0.1211792267989569\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "887 Train_loss = 0.062240462943642355     Test_loss = 0.12116124465695569\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "888 Train_loss = 0.062215308803422374     Test_loss = 0.12114727530273006\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "889 Train_loss = 0.062190203712701286     Test_loss = 0.12113096754772726\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "890 Train_loss = 0.06216510348913926     Test_loss = 0.1211139453302174\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "891 Train_loss = 0.06214003133373302     Test_loss = 0.12109965005453481\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "892 Train_loss = 0.06211492822884839     Test_loss = 0.12108474280719189\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "893 Train_loss = 0.062089874119507144     Test_loss = 0.12106694000961091\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "894 Train_loss = 0.06206482387669292     Test_loss = 0.12105281825433127\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "895 Train_loss = 0.062039790274759796     Test_loss = 0.12103664908988641\n",
            "\n",
            "Accuracy : 0.9635714285714285\n",
            "896 Train_loss = 0.06201474128846103     Test_loss = 0.12102062758660417\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "897 Train_loss = 0.06198974062795497     Test_loss = 0.1210046293953944\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "898 Train_loss = 0.06196470445898702     Test_loss = 0.12099045843451718\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "899 Train_loss = 0.061939712511502536     Test_loss = 0.1209743073294192\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "900 Train_loss = 0.06191471905714631     Test_loss = 0.12095810857659971\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "901 Train_loss = 0.061889730245494844     Test_loss = 0.1209435774456682\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "902 Train_loss = 0.061864753173954574     Test_loss = 0.12092592095829438\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "903 Train_loss = 0.0618398187659917     Test_loss = 0.12091142406949064\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "904 Train_loss = 0.06181487172480087     Test_loss = 0.12089517005758983\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "905 Train_loss = 0.06178996674819049     Test_loss = 0.12088169693764318\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "906 Train_loss = 0.06176506990902529     Test_loss = 0.12086402275008232\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "907 Train_loss = 0.06174017521120645     Test_loss = 0.12084957219658052\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "908 Train_loss = 0.06171531701321608     Test_loss = 0.12083277136120275\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "909 Train_loss = 0.06169045350716958     Test_loss = 0.12081992998838327\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "910 Train_loss = 0.06166560124997246     Test_loss = 0.12080359442983599\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "911 Train_loss = 0.061640734600415414     Test_loss = 0.12078764333642898\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "912 Train_loss = 0.061615917423819506     Test_loss = 0.12077141235979146\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "913 Train_loss = 0.06159108629923448     Test_loss = 0.12075885480412124\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "914 Train_loss = 0.06156625823569266     Test_loss = 0.12074239003473089\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "915 Train_loss = 0.06154142489560424     Test_loss = 0.12072697872034614\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "916 Train_loss = 0.061516651731073006     Test_loss = 0.12071265797444744\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "917 Train_loss = 0.06149188799047174     Test_loss = 0.1206978243828589\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "918 Train_loss = 0.061467111335713     Test_loss = 0.12068194766670463\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "919 Train_loss = 0.06144234795694219     Test_loss = 0.12066743397337772\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "920 Train_loss = 0.06141761159893473     Test_loss = 0.12065217357543144\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "921 Train_loss = 0.061392863387917905     Test_loss = 0.12063714737495727\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "922 Train_loss = 0.06136812582292497     Test_loss = 0.1206220925155933\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "923 Train_loss = 0.06134338136184617     Test_loss = 0.12060621094558224\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "924 Train_loss = 0.06131867799613673     Test_loss = 0.12059207178503359\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "925 Train_loss = 0.06129396728869811     Test_loss = 0.12057606932007471\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "926 Train_loss = 0.061269262037300896     Test_loss = 0.12056098458956278\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "927 Train_loss = 0.06124455913001047     Test_loss = 0.12054660285190816\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "928 Train_loss = 0.06121989600066852     Test_loss = 0.12053055107891611\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "929 Train_loss = 0.06119518746046815     Test_loss = 0.12051555130436728\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "930 Train_loss = 0.06117055099704659     Test_loss = 0.1205004036834268\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "931 Train_loss = 0.06114588643318783     Test_loss = 0.12048585425973242\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "932 Train_loss = 0.061121237325617375     Test_loss = 0.12047027256847725\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "933 Train_loss = 0.06109661035891608     Test_loss = 0.1204552740750267\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "934 Train_loss = 0.06107198809824394     Test_loss = 0.12044041287239844\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "935 Train_loss = 0.06104740267775101     Test_loss = 0.12042371230798724\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "936 Train_loss = 0.061022805211239664     Test_loss = 0.12040902524405979\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "937 Train_loss = 0.06099825183426371     Test_loss = 0.120395934517009\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "938 Train_loss = 0.060973695813282394     Test_loss = 0.12037917423532282\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "939 Train_loss = 0.06094911430572178     Test_loss = 0.12036532292313339\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "940 Train_loss = 0.060924562054337744     Test_loss = 0.1203485296413764\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "941 Train_loss = 0.06090000922683007     Test_loss = 0.12033557847867513\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "942 Train_loss = 0.060875411425364664     Test_loss = 0.12032022176381163\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "943 Train_loss = 0.060850832098351376     Test_loss = 0.12030448206817168\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "944 Train_loss = 0.06082626499970348     Test_loss = 0.12028976452824325\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "945 Train_loss = 0.060801732928155834     Test_loss = 0.12027563415863161\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "946 Train_loss = 0.06077716069322154     Test_loss = 0.12026047690626677\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "947 Train_loss = 0.06075265431638141     Test_loss = 0.12024399065754603\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "948 Train_loss = 0.060728140740699724     Test_loss = 0.12023106046859883\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "949 Train_loss = 0.06070362696702895     Test_loss = 0.12021560335865902\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "950 Train_loss = 0.06067916230943121     Test_loss = 0.12019990365013483\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "951 Train_loss = 0.06065469905231448     Test_loss = 0.12018509832316282\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "952 Train_loss = 0.0606302566423295     Test_loss = 0.12016928850119572\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "953 Train_loss = 0.06060582403245096     Test_loss = 0.1201545739107922\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "954 Train_loss = 0.06058141411904983     Test_loss = 0.1201393117106881\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "955 Train_loss = 0.0605570435746517     Test_loss = 0.1201240482465441\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "956 Train_loss = 0.06053267414006579     Test_loss = 0.12010858773763823\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "957 Train_loss = 0.06050830744987264     Test_loss = 0.1200948051835999\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "958 Train_loss = 0.060483940746339566     Test_loss = 0.12007933419278159\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "959 Train_loss = 0.06045964899715844     Test_loss = 0.12006389311218629\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "960 Train_loss = 0.06043530572315645     Test_loss = 0.1200492871465207\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "961 Train_loss = 0.06041101022971417     Test_loss = 0.12003503294105182\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "962 Train_loss = 0.06038673966357515     Test_loss = 0.1200203960103178\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "963 Train_loss = 0.06036249122021308     Test_loss = 0.1200050974222517\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "964 Train_loss = 0.060338231483635894     Test_loss = 0.1199900003773494\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "965 Train_loss = 0.060314003646559734     Test_loss = 0.11997531046936936\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "966 Train_loss = 0.0602897726789773     Test_loss = 0.11996032387228997\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "967 Train_loss = 0.06026554977294535     Test_loss = 0.1199470170585781\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "968 Train_loss = 0.060241337181630106     Test_loss = 0.11993218251809175\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "969 Train_loss = 0.06021714435109865     Test_loss = 0.11991614360331362\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "970 Train_loss = 0.060192924302999086     Test_loss = 0.11990263676839166\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "971 Train_loss = 0.06016875388481018     Test_loss = 0.11988682753858611\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "972 Train_loss = 0.060144635594442525     Test_loss = 0.11987355737679398\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "973 Train_loss = 0.06012045951987068     Test_loss = 0.11985729886962987\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "974 Train_loss = 0.060096301454550936     Test_loss = 0.1198430089048702\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "975 Train_loss = 0.06007219753794921     Test_loss = 0.11982896234350862\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "976 Train_loss = 0.06004806053530754     Test_loss = 0.11981262611272141\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "977 Train_loss = 0.060023943524347735     Test_loss = 0.11979869494307194\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "978 Train_loss = 0.05999985781974225     Test_loss = 0.11978368852250366\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "979 Train_loss = 0.059975772921301705     Test_loss = 0.11977088063090457\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "980 Train_loss = 0.059951691333580095     Test_loss = 0.11975365440567756\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "981 Train_loss = 0.05992758892046876     Test_loss = 0.11973928969446479\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "982 Train_loss = 0.059903520936757604     Test_loss = 0.11972493996420425\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "983 Train_loss = 0.05987950068933347     Test_loss = 0.1197100258332261\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "984 Train_loss = 0.05985545093103685     Test_loss = 0.11969704649567071\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "985 Train_loss = 0.05983144019770731     Test_loss = 0.11968052658748271\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "986 Train_loss = 0.059807414462012064     Test_loss = 0.11966583340599825\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "987 Train_loss = 0.05978333159287535     Test_loss = 0.11965079956643886\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "988 Train_loss = 0.05975932341034025     Test_loss = 0.11963782636702225\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "989 Train_loss = 0.059735331786138705     Test_loss = 0.11962031257827228\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "990 Train_loss = 0.059711343866115124     Test_loss = 0.11960725881262982\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "991 Train_loss = 0.05968735600858233     Test_loss = 0.11959203125457608\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "992 Train_loss = 0.05966341656953355     Test_loss = 0.1195784600229866\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "993 Train_loss = 0.059639482809212004     Test_loss = 0.11956428625663164\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "994 Train_loss = 0.059615544274213776     Test_loss = 0.11954829282406479\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "995 Train_loss = 0.05959163764626123     Test_loss = 0.11953412676487832\n",
            "\n",
            "Accuracy : 0.9636904761904762\n",
            "996 Train_loss = 0.059567703379454315     Test_loss = 0.11951919467620055\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "997 Train_loss = 0.05954375772797541     Test_loss = 0.11950602003751783\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "998 Train_loss = 0.059519883139724956     Test_loss = 0.11949136576990901\n",
            "\n",
            "Accuracy : 0.9638095238095238\n",
            "999 Train_loss = 0.05949597988741016     Test_loss = 0.11947421194369869\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(test_losses)\n",
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8tmYt8QQOBqD",
        "outputId": "176ffe00-39cb-4424-a9cc-baff497cf464"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbbbb18cd10>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h9pjEHTZsJ7",
        "outputId": "5cf67a81-7e86-4026-dec3-9a8fd97975b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 6, ..., 7, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "finyhat_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqGoAQcXZsJ8",
        "outputId": "b369c7bb-2ef1-4859-abe3-4f9d8b1f83d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 6, ..., 7, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR1MjKSxZsJ8",
        "outputId": "8fda1708-be2d-42db-999a-27dd1288b074"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03619047619047619"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "(finyhat_test.argmax(axis=1) != y_test).sum()/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4kLeQs1ZsJ9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XUv_G0LMLD6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TTuTWZaBLD3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M7CwkPLLLD0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oZywSNMYLDox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Making submission"
      ],
      "metadata": {
        "id": "GqyKAgYuFaav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZztXQzIaZsJ9"
      },
      "outputs": [],
      "source": [
        "X_te = test_df.to_numpy()\n",
        "X_te = X_te/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "G6Xhbd-tZsJ9"
      },
      "outputs": [],
      "source": [
        "y_te = model.predict(X_te).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WVqtY96oZsJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3743fc01-0e4c-4ea4-896e-ae49b2151072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 9, ..., 3, 9, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "y_te"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df['Label'] = y_te"
      ],
      "metadata": {
        "id": "PZ7hZ5wXMSoI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.to_csv(\"NN_twolayer_normal_128_256_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "ukZeYkA8MSk8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MmTNbZqBMSiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zI40_lOUMSew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VMSIeNFyMSaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucTUl_xoZsJ9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aRiZQE9ZsJ-"
      },
      "source": [
        "## Getting some data\n",
        "\n",
        "This is random data. DO NOT USE THIS. This is just to show you what the function calls would be like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZCU7_5CZsJ-"
      },
      "outputs": [],
      "source": [
        "NUM_ROWS = 10000\n",
        "NUM_COLUMNS_X = 200 \n",
        "NUM_CLASSES = 5\n",
        "X = np.random.uniform(size=(NUM_ROWS,NUM_COLUMNS_X))\n",
        "y = np.random.randint(size=(NUM_ROWS,),low=0,high=NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LRm83PKZsJ-"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetworkClassifier([(NUM_COLUMNS_X, \"relu\"), (200, \"relu\"), (NUM_CLASSES, \"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Kl6BohZsJ-"
      },
      "outputs": [],
      "source": [
        "yd = np.zeros((len(y), NUM_CLASSES))\n",
        "for i in range(len(y)):\n",
        "    yd[i][y[i]-1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaAgphWgZsJ_",
        "outputId": "17551f72-22e6-44f7-e4b0-27f2aaac6ab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6.51735571e-04, 9.88383807e-01, 6.17773969e-03, 4.46074257e-04,\n",
              "        4.34064348e-03],\n",
              "       [1.03730682e-03, 9.84018546e-01, 8.62198428e-03, 6.68718651e-04,\n",
              "        5.65344466e-03],\n",
              "       [1.47501066e-03, 9.80120147e-01, 1.01080563e-02, 9.41745652e-04,\n",
              "        7.35504012e-03],\n",
              "       ...,\n",
              "       [1.07377647e-03, 9.83331962e-01, 8.94290440e-03, 7.64428204e-04,\n",
              "        5.88692908e-03],\n",
              "       [1.21479588e-03, 9.81413921e-01, 9.76396501e-03, 8.35904428e-04,\n",
              "        6.77141363e-03],\n",
              "       [1.13575878e-03, 9.83710729e-01, 8.39080987e-03, 7.56295056e-04,\n",
              "        6.00640749e-03]])"
            ]
          },
          "execution_count": 374,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqETj7FKZsJ_",
        "outputId": "949ff763-558a-4ed0-96d9-8a9067087566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.793445531816353"
            ]
          },
          "execution_count": 375,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.categorical_cross_entropy_loss(y, model.predict(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKAS32kTZsJ_"
      },
      "outputs": [],
      "source": [
        "losses = [] \n",
        "NUM_ITERS = 100\n",
        "for _ in range(NUM_ITERS):\n",
        "    yhat = model.predict(X)\n",
        "    loss = model.categorical_cross_entropy_loss(y, yhat)\n",
        "    losses.append(loss)\n",
        "    model.fit_once(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY7gtorHZsKA",
        "outputId": "1347dd7a-52b0-484a-8d8a-9322e1ea0c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4.793445531816353,\n",
              " 4.401753425856968,\n",
              " 4.021828510590914,\n",
              " 3.6597644849216624,\n",
              " 3.3234590729271893,\n",
              " 3.0216763923272665,\n",
              " 2.761871481079625,\n",
              " 2.5474775802452263,\n",
              " 2.376481663143961,\n",
              " 2.242523181984943,\n",
              " 2.1375644686610658,\n",
              " 2.054181558787989,\n",
              " 1.9865785440529005,\n",
              " 1.9306287590757683,\n",
              " 1.8835204183743917,\n",
              " 1.8433588423018594,\n",
              " 1.8088501501263066,\n",
              " 1.7790810848963745,\n",
              " 1.7533755101472572,\n",
              " 1.7312045484170067,\n",
              " 1.7121321142377146,\n",
              " 1.6957830252151016,\n",
              " 1.6818250946759143,\n",
              " 1.6699595640209275,\n",
              " 1.6599162418531153,\n",
              " 1.651451074887023,\n",
              " 1.6443447882988351,\n",
              " 1.6384018361938462,\n",
              " 1.633449288226895,\n",
              " 1.6293355118664818,\n",
              " 1.6259286400297552,\n",
              " 1.623114876944084,\n",
              " 1.6207967172112359,\n",
              " 1.6188911522196578,\n",
              " 1.6173279260877305,\n",
              " 1.6160478874546296,\n",
              " 1.6150014677118636,\n",
              " 1.6141473026612811,\n",
              " 1.6134510038086969,\n",
              " 1.612884077567911,\n",
              " 1.6124229852243417,\n",
              " 1.612048333127781,\n",
              " 1.6117441807762636,\n",
              " 1.6114974537929225,\n",
              " 1.6112974489317355,\n",
              " 1.6111354188981633,\n",
              " 1.6110042257268051,\n",
              " 1.6108980525683105,\n",
              " 1.6108121648957476,\n",
              " 1.6107427132761363,\n",
              " 1.6106865709220948,\n",
              " 1.610641200216784,\n",
              " 1.6106045432814,\n",
              " 1.6105749324260785,\n",
              " 1.6105510169957702,\n",
              " 1.6105317036994085,\n",
              " 1.6105161080023196,\n",
              " 1.6105035145777895,\n",
              " 1.610493345163417,\n",
              " 1.6104851324604361,\n",
              " 1.6104784989576795,\n",
              " 1.6104731397638257,\n",
              " 1.6104688086984864,\n",
              " 1.61046530703018,\n",
              " 1.610462474362313,\n",
              " 1.6104601812609334,\n",
              " 1.610458323293883,\n",
              " 1.610456816212946,\n",
              " 1.6104555920611063,\n",
              " 1.610454596028215,\n",
              " 1.6104537839118436,\n",
              " 1.610453120067332,\n",
              " 1.6104525757531163,\n",
              " 1.610452127795378,\n",
              " 1.610451757510557,\n",
              " 1.6104514498360707,\n",
              " 1.6104511926290896,\n",
              " 1.6104509761009513,\n",
              " 1.6104507923610198,\n",
              " 1.6104506350488448,\n",
              " 1.6104504990375514,\n",
              " 1.610450380194685,\n",
              " 1.6104502751893943,\n",
              " 1.61045018133698,\n",
              " 1.6104500964735744,\n",
              " 1.6104500188551218,\n",
              " 1.6104499470759401,\n",
              " 1.6104498800030813,\n",
              " 1.6104498167234194,\n",
              " 1.6104497565009994,\n",
              " 1.610449698742665,\n",
              " 1.6104496429703512,\n",
              " 1.610449588798754,\n",
              " 1.6104495359173276,\n",
              " 1.6104494840757848,\n",
              " 1.6104494330723984,\n",
              " 1.6104493827445818,\n",
              " 1.6104493329612957,\n",
              " 1.6104492836169222,\n",
              " 1.6104492346263366]"
            ]
          },
          "execution_count": 377,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl5EmAk2ZsKA"
      },
      "outputs": [],
      "source": [
        "q = np.array([[1, -1, 2], [1, 2, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uUbtv4WZsKA",
        "outputId": "17cc6c3e-7fdc-4a60-c510-c070464d6acb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 0, 3],\n",
              "       [3, 4, 5]])"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q + np.array([[1], [2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIUNx1sGZsKA",
        "outputId": "8aa6bc19-e601-4499-e6ce-2f2de59d3bde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.07382656],\n",
              "       [0.07878063],\n",
              "       [0.02466814],\n",
              "       [0.08475965]])"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " np.random.uniform(low=0, high=0.1, size=(4, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9nQFSAtZsKB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVhBv2CZsKB",
        "outputId": "80b82e7b-540b-4f35-8355-2fb49c73db73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25949646, 0.03511903, 0.70538451],\n",
              "       [0.09003057, 0.24472847, 0.66524096]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = np.array([[1, -1, 2], [1, 2, 3]])\n",
        "np.exp(q) / np.tile(np.exp(q).sum(axis=1), (3, 1)).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdEE8t6XZsKB",
        "outputId": "9700244d-5245-413a-96d0-f0c6a76e5d09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25949646, 0.03511903, 0.70538451],\n",
              "       [0.09003057, 0.24472847, 0.66524096]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "softmaxActivate(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVELzNLYZsKB"
      },
      "outputs": [],
      "source": [
        "l = [softmaxActivate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qinHHKgZsKB",
        "outputId": "8ab5bd35-1b22-424b-a32d-83858636075a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.25949646, 0.03511903, 0.70538451],\n",
              "       [0.09003057, 0.24472847, 0.66524096]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l[0](q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8uQijniZsKB",
        "outputId": "8111aaa4-56fc-4450-cac8-e49bac72ae81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.71828183,  0.36787944,  7.3890561 ],\n",
              "       [ 2.71828183,  7.3890561 , 20.08553692]])"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.exp(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozQ1oAD8ZsKC"
      },
      "outputs": [],
      "source": [
        "r = np.array([-1,5,6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGjxts06ZsKC"
      },
      "outputs": [],
      "source": [
        "r[r<0] = 0\n",
        "r[r>0] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJnyo3cuZsKC",
        "outputId": "9b6f929d-4817-4fc0-b41f-3a4abd6e7765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1])"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43S2cmrDZsKC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "3e8fb002e6e83f8cdbe11f489f5734d63338be518a5eeb53c4bb6f16064b3c51"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "a3_notebook_128_256.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-aRiZQE9ZsJ-"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}